{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RVKTUExooKZ"
      },
      "source": [
        "# 1. Initialization\n",
        "\n",
        "This section contains code for initialization. It contains code from the labs relating to dataset preparation, setting up the experiments, and helper functions etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbc-zZGqJDJB",
        "outputId": "7379aefd-6504-4eb9-ccee-1b4cc32cc2e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flwr (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install --quiet --upgrade \"pip\"\n",
        "! pip install --quiet git+https://github.com/Iacob-Alexandru-Andrei/flower.git@teaching torch torchvision matplotlib gdown tqdm ray==\"2.6.3\" seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "99aC-H3gr5ey"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import sys\n",
        "import random\n",
        "from collections.abc import Callable, Sequence\n",
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "from logging import INFO\n",
        "from datetime import timezone\n",
        "from datetime import datetime\n",
        "\n",
        "import flwr as fl\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import json\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from flwr.common.parameter import ndarrays_to_parameters\n",
        "from flwr.common.typing import NDArrays, Parameters, Scalar\n",
        "from flwr.common.logger import log\n",
        "from flwr.server import ServerConfig, History\n",
        "from flwr.server.strategy import FedAvg, Strategy\n",
        "from torch.nn import Module\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "from enum import IntEnum\n",
        "from flwr.client import Client\n",
        "\n",
        "\n",
        "# Add new seeds here for easy autocomplete\n",
        "class Seeds(IntEnum):\n",
        "    DEFAULT = 1337\n",
        "\n",
        "\n",
        "np.random.seed(Seeds.DEFAULT)\n",
        "random.seed(Seeds.DEFAULT)\n",
        "torch.manual_seed(Seeds.DEFAULT)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def fit_client_seeded(client, params, conf, seed=Seeds.DEFAULT):\n",
        "    \"\"\"Wrapper to always seed client training.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    return client.fit(params, conf)\n",
        "\n",
        "\n",
        "PathType = Path | str | None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following contains code for preparing the dataset. This project uses CIFAR10 instead of FEMNIST and the code is changed accordingly."
      ],
      "metadata": {
        "id": "wvlgytFAA2ii"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2hQhnTM0JU9y"
      },
      "outputs": [],
      "source": [
        "home_dir = content if (content := Path(\"/content\")).exists() else Path.cwd()\n",
        "dataset_dir: Path = home_dir / \"cifar10\"\n",
        "data_dir: Path = dataset_dir / \"data\"\n",
        "centralized_partition: Path = dataset_dir / \"client_data_mappings\" / \"centralized\"\n",
        "centralized_mapping: Path = dataset_dir / \"client_data_mappings\" / \"centralized\" / \"0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_train = torchvision.datasets.CIFAR10(dataset_dir, train = True, download = True)\n",
        "cifar10_test = torchvision.datasets.CIFAR10(dataset_dir, train = False, download = True)"
      ],
      "metadata": {
        "id": "05qpjt5ABum2",
        "outputId": "4ec1fe1f-2b2d-458d-fe93-1d33fe93fe95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 63411142.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/cifar10/cifar-10-python.tar.gz to /content/cifar10\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(cifar10_train))\n",
        "sample[0]"
      ],
      "metadata": {
        "id": "XHdCCkikCB0e",
        "outputId": "cfe196b9-fcaa-4816-8d1d-f4bded905399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions and experiment setup functions\n",
        "def convert(o: Any) -> int | float:\n",
        "    \"\"\"Convert input object to Python numerical if numpy.\"\"\"\n",
        "    # type: ignore[reportGeneralTypeIssues]\n",
        "    if isinstance(o, np.int32 | np.int64):\n",
        "        return int(o)\n",
        "    # type: ignore[reportGeneralTypeIssues]\n",
        "    if isinstance(o, np.float32 | np.float64):\n",
        "        return float(o)\n",
        "    raise TypeError\n",
        "\n",
        "\n",
        "def save_history(hist: History, name: str) -> None:\n",
        "    \"\"\"Save history from simulation to file.\"\"\"\n",
        "    time = int(datetime.now(timezone.utc).timestamp())\n",
        "    path = home_dir / \"histories\"\n",
        "    path.mkdir(exist_ok=True)\n",
        "    path = path / f\"hist_{time}_{name}.json\"\n",
        "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(hist.__dict__, f, ensure_ascii=False, indent=4, default=convert)\n",
        "\n",
        "\n",
        "def start_seeded_simulation(\n",
        "    client_fn: Callable[[str], Client],\n",
        "    num_clients: int,\n",
        "    config: ServerConfig,\n",
        "    strategy: Strategy,\n",
        "    name: str,\n",
        "    seed: int = Seeds.DEFAULT,\n",
        "    iteration: int = 0,\n",
        ") -> tuple[list[tuple[int, NDArrays]], History]:\n",
        "    \"\"\"Wrap simulation to always seed client selection.\"\"\"\n",
        "    np.random.seed(seed ^ iteration)\n",
        "    torch.manual_seed(seed ^ iteration)\n",
        "    random.seed(seed ^ iteration)\n",
        "    parameter_list, hist = fl.simulation.start_simulation_no_ray(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=num_clients,\n",
        "        client_resources={},\n",
        "        config=config,\n",
        "        strategy=strategy,\n",
        "    )\n",
        "    save_history(hist, name)\n",
        "    return parameter_list, hist"
      ],
      "metadata": {
        "id": "Y4qq8gTTBLIl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not (home_dir / \"common\").exists():\n",
        "    ! git clone \"https://github.com/camlsys/L361-Federated-Learning.git\" temp_repo\n",
        "\n",
        "    # Copy the folder to the current directory\n",
        "    ! cp -r \"temp_repo/labs/common\" {home_dir}\n",
        "\n",
        "    # Delete the cloned repository\n",
        "    ! rm -rf temp_repo\n",
        "\n",
        "    # Create the __init__.py file\n",
        "    (home_dir / \"__init__.py\").open(mode=\"a+\")"
      ],
      "metadata": {
        "id": "xLbpNynNHEnd",
        "outputId": "fcbd3718-9f55-4c78-a9cd-7188b5d65488",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'temp_repo'...\n",
            "remote: Enumerating objects: 214, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 214 (delta 54), reused 50 (delta 34), pack-reused 135\u001b[K\n",
            "Receiving objects: 100% (214/214), 648.81 KiB | 5.15 MiB/s, done.\n",
            "Resolving deltas: 100% (121/121), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from common.client_utils import (\n",
        "    to_tensor_transform,\n",
        "    get_model_parameters,\n",
        "    set_model_parameters,\n",
        "    get_federated_evaluation_function,\n",
        "    aggregate_weighted_average,\n",
        "    get_device,\n",
        ")\n",
        "from common.client import FlowerClient, get_flower_client_generator"
      ],
      "metadata": {
        "id": "ngnYpVnBATFX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Setup\n",
        "\n",
        "Additional experimental setup functions. This includes code for partitioning (as CIFAR10 is not a FL dataset), the models we will be using, and code for setting up the FL experiments."
      ],
      "metadata": {
        "id": "SpsM6V5HaKPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some variables\n",
        "\n",
        "NUM_CLIENTS = 100\n",
        "lda_concentrations = [0.1, 1.0, 1000.]\n",
        "lda_concentration_string = [\"0_1\", \"1\", \"1000\"]"
      ],
      "metadata": {
        "id": "Ikw20Ltf-ZqK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating centralized partition\n",
        "train_data_dir: Path = data_dir / \"train\"\n",
        "test_data_dir: Path = data_dir / \"test\"\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "train_data_dir.mkdir(parents=True, exist_ok=True)\n",
        "test_data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "images_train, labels_train = zip(*cifar10_train)\n",
        "for i, image in enumerate(images_train):\n",
        "  image.save(f\"{train_data_dir}/train_{i}.png\")\n",
        "image_train_paths = [f\"train_{i}.png\" for i, image in enumerate(images_train)]\n",
        "\n",
        "images_test, labels_test = zip(*cifar10_test)\n",
        "for i, image in enumerate(images_test):\n",
        "  image.save(f\"{test_data_dir}/test_{i}.png\")\n",
        "image_test_paths = [f\"test_{i}.png\" for i, image in enumerate(images_test)]\n",
        "\n",
        "centralized_mapping.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_path: Path = centralized_mapping / \"train.csv\"\n",
        "test_path: Path = centralized_mapping / \"test.csv\"\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"client_id\": [0] * len(image_train_paths),\n",
        "        \"sample_path\": image_train_paths,\n",
        "        \"sample_id\": range(len(image_train_paths)),\n",
        "        \"label\": labels_train,\n",
        "    }\n",
        ").to_csv(train_path, index=False, mode=\"w\")\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"client_id\": [0] * len(image_test_paths),\n",
        "        \"sample_path\": image_test_paths,\n",
        "        \"sample_id\": range(len(image_test_paths)),\n",
        "        \"label\": labels_test,\n",
        "    }\n",
        ").to_csv(test_path, index=False, mode=\"w\")"
      ],
      "metadata": {
        "id": "785Rc1rH-RdD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating federated partition using LDA\n",
        "\n",
        "from common.lda_utils import create_lda_partitions\n",
        "\n",
        "for i, concentration in enumerate(lda_concentrations):\n",
        "  images_train, labels_train = zip(*cifar10_train)\n",
        "  image_train_paths = np.array([f\"train_{i}.png\" for i, image in enumerate(images_train)])\n",
        "  labels_train = np.array(labels_train)\n",
        "  train_clients_partitions, dist = create_lda_partitions(\n",
        "      dataset=(image_train_paths, labels_train),\n",
        "      dirichlet_dist=None,\n",
        "      num_partitions=NUM_CLIENTS,\n",
        "      concentration=concentration,\n",
        "      accept_imbalanced=True,\n",
        "      seed=Seeds.DEFAULT,\n",
        "  )\n",
        "  images_test, labels_test = zip(*cifar10_test)\n",
        "  image_test_paths = np.array([f\"test_{i}.png\" for i, image in enumerate(images_test)])\n",
        "  labels_test = np.array(labels_test)\n",
        "  test_clients_partitions, dist = create_lda_partitions(\n",
        "      dataset=(image_test_paths, labels_test),\n",
        "      dirichlet_dist=dist,\n",
        "      num_partitions=NUM_CLIENTS,\n",
        "      concentration=concentration,\n",
        "      accept_imbalanced=True,\n",
        "      seed=Seeds.DEFAULT,\n",
        "  )\n",
        "  lda_partition: Path = dataset_dir / \"client_data_mappings\" / \"lda\" / lda_concentration_string[i]\n",
        "  if lda_partition.exists():\n",
        "      ! rm -rf {str(lda_partition)}\n",
        "  lda_partition.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  for j, (train_set, test_set) in enumerate(\n",
        "      zip(train_clients_partitions, test_clients_partitions, strict=True)\n",
        "  ):\n",
        "      folder_path: Path = lda_partition / str(j)\n",
        "      folder_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "      train_path: Path = folder_path / \"train.csv\"\n",
        "      test_path: Path = folder_path / \"test.csv\"\n",
        "\n",
        "      pd.DataFrame(\n",
        "          {\n",
        "              \"client_id\": [0] * len(train_set[0]),\n",
        "              \"sample_path\": train_set[0],\n",
        "              \"sample_id\": range(len(train_set[0])),\n",
        "              \"label\": train_set[1],\n",
        "          }\n",
        "      ).to_csv(train_path, index=False, mode=\"w\")\n",
        "      pd.DataFrame(\n",
        "          {\n",
        "              \"client_id\": [0] * len(test_set[0]),\n",
        "              \"sample_path\": test_set[0],\n",
        "              \"sample_id\": range(len(test_set[0])),\n",
        "              \"label\": test_set[1],\n",
        "          }\n",
        "      ).to_csv(test_path, index=False, mode=\"w\")"
      ],
      "metadata": {
        "id": "07GGFGlycRKQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from PIL.Image import Image as ImageType\n",
        "class ImageDataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        mapping: Path,\n",
        "        data_dir: Path,\n",
        "        name: str = \"train\",\n",
        "        transform: Callable[[ImageType], Any] | None = None,\n",
        "        target_transform: Callable[[int], Any] | None = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            mapping (Path): path to the mapping folder containing the .csv files.\n",
        "            data_dir (Path): path to the dataset folder. Defaults to data_dir.\n",
        "            name (str): name of the dataset to load, train or test.\n",
        "            transform (Optional[Callable[[ImageType], Any]], optional):\n",
        "                    transform function to be applied to the ImageType object.\n",
        "            target_transform (Optional[Callable[[int], Any]], optional):\n",
        "                    transform function to be applied to the label.\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.mapping = mapping\n",
        "        self.name = name\n",
        "\n",
        "        self.data: Sequence[tuple[str, int]] = self._load_dataset()\n",
        "        self.transform: Callable[[ImageType], Any] | None = transform\n",
        "        self.target_transform: Callable[[int], Any] | None = target_transform\n",
        "\n",
        "    def __getitem__(self, index: int) -> tuple[Any, Any]:\n",
        "        \"\"\"Get a sample.\n",
        "\n",
        "        Args:\n",
        "            index (_type_): index of the sample.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            Tuple[Any, Any]: couple (sample, label).\n",
        "        \"\"\"\n",
        "        sample_path, label = self.data[index]\n",
        "\n",
        "        # Convert to the full path\n",
        "        full_sample_path: Path = self.data_dir / self.name / sample_path\n",
        "\n",
        "        img: ImageType = Image.open(full_sample_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"Get the length of the dataset as number of samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            int: the length of the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def _load_dataset(self) -> Sequence[tuple[str, int]]:\n",
        "        \"\"\"Load the paths and labels of the partition.\n",
        "\n",
        "        Preprocess the dataset for faster future loading\n",
        "        If opened for the first time\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "            ValueError: raised if the mapping file doesn't exists\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            Sequence[Tuple[str, int]]:\n",
        "                partition asked as a sequence of couples (path_to_file, label)\n",
        "        \"\"\"\n",
        "        preprocessed_path: Path = (self.mapping / self.name).with_suffix(\".pt\")\n",
        "        if preprocessed_path.exists():\n",
        "            return torch.load(preprocessed_path)\n",
        "        else:\n",
        "            csv_path = (self.mapping / self.name).with_suffix(\".csv\")\n",
        "            if not csv_path.exists():\n",
        "                raise ValueError(f\"Required files do not exist, path: {csv_path}\")\n",
        "\n",
        "            with open(csv_path) as csv_file:\n",
        "                csv_reader = csv.reader(csv_file)\n",
        "                # Ignore header\n",
        "                next(csv_reader)\n",
        "\n",
        "                # Extract the samples and the labels\n",
        "                partition: Sequence[tuple[str, int]] = [\n",
        "                    (sample_path, int(label_id))\n",
        "                    for _, sample_path, _, label_id in csv_reader\n",
        "                ]\n",
        "\n",
        "                # Save for future loading\n",
        "                torch.save(partition, preprocessed_path)\n",
        "                return partition\n",
        "\n",
        "def load_dataset(  # noqa: N802\n",
        "    data_dir: Path, mapping: Path, name: str\n",
        ") -> Dataset:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    return ImageDataset(\n",
        "        mapping=mapping,\n",
        "        name=name,\n",
        "        data_dir=data_dir,\n",
        "        transform=transform,\n",
        "        target_transform=to_tensor_transform,\n",
        "    )"
      ],
      "metadata": {
        "id": "2w3eTL8TCgZW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first define the models for training. These are simple CNNs and ViTs for CIFAR10."
      ],
      "metadata": {
        "id": "Ob47bicbdGFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10Net(nn.Module):\n",
        "\n",
        "    def __init__(self, num_labels) -> None:\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(2048, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, num_labels)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Perform a forward pass through the neural network.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            torch.Tensor: The output tensor.\n",
        "        \"\"\"\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "03Atx3CHxkZF"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from common.client import FlowerClient\n",
        "from collections.abc import Sized\n",
        "import logging\n",
        "\n",
        "def get_flower_client_generator(\n",
        "    model_generator: Callable[[], Module],\n",
        "    partition_dir: Path,\n",
        "    data_dir: Path,\n",
        "    mapping_fn: Callable[[int], int] | None = None,\n",
        "    client_class = FlowerClient,\n",
        "    *args,\n",
        "    **kwargs,\n",
        ") -> Callable[[str], FlowerClient]:\n",
        "\n",
        "    def client_fn(cid: str) -> FlowerClient:\n",
        "        return client_class(\n",
        "            cid=mapping_fn(int(cid)) if mapping_fn is not None else int(cid),\n",
        "            partition_dir=partition_dir,\n",
        "            model_generator=model_generator,\n",
        "            data_dir=data_dir,\n",
        "            *args,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "def get_federated_evaluation_function(\n",
        "    data_dir: Path,\n",
        "    centralized_mapping: Path,\n",
        "    device: str,\n",
        "    batch_size: int,\n",
        "    num_workers: int,\n",
        "    model_generator: Callable[[], Module],\n",
        "    criterion: Module,\n",
        ") -> Callable[[int, NDArrays, dict[str, Any]], tuple[float, dict[str, Scalar]]]:\n",
        "    \"\"\"Wrap function for the external federated evaluation function.\n",
        "\n",
        "    It provides the external federated evaluation function with some\n",
        "    parameters for the dataloader, the model generator function, and\n",
        "    the criterion used in the evaluation.\n",
        "\n",
        "    Args:\n",
        "        data_dir (Path): path to the dataset folder.\n",
        "        centralized_mapping (Path): path to the mapping .csv file chosen.\n",
        "        device (str):  device name onto which perform the computation.\n",
        "        batch_size (int): batch size of the test set to use.\n",
        "        num_workers (int): correspond to `num_workers` param in the Dataloader object.\n",
        "        model_generator (Callable[[], Module]):  model generator function.\n",
        "        criterion (Module): PyTorch Module containing the criterion.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Callable[[int, NDArrays, dict[str, Any]], tuple[float, dict[str, Scalar]]]:\n",
        "            external federated evaluation function.\n",
        "    \"\"\"\n",
        "    full_file: Path = centralized_mapping\n",
        "    dataset: Dataset = load_dataset(data_dir, full_file, \"test\")\n",
        "    num_samples = len(cast(Sized, dataset))\n",
        "    index_list = list(range(num_samples))\n",
        "    prng = np.random.RandomState(1337)\n",
        "    prng.shuffle(index_list)\n",
        "    index_list = index_list[:1500]\n",
        "    dataset = torch.utils.data.Subset(dataset, index_list)\n",
        "\n",
        "    log(\n",
        "        logging.INFO,\n",
        "        \"Reduced federated test_set size from %s to a size of %s mean index: %s\",\n",
        "        num_samples,\n",
        "        len(cast(Sized, dataset)),\n",
        "        np.mean(index_list),\n",
        "    )\n",
        "\n",
        "    def federated_evaluation_function(\n",
        "        server_round: int,\n",
        "        parameters: NDArrays,\n",
        "        fed_eval_config: dict[\n",
        "            str, Any\n",
        "        ],  # mandatory argument, even if it's not being used\n",
        "    ) -> tuple[float, dict[str, Scalar]]:\n",
        "        net: Module = set_model_parameters(model_generator(), parameters)\n",
        "        net.to(device)\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            dataset=dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            drop_last=False,\n",
        "        )\n",
        "\n",
        "        loss, acc = test(\n",
        "            net=net,\n",
        "            test_loader=test_loader,\n",
        "            device=device,\n",
        "            criterion=criterion,\n",
        "        )\n",
        "        return loss, {\"accuracy\": acc}\n",
        "\n",
        "    return federated_evaluation_function"
      ],
      "metadata": {
        "id": "3TwEoqT0kdpm"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic Strategy (Weighted FedAvg)\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.common import FitRes, parameters_to_ndarrays\n",
        "\n",
        "class WrappedFedAvg(FedAvg):\n",
        "    clients_models: dict[int, list[tuple[int, NDArrays]]] = {}\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: list[tuple[ClientProxy, FitRes]],\n",
        "        failures: list[tuple[ClientProxy, FitRes] | BaseException],\n",
        "    ) -> tuple[Parameters | None, dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        # Call FedAvg original aggregate_fit, so that it handles the failures\n",
        "        ret = super().aggregate_fit(server_round, results, failures)\n",
        "        # Append clients' model parameters to the list\n",
        "        self.clients_models[server_round] = [\n",
        "            (i, parameters_to_ndarrays(fit_res.parameters))\n",
        "            for i, (_, fit_res) in enumerate(results)\n",
        "        ]\n",
        "        # Return the original return value\n",
        "        return ret"
      ],
      "metadata": {
        "id": "5Rod_R4yDGtW"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_network_generator_cnn():\n",
        "    untrained_net: CIFAR10Net = CIFAR10Net(num_labels = 10)\n",
        "    def generated_net():\n",
        "        return deepcopy(untrained_net)\n",
        "    return generated_net\n",
        "\n",
        "def fit_client_seeded(client, params, conf, seed=Seeds.DEFAULT):\n",
        "    \"\"\"Wrapper to always seed client training.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    random.seed(seed)\n",
        "    return client.fit(params, conf)"
      ],
      "metadata": {
        "id": "bGS6TsICr0b4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Experiments\n",
        "\n",
        "The following contains code to be running the experiments. This is split into the basic requirements, and the extensions part. The basic requirements looks into FedOpt and how the different FedOpt strategies perform under different data heterogeneity levels."
      ],
      "metadata": {
        "id": "bX2V4A-yFHU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to save computing resources and focus more on per-round effects in FL, in this project we use models trained with 50% of steps necessary for full training as the starting model in FL experiments. To determine the number of steps necessary for full training, we train a centralized model until its performance stops improving. The following is a simple FlowerClient which performs validation during training and stops training when the performance on the validation dataset stops improving."
      ],
      "metadata": {
        "id": "YYuRap-EpGUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import cast\n",
        "\n",
        "def test(  # noqa: N802\n",
        "    net: Module,\n",
        "    test_loader: DataLoader,\n",
        "    device: str,\n",
        "    criterion: Module,\n",
        "    max_batches: int | None = None,\n",
        "    **kwargs: dict[str, Any],\n",
        ") -> tuple[float, float]:\n",
        "    batch_cnt = 0\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, labels in tqdm(test_loader):\n",
        "\n",
        "            if max_batches is not None and batch_cnt >= max_batches:\n",
        "                break\n",
        "            batch_cnt += 1\n",
        "\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            outputs = net(data)\n",
        "\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy\n",
        "\n",
        "\n",
        "class FlowerEarlyStoppingClient(FlowerClient):\n",
        "  def __init__(\n",
        "        self,\n",
        "        cid: int,\n",
        "        partition_dir: Path,\n",
        "        model_generator: Callable[[], Module],\n",
        "        data_dir: Path,\n",
        "        validation_config: dict\n",
        "    ):\n",
        "    self.cid = cid\n",
        "    log(INFO, \"Creating client with cid: %s\", self.cid)\n",
        "    self.partition_dir = partition_dir\n",
        "    self.data_dir = data_dir\n",
        "    self.device = get_device()\n",
        "    self.model_generator: Callable[[], Module] = model_generator\n",
        "    self.properties: dict[str, Scalar] = {\"tensor_type\": \"numpy.ndarray\"}\n",
        "    self.validation_config = validation_config\n",
        "    self.epochs_trained = 0\n",
        "\n",
        "  # def fit(\n",
        "  #     self, parameters: NDArrays, config: dict[str, Scalar]\n",
        "  # ) -> tuple[NDArrays, int, dict]:\n",
        "  #     \"\"\"Receive and train a model on the local client data.\n",
        "\n",
        "  #     It uses the instruction passed through the config dict.\n",
        "\n",
        "  #     Args:\n",
        "  #         net (NDArrays): Pytorch model parameters\n",
        "  #         config (dict[str, Scalar]): dictionary describing the training parameters\n",
        "\n",
        "  #     Returns\n",
        "  #     -------\n",
        "  #         tuple[NDArrays, int, dict]: Returns the updated model, the size of the local\n",
        "  #             dataset and other metrics\n",
        "  #     \"\"\"\n",
        "  #     # Only create model right before training/testing\n",
        "  #     # To lower memory usage when idle\n",
        "  #     net = self.set_parameters(parameters)\n",
        "  #     net.to(self.device)\n",
        "\n",
        "  #     train_loader: DataLoader = self._create_data_loader(config, name=\"train\")\n",
        "  #     train_loss = self._train(net, train_loader=train_loader, config=config)\n",
        "  #     return get_model_parameters(net), len(train_loader), {\"train_loss\": train_loss}\n",
        "\n",
        "  # def evaluate(\n",
        "  #     self, parameters: NDArrays, config: dict[str, Scalar]\n",
        "  # ) -> tuple[float, int, dict]:\n",
        "  #     \"\"\"Receive and test a model on the local client data.\n",
        "\n",
        "  #     It uses the instruction passed through the config dict.\n",
        "\n",
        "  #     Args:\n",
        "  #         net (NDArrays): Pytorch model parameters\n",
        "  #         config (dict[str, Scalar]): dictionary describing the testing parameters\n",
        "\n",
        "  #     Returns\n",
        "  #     -------\n",
        "  #         tuple[float, int, dict]: Returns the loss accumulate during testing, the\n",
        "  #             size of the local dataset and other metrics such as accuracy\n",
        "  #     \"\"\"\n",
        "  #     net = self.set_parameters(parameters)\n",
        "  #     net.to(self.device)\n",
        "\n",
        "  #     test_loader: DataLoader = self._create_data_loader(config, name=\"test\")\n",
        "  #     loss, accuracy = self._test(net, test_loader=test_loader, config=config)\n",
        "  #     return loss, len(test_loader), {\"local_accuracy\": accuracy}\n",
        "\n",
        "  def _train(\n",
        "        self, net: Module, train_loader: DataLoader, config: dict[str, Scalar]\n",
        "    ) -> float:\n",
        "      running_loss, total = 0.0, 0\n",
        "      min_validation_loss = float('inf')\n",
        "      early_stopping_counter = 0\n",
        "      if(config[\"optimizer\"] == \"sgd\"):\n",
        "        optimizer = torch.optim.SGD(\n",
        "            net.parameters(),\n",
        "            lr = float(config[\"client_learning_rate\"]),\n",
        "            weight_decay=float(config[\"weight_decay\"])\n",
        "        )\n",
        "      elif(config[\"optimizer\"] == \"adam\"):\n",
        "        optimizer=torch.optim.AdamW(\n",
        "            net.parameters(),\n",
        "            lr=float(config[\"client_learning_rate\"]),\n",
        "            weight_decay=float(config[\"weight_decay\"])\n",
        "        )\n",
        "      criterion=torch.nn.CrossEntropyLoss()\n",
        "      max_batches=cast(int | None, config[\"max_batches\"])\n",
        "      for epoch in tqdm(range(int(config[\"epochs\"]))):\n",
        "          net.train()\n",
        "          running_loss = 0.0\n",
        "          total, batch_cnt = 0, 0\n",
        "          train_size = int(self.validation_config[\"train_dataloader_ratio\"] * len(train_loader.dataset))\n",
        "          valid_size = len(train_loader.dataset) - train_size\n",
        "          train_dataset, valid_dataset = torch.utils.data.random_split(train_loader.dataset, [train_size, valid_size])\n",
        "          train_dataloader = DataLoader(train_dataset, batch_size=train_loader.batch_size, shuffle=True)\n",
        "          valid_dataloader = DataLoader(valid_dataset, batch_size=train_loader.batch_size, shuffle=False)\n",
        "          for i, (data, labels) in enumerate(train_dataloader):\n",
        "              data, labels = data.to(self.device), labels.to(self.device)\n",
        "              optimizer.zero_grad()\n",
        "              outputs = net(data)\n",
        "              loss = criterion(outputs, labels)\n",
        "              running_loss += loss.item()\n",
        "              total += labels.size(0)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              # Break if we have exceeded the upper limit\n",
        "              # On training batches for a given round\n",
        "              # Simulate enumerate counting for train/test parity\n",
        "              if max_batches and batch_cnt > max_batches:\n",
        "                  break\n",
        "              batch_cnt += 1\n",
        "          self.epochs_trained += 1\n",
        "          net.eval()\n",
        "          validation_loss = 0.\n",
        "          for i, (data, labels) in enumerate(valid_dataloader):\n",
        "                data, labels = data.to(self.device), labels.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = net(data)\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_loss += loss.item()\n",
        "                validation_loss += loss.item()\n",
        "                total += labels.size(0)\n",
        "          if (validation_loss - min_validation_loss) < self.validation_config[\"min_delta\"]:\n",
        "            min_validation_loss = min(validation_loss, min_validation_loss)\n",
        "            early_stopping_counter = 0\n",
        "          else:\n",
        "            min_validation_loss = min(validation_loss, min_validation_loss)\n",
        "            early_stopping_counter += 1\n",
        "            if(early_stopping_counter > self.validation_config[\"patience\"]):\n",
        "              break\n",
        "\n",
        "      return running_loss / total\n",
        "  def _load_dataset(self, name: str) -> Dataset:\n",
        "        full_file: Path = self.partition_dir / str(self.cid)\n",
        "        return load_dataset(\n",
        "            mapping=full_file,\n",
        "            name=name,\n",
        "            data_dir=self.data_dir,\n",
        "        )"
      ],
      "metadata": {
        "id": "lUzBGAOopU-w"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(Seeds.DEFAULT)\n",
        "network_generator_cnn = get_network_generator_cnn()\n",
        "\n",
        "centralized_early_stopping_flower_client_generator: Callable[\n",
        "    [int], FlowerClient\n",
        "] = get_flower_client_generator(\n",
        "    model_generator=network_generator_cnn,\n",
        "    partition_dir=centralized_partition,\n",
        "    data_dir=data_dir,\n",
        "    client_class=FlowerEarlyStoppingClient,\n",
        "    validation_config = {\n",
        "        \"min_delta\": 0,\n",
        "        \"patience\": 5,\n",
        "        \"train_dataloader_ratio\": 0.95\n",
        "    }\n",
        ")\n",
        "centralized_train_config: dict[str, Any] = {\n",
        "    \"epochs\": 100,\n",
        "    \"batch_size\": 32,\n",
        "    \"optimizer\": \"adam\",\n",
        "    \"client_learning_rate\": 0.01,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"max_batches\": None,\n",
        "    \"num_workers\": 0\n",
        "}\n",
        "\n",
        "test_config: dict[str, Any] = {\n",
        "    \"batch_size\": 32,\n",
        "    \"num_workers\": 0,\n",
        "}\n",
        "\n",
        "federated_evaluation_function = get_federated_evaluation_function(\n",
        "    data_dir=data_dir,\n",
        "    centralized_mapping=centralized_mapping,\n",
        "    device=get_device(),\n",
        "    batch_size=test_config[\"batch_size\"],\n",
        "    num_workers=test_config[\"num_workers\"],\n",
        "    model_generator=network_generator_cnn,\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        ")\n",
        "\n",
        "centralized_early_stopping_flower_client = centralized_early_stopping_flower_client_generator(0)\n",
        "seed_net_cnn = network_generator_cnn()\n",
        "randomly_seeded_parameters = get_model_parameters(seed_net_cnn)\n",
        "\n",
        "trained_params, num_examples, train_metrics = fit_client_seeded(\n",
        "    centralized_early_stopping_flower_client,\n",
        "    params=randomly_seeded_parameters,\n",
        "    conf=centralized_train_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "aQ6ViCZr_anL",
        "outputId": "4f37476b-234f-4d9e-a8e6-5600be0a15d8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-29 01:05:58,684 | <ipython-input-56-ee17c45357c9>:65 | Reduced federated test_set size from 10000 to a size of 1500 mean index: 4924.406\n",
            "INFO:flwr:Reduced federated test_set size from 10000 to a size of 1500 mean index: 4924.406\n",
            "INFO flwr 2024-02-29 01:05:58,688 | <ipython-input-74-4978315838c4>:44 | Creating client with cid: 0\n",
            "INFO:flwr:Creating client with cid: 0\n",
            "  0%|          | 0/100 [00:13<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-dfff3b9cd93c>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mrandomly_seeded_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_net_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m trained_params, num_examples, train_metrics = fit_client_seeded(\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mcentralized_early_stopping_flower_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandomly_seeded_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-1969b300fbb2>\u001b[0m in \u001b[0;36mfit_client_seeded\u001b[0;34m(client, params, conf, seed)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/common/client.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, parameters, config)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_model_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-74-4978315838c4>\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, net, train_loader, config)\u001b[0m\n\u001b[1;32m    131\u001b[0m               \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m               \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-6fa9d6dae045>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \"\"\"\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# flatten all dimensions except batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLx7-YaNud_e"
      },
      "source": [
        "### 2.1 Feature distribution skew\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P25sgH4ZH2Xg"
      },
      "source": [
        "Statisticians and data scientists refer to this property as \"covariate shift”. It happens when different clients present samples which describe ideally the same objects having slightly different features. That is the case for two different writers hand-writing the same word, since these may have different stroke widths, slants, etc.\n",
        "What happens to an FL setting in which this property is strong is not always predictable. Ideally, the global model, obtained using FedAvg, will try to learn a shared representation between clients. This could be problematic since clients have different features to represent their data. We could simply expect that the same seed model trained separately on local clients may perform better than a global model obtained in an FL training.\n",
        "\n",
        "To see this property in our chosen dataset we will show two images for the same number taken from different clients.\n",
        "_NOTE: the choice of clients and samples in the following is not random, but suitably made to show you the property._\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQSu0BsBw_tO"
      },
      "outputs": [],
      "source": [
        "client_0_dataset: FEMNIST = FEMNIST(\n",
        "    mapping=federated_partition / \"0\", data_dir=data_dir, name=\"train\"\n",
        ")\n",
        "client_1000_dataset: FEMNIST = FEMNIST(\n",
        "    mapping=federated_partition / \"1000\", data_dir=data_dir, name=\"train\"\n",
        ")\n",
        "img_a, label_a = client_0_dataset[4]\n",
        "img_b, label_b = client_1000_dataset[0]\n",
        "\n",
        "log(INFO, f\"For client 0, sample 4 has label {label_a}\")\n",
        "log(INFO, f\"For client 1000, sample 0 has label {label_b}\")\n",
        "# display images\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(img_a)\n",
        "ax[1].imshow(img_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8BULdP73HYV"
      },
      "source": [
        "We can also compare the average values of all the features for all the samples of these clients having the label chosen. You can try to execute the cell below choosing different labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xS7S-xk07dQ"
      },
      "outputs": [],
      "source": [
        "label_chosen = 4\n",
        "features_0 = []\n",
        "for img, lbl in client_0_dataset:\n",
        "    if lbl == label_chosen:\n",
        "        features_0.append(np.asarray(img).flatten())\n",
        "\n",
        "features_1000 = []\n",
        "for img, lbl in client_1000_dataset:\n",
        "    if lbl == label_chosen:\n",
        "        features_1000.append(np.asarray(img).flatten())\n",
        "\n",
        "# display images\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow((np.sum(features_0, axis=0) / len(features_0)).reshape((28, 28)))\n",
        "ax[1].imshow((np.sum(features_1000, axis=0) / len(features_1000)).reshape((28, 28)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbPKX2SuWFcr"
      },
      "outputs": [],
      "source": [
        "label_chosen = 1\n",
        "features_0 = []\n",
        "for img, lbl in client_0_dataset:\n",
        "    if lbl == label_chosen:\n",
        "        features_0.append(np.asarray(img).flatten())\n",
        "\n",
        "features_1000 = []\n",
        "for img, lbl in client_1000_dataset:\n",
        "    if lbl == label_chosen:\n",
        "        features_1000.append(np.asarray(img).flatten())\n",
        "\n",
        "# display images\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow((np.sum(features_0, axis=0) / len(features_0)).reshape((28, 28)))\n",
        "ax[1].imshow((np.sum(features_1000, axis=0) / len(features_1000)).reshape((28, 28)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MbYTin-77BR"
      },
      "source": [
        "It is worth having a glance on what are the consequences of this property on an FL experiment. To do that we will re-use the code for training an FL client from the previous lab.\n",
        "\n",
        "The following cell is thus meant to import objects and methods you have already used in the previous lab. There's nothing new in the cell below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hb6M0AD4FdOP"
      },
      "outputs": [],
      "source": [
        "from common.client_utils import (\n",
        "    to_tensor_transform,\n",
        "    get_network_generator_mlp,\n",
        "    get_network_generator_cnn,\n",
        "    get_model_parameters,\n",
        "    get_federated_evaluation_function,\n",
        "    aggregate_weighted_average,\n",
        "    get_device,\n",
        ")\n",
        "from common.client import FlowerClient, get_flower_client_generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_hZ8ZKqAwsY"
      },
      "source": [
        "In order to show on a small scale what can happen to FL training setups where clients have feature distribution skew, we will now build two toy settings. We choose the most populated client---the one with the most samples in the federation. We will then construct a second version of this same client by artificially changing its features by inverting the underlying images--- transforming each image into its negative. Furthermore, we need a specific `get_flower_client_generator` able to invert the images of a specific client.\n",
        "\n",
        "In the following, we provide the relevant methods to do that. These methods are simplified taking advantage of the federation being composed of just two clients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y420LYKH_8BL"
      },
      "outputs": [],
      "source": [
        "def load_FEMNIST_inverted_dataset(mapping: Path, name: str) -> Dataset:\n",
        "    \"\"\"Load the filterd FEMNIST dataset given the mapping .csv file.\n",
        "\n",
        "    The relevant transforms are automatically applied.\n",
        "    Note that the last transform will invert images, getting their negative\n",
        "    representation.\n",
        "\n",
        "    Args:\n",
        "        mapping (Path): path to the mapping .csv file chosen.\n",
        "        name (str): name of the dataset to load, train or test.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Dataset: FEMNIST dataset object, ready to use.\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.functional.invert,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return FEMNIST(\n",
        "        mapping=mapping,\n",
        "        name=name,\n",
        "        data_dir=data_dir,\n",
        "        transform=transform,\n",
        "        target_transform=to_tensor_transform,\n",
        "    )\n",
        "\n",
        "\n",
        "# NOTE: We need the self to use this for replacing an internal of a class\n",
        "\n",
        "\n",
        "def _load_inverted_dataset(self, name: str) -> Dataset:\n",
        "    full_file: Path = self.partition_dir / str(self.cid)\n",
        "    return load_FEMNIST_inverted_dataset(mapping=full_file, name=name)\n",
        "\n",
        "\n",
        "def get_mod_flower_client_generator(\n",
        "    model_generator: Callable[[], Module],\n",
        "    data_dir: Path,\n",
        "    partition_dir: Path,\n",
        "    mapping_fn: Callable[[int], int] | None = None,\n",
        ") -> Callable[[str], FlowerClient]:\n",
        "    \"\"\"Wrap the function for the client instance generator.\n",
        "\n",
        "    This provides the client generator with a model generator function.\n",
        "    Also, the partition directory must be passed.\n",
        "    A mapping function could be used for filtering/ordering clients.\n",
        "    Note that the \"even\" clients here will have a modified `_load_dataset` function.\n",
        "    The new `_load_dataset` has been chosen to be the one inverting the images.\n",
        "\n",
        "    Args:\n",
        "        data_dir (Path): path to the dataset folder.\n",
        "        model_generator (Callable[[], Module]): model generator function.\n",
        "        partition_dir (Path): directory containing the partition.\n",
        "        mapping_fn (Optional[Callable[[int], int]]): function mapping sorted/filtered\n",
        "            ids to real cid.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Callable[[str], FlowerClient]: client instance.\n",
        "    \"\"\"\n",
        "\n",
        "    def client_fn(cid: str) -> FlowerClient:\n",
        "        \"\"\"Create a single client instance given the client id `cid`.\n",
        "\n",
        "        Args:\n",
        "            cid (str): client id, Flower requires this to of type str.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            FlowerClient: client instance.\n",
        "        \"\"\"\n",
        "        log(INFO, f\"Getting client with id {cid}\")\n",
        "        actual_cid = mapping_fn(int(cid)) if mapping_fn is not None else int(cid)\n",
        "        client = FlowerClient(\n",
        "            cid=actual_cid,\n",
        "            data_dir=data_dir,\n",
        "            partition_dir=partition_dir,\n",
        "            model_generator=model_generator,\n",
        "        )\n",
        "        # Pay attention to the following two lines\n",
        "        if int(cid) % 2 == 0:\n",
        "            client._load_dataset = _load_inverted_dataset.__get__(client, FlowerClient)\n",
        "        return client\n",
        "\n",
        "    return client_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6-ipEzaY8QY"
      },
      "source": [
        "We will now try to train separately the two clients generated this way. The mapping function will be provided to point both client IDs to the data of the most populated client.\n",
        "\n",
        "```python\n",
        "mapping_dict = {0: '178', 1: '178'}\n",
        "```\n",
        "\n",
        "_NOTE: you may want *to experiment \\_with \\_different\\_\\_ clients here*. After having completed the lab, feel free to try!_\n",
        "\n",
        "The following cell will set the relevant configuration for both training and testing of the client and its inverted version.\n",
        "\n",
        "> **IMPORTANT: The architecture used here is an MLP because it is affected by inversion of images. Also, note that we must seed the model parameters here.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_ZCNLJRZoah"
      },
      "outputs": [],
      "source": [
        "# Seed the model\n",
        "torch.manual_seed(Seeds.DEFAULT)\n",
        "network_generator_mlp = get_network_generator_mlp()\n",
        "seed_net_mlp = network_generator_mlp()\n",
        "seed_model_mlp_params: NDArrays = get_model_parameters(seed_net_mlp)\n",
        "# Set up config for both train and eval\n",
        "train_config: dict[str, Any] = {\n",
        "    \"epochs\": 8,\n",
        "    \"batch_size\": 32,\n",
        "    \"client_learning_rate\": 0.01,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": None,\n",
        "}\n",
        "test_config: dict[str, Any] = {\n",
        "    \"batch_size\": 32,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": None,\n",
        "}\n",
        "# Here is the mapping\n",
        "mapping_dict = {0: \"178\", 1: \"178\"}\n",
        "# NOTE: we are using here the `get_mod_flower_client_generator`\n",
        "federated_mod_flower_client_generator: Callable[\n",
        "    [int], FlowerClient\n",
        "] = get_mod_flower_client_generator(\n",
        "    model_generator=network_generator_mlp,\n",
        "    data_dir=data_dir,\n",
        "    partition_dir=federated_partition,\n",
        "    mapping_fn=lambda x: mapping_dict[x],\n",
        ")\n",
        "# NOTE: we are using here the `get_flower_client_generator`\n",
        "federated_flower_client_generator: Callable[\n",
        "    [int], FlowerClient\n",
        "] = get_flower_client_generator(\n",
        "    model_generator=network_generator_mlp,\n",
        "    data_dir=data_dir,\n",
        "    partition_dir=federated_partition,\n",
        "    mapping_fn=lambda x: mapping_dict[x],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLqrKFqtaIYh"
      },
      "source": [
        "Let's train separately the two versions of the client and then mutually evaluate their models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWYktaFiaH3d"
      },
      "outputs": [],
      "source": [
        "# Create clients\n",
        "client_0 = federated_mod_flower_client_generator(0)\n",
        "client_1 = federated_mod_flower_client_generator(1)\n",
        "# Fit client 0\n",
        "client_0_params, *rest = fit_client_seeded(\n",
        "    client_0, seed_model_mlp_params, train_config\n",
        ")\n",
        "log(INFO, f\"Results of fitting the seed model on client 0:\\n\\t{rest}\")\n",
        "# Evaluate client 0 on model trained on client 0\n",
        "client_0_res = client_0.evaluate(client_0_params, test_config)\n",
        "log(\n",
        "    INFO,\n",
        "    \"Results of model eval trained on client 0 on the test set of client 0:\\n\\t%s\",\n",
        "    client_0_res,\n",
        ")\n",
        "# Fit client 1\n",
        "client_1_params, *rest = fit_client_seeded(\n",
        "    client_1, seed_model_mlp_params, train_config\n",
        ")\n",
        "log(INFO, f\"Results of fitting the seed model on client 1:\\n\\t{rest}\")\n",
        "# Evaluate client 1 on model trained on client 1\n",
        "client_1_res = client_1.evaluate(client_1_params, test_config)\n",
        "log(\n",
        "    INFO,\n",
        "    \"Results of model eval trained on client 1 on the test set of client 1:\\n\\t%s\",\n",
        "    client_1_res,\n",
        ")\n",
        "# Evaluate client 0 on model trained on client 0\n",
        "client_0_res = client_0.evaluate(client_1_params, test_config)\n",
        "log(\n",
        "    INFO,\n",
        "    \"Results of model eval trained on client 1 on the test set of client 0:\\n\\t%s\",\n",
        "    client_0_res,\n",
        ")\n",
        "# Evaluate client 1 on model trained on client 1\n",
        "client_1_res = client_1.evaluate(client_0_params, test_config)\n",
        "log(\n",
        "    INFO,\n",
        "    \"Results of model eval trained on client 0 on the test set of client 1:\\n\\t%s\",\n",
        "    client_1_res,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2I9CswibRCb"
      },
      "source": [
        "In the following cell, we will set up all the relevant methods and parameters to run an FL simulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pEHYQedk8xW"
      },
      "outputs": [],
      "source": [
        "def _on_fit_config_fn(server_round: int) -> dict[str, Scalar]:\n",
        "    return train_config.update({\"server_round\": server_round})\n",
        "\n",
        "\n",
        "def _on_evaluate_config_fn(server_round: int) -> dict[str, Scalar]:\n",
        "    return test_config.update({\"server_round\": server_round})\n",
        "\n",
        "\n",
        "# NOTE: We don't need the `federated_evaluation_function`. We care about the\n",
        "# distributed accuracy, thus we skip centralised evaluation.\n",
        "strategy = FedAvg(\n",
        "    fraction_fit=sys.float_info.min,\n",
        "    fraction_evaluate=sys.float_info.min,\n",
        "    min_fit_clients=2,\n",
        "    min_evaluate_clients=2,\n",
        "    min_available_clients=2,\n",
        "    on_fit_config_fn=_on_fit_config_fn,\n",
        "    on_evaluate_config_fn=_on_evaluate_config_fn,\n",
        "    initial_parameters=ndarrays_to_parameters(seed_model_mlp_params),\n",
        "    accept_failures=False,\n",
        "    fit_metrics_aggregation_fn=aggregate_weighted_average,\n",
        "    evaluate_metrics_aggregation_fn=aggregate_weighted_average,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DZfkIkaYPME"
      },
      "source": [
        "**Question 1 (Part II ✅):**\n",
        "\n",
        "(You need to provide the answer with **code** and **plots** for this question. A short written argumentation is recommended.)\n",
        "\n",
        "1. Using the methods implemented so far, set up two FL settings composed of the clients above. One has both clients with their original dataset, and the other has one client with their features inverted. _(Hint: use `federated_flower_client_generator` for the first setting and `federated_mod_flower_client_generator` for the second setting)_\n",
        "2. Train the two settings generated at 1) for 5 rounds using `fl.simulation.start_simulation`. Set `num_clients=2` to use only client IDs in `[0,1]`. Use the `strategy` from the cell above.\n",
        "3. Take note of the evaluation metrics of both FL experiments that you have done. Compare the two using those metrics (plots are recommended). Briefly discuss the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mTgAc5yYVny"
      },
      "source": [
        "### 2.2 Label distribution skew\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE6yFy4sH79L"
      },
      "source": [
        "The flavour of data heterogeneity we are dealing with in this subsection is often called “prior probability shift\". In a few words, this occurs when, given a particular label, the distribution of samples having that label differs from client to client. In our running example, we can see whether in FEMNIST happens that different clients have drawn different distributions of symbols.\n",
        "We can think about what could happen to an FL training in this situation simplifying a bit the actors in a play. Let's imagine that the federation has a subset of clients (one client: client 0) that is the only one having a specific subset of labels (say letters). A global model trained using FedAvg on that federation won't ever be able to learn well the representation of that subset of labels (letters). There exist methods to mitigate this particular situation, but often they involve sharing statistics about local datasets, thus creating privacy concerns.\n",
        "\n",
        "We will select two clients, then we will plot the histogram of the labels for each of them on the same canvas. Thus, we will be able to evaluate whether there is a qualitative difference between the two.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CobK_i5-cwxI"
      },
      "outputs": [],
      "source": [
        "client_3000_dataset: FEMNIST = FEMNIST(\n",
        "    mapping=federated_partition / \"3000\", data_dir=data_dir, name=\"train\"\n",
        ")\n",
        "plt.hist(\n",
        "    [int(x[1]) for x in client_0_dataset],\n",
        "    bins=62,\n",
        "    color=\"blue\",\n",
        "    alpha=0.7,\n",
        "    label=\"client 0\",\n",
        ")\n",
        "plt.hist(\n",
        "    [int(x[1]) for x in client_3000_dataset],\n",
        "    bins=62,\n",
        "    color=\"orange\",\n",
        "    alpha=0.7,\n",
        "    label=\"client 3000\",\n",
        ")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ekusyXpeLy3"
      },
      "source": [
        "**Question 2 (Part II ✅ | Part III/MPhil ✅):**\n",
        "\n",
        "(These are meant to be conceptual questions. You should provide written answers for these. **No more than 3 sentences each**. **No code** is needed)\n",
        "\n",
        "1. If we ignore the privacy assumption of FL and allow the overall label distribution to be known, how could we balance the set of selected clients to guide the federated model towards a similar per-class accuracy that the centralised model can achieve? Assume FedAvg and the usual client implementation in your reasoning.\n",
        "2. Can you design an automatic data-driven procedure to mitigate label skew? Assume you are operating on a client level, keeping data private, and using standard FedAvg with random client selection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2\n",
        "\n",
        "1. If we knew the label distribution, we could simply select clients such that the distribution of labels among the selected clients is similar to the distribution of labels among all the clients, and the model updates averaged from these clients will yield similar per-class accuracy as centralized model due to similar class distributions.\n",
        "\n",
        "2. We could change the client selection to favour clients that have been selected less for training, for example by only sampling from clients that have not been selected yet, such that the data on each client contributes similarly to the global model."
      ],
      "metadata": {
        "id": "-NruO_sxY3o7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR7M2rpHJ5kO"
      },
      "source": [
        "### 2.3 Quantity skew\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amXbWzGcIACk"
      },
      "source": [
        "The last kind of heterogeneity we will discuss in detail is the _quantity skew_, which occurs when clients possess different numbers of samples. Last, but not least, it is the most investigated property that real FL datasets have. Also called “unbalancedness\", it has been tackled using many techniques spanning from data manipulation to optimization algorithm design. Even if the literature regarding such techniques is quite broad, relative to FL being a new topic of research, there is still not any agreement about how to deal with unbalancedness. Often different solutions have different accuracy depending on the task and how unbalanced the FL dataset is.\n",
        "\n",
        "Those of you that have well-trained observation skills may recall a plot in the last lab that spoiled this property. Now we'll try to get the global view of FEMNIST data from this perspective.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-bzX0KvhZ5z"
      },
      "outputs": [],
      "source": [
        "sns.histplot(\n",
        "    alpha=0.15,\n",
        "    legend=True,\n",
        "    data=[\n",
        "        len(\n",
        "            FEMNIST(\n",
        "                mapping=federated_partition / str(i), data_dir=data_dir, name=\"train\"\n",
        "            )\n",
        "        )\n",
        "        for i in range(3229)\n",
        "    ],\n",
        "    fill=True,\n",
        "    kde=True,\n",
        "    element=\"step\",\n",
        "    stat=\"density\",\n",
        "    common_norm=False,\n",
        "    common_bins=True,\n",
        "    cbar=True,\n",
        "    palette=\"dark\",\n",
        ")\n",
        "plt.xlabel(\"# samples\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCkfjXY1hX7D"
      },
      "source": [
        "**Question 3 (Part II ✅ | Part III/MPhil ✅):**\n",
        "\n",
        "(These are meant to be conceptual questions. You should provide written answers for these. **No more than 3 sentences each**. **No code** is needed)\n",
        "\n",
        "1. Given the skewness of number of samples held by each client plotted above, list one potential advantage and one potential disadvantage of training only clients with a number of samples close to the mean (e.g., within one $\\sigma$ of the mean).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3\n",
        "\n",
        "1. One advantage is that this effectively mitigates quantity skewness as all clients used for training have similar number of samples, a disadvantage is that it may amplify other types of skewness such as label distribution skewness as certain clients are never sampled."
      ],
      "metadata": {
        "id": "E0eYj0W9aI0M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFYZaMvAcaYV"
      },
      "source": [
        "# 3. The behaviour of FL under data heterogeneity/creating heterogeneous partitions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zemO_m5s2Bff"
      },
      "source": [
        "## FEMNIST folder structure\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsTGyV4ms_bm"
      },
      "source": [
        "By default, FEMNIST will be split as follows:\n",
        "\n",
        "- `femnist`: the location of the relevant data\n",
        "  - `client_data_mappings`: contains different partitions\n",
        "    - `centralized`: mappings from writer_id -> `[image_path, label]` for the centralized dataset\n",
        "    - `fed_natural`: mappings from writer_id -> `[image_path, label]` for the naturally federated dataset\n",
        "  - `data`: contains the macro partitions between test, train, and val\n",
        "    - `train`: contains the raw images---samples of the train set\n",
        "    - `test`: contains the raw images---samples of the test set\n",
        "    - `val`: contains the raw images---samples of the val set\n",
        "- `femnist.tar.gz`: the compressed dataset\n",
        "\n",
        "We will store client datasets in sequentially labelled folders within each partition and do all necessary remapping in python.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZjU-2dyrVxC",
        "outputId": "915e26b2-eb4c-4168-d745-92177f2cfdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34m./\u001b[0m\n",
            "├── \u001b[01;34mcommon\u001b[0m\n",
            "│   └── \u001b[01;34m__pycache__\u001b[0m\n",
            "├── \u001b[01;34mfemnist\u001b[0m\n",
            "│   ├── \u001b[01;34mclient_data_mappings\u001b[0m\n",
            "│   │   ├── \u001b[01;34mcentralized\u001b[0m\n",
            "│   │   └── \u001b[01;34mfed_natural\u001b[0m\n",
            "│   └── \u001b[01;34mdata\u001b[0m\n",
            "│       ├── \u001b[01;34mtest\u001b[0m\n",
            "│       ├── \u001b[01;34mtrain\u001b[0m\n",
            "│       └── \u001b[01;34mval\u001b[0m\n",
            "└── \u001b[01;34msample_data\u001b[0m\n",
            "\n",
            "11 directories\n"
          ]
        }
      ],
      "source": [
        "# Showing resulting folder tree\n",
        "! tree -dC -L 3 ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_QqLvPZ2Bff"
      },
      "source": [
        "## Test sets for FL\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhsBuoiOtDzE"
      },
      "source": [
        "Prior to constructing our centralized partition, it is necessary to discuss what a test set even means for FL.\n",
        "\n",
        "A testing set can generally be either a **federated test set** or a **local test set**:\n",
        "\n",
        "- A federated test set contains data representative of the entire federated network and is used to provide a form of centralized-like evaluation of the federated model. In production scenarios, this would be data that has been consensually gathered from a multitude of users and is legal/efficient to store on the server or clients which have been kept out of the training loop. For research purposes it can be constructed in one of the two following ways:\n",
        "  - Take x% of data from all clients and save it separately.\n",
        "  - Leave y% of clients utterly unavailable for federated training and use their data as a test/validation set. **This is the version we shall use during the lab for the federated test set.**\n",
        "- A local test set is formed via data from a specific client which has not been seen during training. There are as many local test sets as there are clients. As such, they can be used to test the model on a specific client or to accumulate average statistics to determine its performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEnNRUzntSHQ"
      },
      "source": [
        "## Creating and using partitions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XBPXfzPtkJe"
      },
      "source": [
        "### Class unbalancedness\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEzJSW4TvEmK"
      },
      "source": [
        "We will start creating class unbalanced partitions. The most representative example, as often happens, is the extreme one. Thus, we are going to create a partition of the dataset in which each client possesses one class only. This aim sets one parameter for the creation of the current partition, but we need to choose also another parameter: the number of clients we want to create or the number of samples per client that we want to infer. These last are two antagonist parameters that describe the same thing. The larger the number of clients is, the lower the number of samples per client is.\n",
        "\n",
        "Let's start by looking at how labels are distributed in the entire dataset (test set only), by treating the dataset as centralized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "yLEQJLkjwM4u",
        "outputId": "e3e3c24b-265d-4916-e320-0624d6785387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c8e5007a170>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1AAAAGsCAYAAADT1EZ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABemklEQVR4nO3de1hVZf7//xeie4MHIDROIyKlqaR4wMLdwcEkUcnRskbL0srD6AealEaNz88hD9PQWOYhTaepxBoZD/PJSi2VMDQTTyR5jCmHwhnZYAfZaQoK6/dHF+vrTtSNcub5uK511Vr3e6913xvcN+99r3XfboZhGAIAAAAAXFWT2q4AAAAAANQXJFAAAAAA4CISKAAAAABwEQkUAAAAALiIBAoAAAAAXEQCBQAAAAAuIoECAAAAABc1re0K1KaysjKdOHFCrVq1kpubW21XBwAaDcMw9OOPPyooKEhNmvBdXjn6JQCoPa72TY06gTpx4oSCg4NruxoA0GgdP35cbdu2re1q1Bn0SwBQ+67WNzXqBKpVq1aSfn6TvLy8ark2ANB4OBwOBQcHm5/D+Bn9EgDUHlf7pkadQJXfHuHl5UVHBQC1gNvUnNEvAUDtu1rfxI3nAAAAAOAiEigAAAAAcBEJFAAAAAC4qFE/A4XGqaysTCUlJbVdDaBBa9asmdzd3Wu7GkC9V1paqvPnz9d2NYAGoar6JhIoNColJSXKzc1VWVlZbVcFaPB8fHwUEBDARBHANTAMQ3a7XadOnartqgANSlX0TSRQaDQMw1B+fr7c3d0VHBzM4p1ANTEMQz/99JMKCwslSYGBgbVcI6D+KU+e/Pz81Lx5c76IAK5TVfZNJFBoNC5cuKCffvpJQUFBat68eW1XB2jQPD09JUmFhYXy8/Pjdj6gEkpLS83kqXXr1rVdHaDBqKq+ia/g0WiUlpZKkiwWSy3XBGgcyr+o4PkNoHLK/83wZR9Q9aqibyKBQqPDbRBAzeDfGnB9+DcEVL2q+HdFAgUAAAAALiKBAgAAAAAXMYkEGr0hQ2r2euvX1+z1aoObm5vWrVunYcOG6euvv1ZoaKj279+vHj16VMv1UlJSNHny5Bqb7jcjI0P9+vXTDz/8IB8fnzp/XgANSEYNd1pRDb/Tauh91vWqifekvmEECoDat2+vBQsWVMu5g4ODlZ+fr65du1bL+V3x9ddfy83NTdnZ2VVyvjvuuEP5+fny9vaukvNdj6ioKE2ePLnGr+vm5qZ33323xq8LAPRZ16YmP7cff/xxDRs2rEaudbHq/N24GCNQAFxSWloqNze3Sq+f5e7uroCAgGqqVdUqKSlxaZZGi8VSb9oEAI1RY+izUHsYgQLquLKyMs2dO1cdOnSQ1WpVu3bt9Pzzz5vlx48f129/+1v5+PjI19dXQ4cO1ddff22Wl38L9NJLLykwMFCtW7dWXFycOX1nVFSUvvnmG02ZMkVubm7m7DQpKSny8fHR+++/r7CwMFmtVuXl5Wnv3r2699571aZNG3l7e+vXv/61Pvvss8vW/5ffpD3++OPmdS7eMjIyJEnFxcX6wx/+oF/96ldq0aKFIiMjzbJyKSkpateunZo3b677779f33333RXfw9DQUElSz5495ebmpqioKKf35vnnn1dQUJA6deokSXr77bfVu3dvtWrVSgEBAXrkkUfMhfekn2+1c3NzM2+/KH+vNm/erC5duqhly5YaOHCg8vPzr1ivDz74QLfccos8PT3Vr18/p5+bJH333Xd6+OGH9atf/UrNmzdXt27d9I9//MMsf/zxx7Vt2zYtXLjQfB+//vprlZaWauzYsQoNDZWnp6c6deqkhQsXOp07IyNDt99+u1q0aCEfHx/deeed+uabb8zy9957T7169ZKHh4duuukmzZo1SxcuXJD08zd8knT//ffLzc3N3AcA+qzq67Mk6fXXX1eXLl3k4eGhzp0769VXXzXLSkpKFB8fr8DAQHl4eCgkJETJycmSKve5vWfPHvXs2VMeHh7q3bu39u/f71R+tT5m5syZWrFihd57771L3q/p06frlltuUfPmzXXTTTfpj3/8o9N04p9//rn69eunVq1aycvLSxEREdq3b59ZvmPHDt19993y9PRUcHCwfv/73+vMmTOSLv+7UR1IoIA6LjExUS+88IL++Mc/6siRI0pNTZW/v7+kn9cwiImJUatWrfTJJ5/o008/Nf94LykpMc/x8ccf69ixY/r444+1YsUKpaSkKCUlRZL0zjvvqG3btpo9e7by8/Od/uj/6aef9Je//EWvv/66Dh8+LD8/P/34448aM2aMduzYoV27dqljx44aPHiwfvzxR5fas3DhQvM6+fn5evrpp+Xn56fOnTtLkuLj45WZmalVq1bpwIEDeuihhzRw4EB9+eWXkqTdu3dr7Nixio+PV3Z2tvr166c//elPV7zmnj17JEkfffSR8vPz9c4775hl6enpysnJUVpamjZs2GC+r3PmzNHnn3+ud999V19//bUef/zxK17jp59+0ksvvaS3335b27dvV15env7whz9cNv748eN64IEHNGTIEGVnZ2vcuHF69tlnnWLOnTuniIgIbdy4UYcOHdKECRP02GOPme1ZuHChbDabxo8fb76fwcHBKisrU9u2bbV27VodOXJESUlJ+t///V+tWbNG0s+LSg8bNky//vWvdeDAAWVmZmrChAlmZ/PJJ59o9OjRevrpp3XkyBH99a9/VUpKivlH0N69eyVJy5cvV35+vrkPAPRZ1ddnrVy5UklJSXr++ed19OhR/fnPf9Yf//hHrVixQpK0aNEivf/++1qzZo1ycnK0cuVKM1Fy9XP79OnTuu+++xQWFqasrCzNnDnzkr7san3MH/7wB/32t781v0jMz8/XHXfcIUlq1aqVUlJSdOTIES1cuFB/+9vfNH/+fPPco0aNUtu2bbV3715lZWXp2WefVbNmzSRJx44d08CBAzV8+HAdOHBAq1ev1o4dOxQfHy/pyr8bVc5oxIqKigxJRlFRUZWe9777Lt1Q+86ePWscOXLEOHv2rNPxin5e1blVhsPhMKxWq/G3v/2twvK3337b6NSpk1FWVmYeKy4uNjw9PY3NmzcbhmEYY8aMMUJCQowLFy6YMQ899JAxYsQIcz8kJMSYP3++07mXL19uSDKys7OvWMfS0lKjVatWxvr1681jkox169YZhmEYubm5hiRj//79l7z2//7v/wwPDw9jx44dhmEYxjfffGO4u7sb//3vf53i+vfvbyQmJhqGYRgPP/ywMXjwYKfyESNGGN7e3pet4+XqMGbMGMPf398oLi6+Yhv37t1rSDJ+/PFHwzAM4+OPPzYkGT/88INhGP/vvfrqq6/M1yxZssTw9/e/7DkTExONsLAwp2PTp093Om9FYmNjjWeeecbc//Wvf208/fTTV6y/YRhGXFycMXz4cMMwDOO7774zJBkZGRkVxvbv39/485//7HTs7bffNgIDA839i3/Gl3O5f3OGUX2fv/Vdtb4vH9936YY66Ur/dir8OVbnVgn0WT+rrj7r5ptvNlJTU52OzZkzx7DZbIZhGMZTTz1l3HPPPU7v78Vc+dz+61//arRu3drpd2/p0qWXfU/KXdzHGMbPP8ehQ4de8VqGYRgvvviiERERYe63atXKSElJqTB27NixxoQJE5yOffLJJ0aTJk3M+lb0u/FLVdE38QwUUIcdPXpUxcXF6t+/f4Xln3/+ub766iu1atXK6fi5c+d07Ngxc//WW2+Vu7u7uR8YGKiDBw9e9foWi0Xh4eFOxwoKCjRjxgxlZGSosLBQpaWl+umnn5SXl1eZpmn//v167LHHtHjxYt15552SpIMHD6q0tFS33HKLU2xxcbFat24t6ef35P7773cqt9ls2rRpU6WuX65bt26XPPdU/q3b559/rh9++EFlZWWSpLy8PIWFhVV4nubNm+vmm2829wMDA51u+/ulo0ePKjIy8pJ2XKy0tFR//vOftWbNGv33v/9VSUmJiouLzVXUr2TJkiV68803lZeXp7Nnz6qkpMScPcnX11ePP/64YmJidO+99yo6Olq//e1vFRgYKOnn36tPP/3U6bab0tJSnTt3Tj/99JNL1wfQ+NBn/aw6+qwzZ87o2LFjGjt2rMaPH28ev3Dhgjmh0eOPP657771XnTp10sCBA3XfffdpwIABlbrO0aNHFR4eLg8PD6f6/tKV+pgrWb16tRYtWqRjx47p9OnTunDhgry8vMzyhIQEjRs3Tm+//baio6P10EMPmX3r559/rgMHDmjlypVmvGEYKisrU25urrp06VKptl4PEiigDvP09Lxi+enTpxUREeH0YVLuxhtvNP+/fPi7nJubm5kUXO36v7yHeMyYMfruu++0cOFChYSEyGq1ymazOd1+cTV2u12/+c1vNG7cOI0dO9apPe7u7srKynLqPCWpZcuWLp+/Mlq0aOG0f+bMGcXExCgmJkYrV67UjTfeqLy8PMXExFyxjRW9x4ZhXFfdXnzxRS1cuFALFixQt27d1KJFC02ePPmq7/WqVav0hz/8QfPmzZPNZlOrVq304osvavfu3WbM8uXL9fvf/16bNm3S6tWrNWPGDKWlpalPnz46ffq0Zs2apQceeOCSc1/cqQLAxeiz/p+q7rNOnz4tSfrb3/52yZdv5dfu1auXcnNz9eGHH+qjjz7Sb3/7W0VHR+uf//xnldbFlT6mIpmZmRo1apRmzZqlmJgYeXt7a9WqVZo3b54ZM3PmTD3yyCPauHGjPvzwQz333HNatWqV7r//fp0+fVq/+93v9Pvf//6Sc7dr165K23g1JFBAHdaxY0d5enoqPT1d48aNu6S8V69eWr16tfz8/Jy+waksi8Wi0tJSl2I//fRTvfrqqxo8eLCkn5/l+fbbb12+1rlz5zR06FB17txZL7/8slNZz549VVpaqsLCQt19990Vvr5Lly6XfEjv2rXritcsH2FypY1ffPGFvvvuO73wwgsKDg6WJKcHWKtKly5d9P777zsd+2U7Pv30Uw0dOlSPPvqopJ/vO//Xv/7lNApW0c/u008/1R133KH/+Z//MY9d/O1uuZ49e6pnz55KTEyUzWZTamqq+vTpo169eiknJ0cdOnS4bP2bNWvm8u8MgMaBPutSVdVn+fv7KygoSP/+9781atSoy77Wy8tLI0aM0IgRI/Tggw9q4MCB+v777+Xr6+vS53aXLl309ttv69y5c+YXZhX1TVfrYyr6Ge3cuVMhISH6//6//888dvHkReVuueUW3XLLLZoyZYoefvhhLV++XPfff7969eqlI0eOXLFvqszvxvVgEgmgDvPw8ND06dM1bdo0vfXWWzp27Jh27dqlN954Q9LPD1u2adNGQ4cO1SeffKLc3FxlZGTo97//vf7zn/+4fJ327dtr+/bt+u9//3vVjqVjx456++23dfToUe3evVujRo266reOF/vd736n48ePa9GiRTp58qTsdrvsdrtKSkp0yy23aNSoURo9erTeeecd5ebmas+ePUpOTtbGjRslyRw1eemll/Tll19q8eLFV70Vws/PT56entq0aZMKCgpUVFR02dh27drJYrHolVde0b///W+9//77mjNnjsvtc9XEiRP15ZdfaurUqcrJyVFqaqr5kHS5jh07Ki0tTTt37tTRo0f1u9/9TgUFBU4x7du31+7du/X111/r22+/VVlZmTp27Kh9+/Zp8+bN+te//qU//vGPTg8M5+bmKjExUZmZmfrmm2+0ZcsWffnll+btD0lJSXrrrbc0a9YsHT58WEePHtWqVas0Y8YMp+ump6fLbrfrhx9+qPL3pzq98MILcnNzc1o/69y5c4qLi1Pr1q3VsmVLDR8+/JL3Oi8vT7GxsWrevLn8/Pw0depUc2bCchkZGerVq5esVqs6dOhwyc8UaMjos6q3z5o1a5aSk5O1aNEi/etf/9LBgwe1fPlyM7F7+eWX9Y9//ENffPGF/vWvf2nt2rUKCAgwF2Z35XP7kUcekZubm8aPH68jR47ogw8+0EsvvXTJe3qlPqb8WgcOHFBOTo6+/fZbnT9/Xh07dlReXp5WrVqlY8eOadGiRVq3bp35mrNnzyo+Pl4ZGRn65ptv9Omnn2rv3r1m3zR9+nTt3LnTnJDjyy+/1HvvvWdOIlF+XVd/N67LFZ+QauCYRKJxueJDuXVYaWmp8ac//ckICQkxmjVrZrRr187pAf/8/Hxj9OjRRps2bQyr1WrcdNNNxvjx483f64oe5Hz66aeNX//61+Z+ZmamER4eblitVqP8Y2H58uUVPuT62WefGb179zY8PDyMjh07GmvXrr3koU1d4YHckJAQQ9Il28cff2wYhmGUlJQYSUlJRvv27Y1mzZoZgYGBxv33328cOHDAPP8bb7xhtG3b1vD09DSGDBlivPTSS1d8INcwDONvf/ubERwcbDRp0sRs++Ueck1NTTXat29vWK1Ww2azGe+//75TGyqaROKX11+3bp1xtY/Y9evXGx06dDCsVqtx9913G2+++abTeb/77jtj6NChRsuWLQ0/Pz9jxowZxujRo53qnJOTY/Tp08fw9PQ0JBm5ubnGuXPnjMcff9zw9vY2fHx8jEmTJhnPPvus0b17d8MwDMNutxvDhg0zAgMDDYvFYoSEhBhJSUlGaWmped5NmzYZd9xxh+Hp6Wl4eXkZt99+u/Haa6+Z5e+//77RoUMHo2nTpkZISEiF7auLk0js2bPHaN++vREeHu40+cbEiRON4OBgIz093di3b5/Rp08f44477jDLL1y4YHTt2tWIjo429u/fb3zwwQdGmzZtzAfFDcMw/v3vfxvNmzc3EhISjCNHjhivvPKK4e7ubmzatMnl+jGJBAyj/vZXhkGfVZ19lmEYxsqVK40ePXoYFovFuOGGG4y+ffsa77zzjmEYhvHaa68ZPXr0MFq0aGF4eXkZ/fv3Nz777DPzta58bpe/v927dzcsFovRo0cP4//+7/+c3pOr9TGGYRiFhYXGvffea7Rs2dLp/Zo6darRunVro2XLlsaIESOM+fPnm+9FcXGxMXLkSCM4ONiwWCxGUFCQER8f7/TvYM+ePeZ5W7RoYYSHhxvPP/+8U91/+bvxS1XRN7kZxnXepF+PORwOeXt7q6io6LqGkn9pyJBLj61fX2WnxzU6d+6ccnNzFRoaynMcQA240r+56vr8vZLTp0+rV69eevXVV/WnP/1JPXr00IIFC1RUVKQbb7xRqampevDBByX9fCtnly5dlJmZqT59+ujDDz/UfffdpxMnTphTMi9btkzTp0/XyZMnZbFYNH36dHPK+XIjR47UqVOnXH5gvFrfl4wKOqcoOqe6iP4KqD5V0TdV6ha+pUuXKjw8XF5eXvLy8pLNZtOHH35olkdFRV2y0NjEiROdzlFVt0AsWbJE7du3l4eHhyIjI8058wEAqEhcXJxiY2MVHR3tdDwrK0vnz593Ot65c2e1a9dOmZmZkn5++Llbt25m8iRJMTExcjgcOnz4sBnzy3PHxMSY56hIcXGxHA6H0wYAqNsqlUC1bdtWL7zwgrKysrRv3z7dc889Gjp0qNl5SHJa0DE/P19z5841y0pLSxUbG6uSkhLt3LnTXBwtKSnJjMnNzVVsbKz69eun7OxsTZ48WePGjdPmzZvNmNWrVyshIUHPPfecPvvsM3Xv3l0xMTFXnDIYANB4rVq1Sp999pmSk5MvKbPb7bJYLOZzAuX8/f1lt9vNmIuTp/Ly8rIrxTgcDp09e7bCeiUnJ8vb29vcyicuAQDUXZVKoIYMGaLBgwerY8eOuuWWW/T888+rZcuWTrNzNG/eXAEBAeZ28fDXli1bdOTIEf39739Xjx49NGjQIM2ZM0dLliwxp5NctmyZQkNDNW/ePHXp0kXx8fF68MEHnVYpfvnllzV+/Hg98cQTCgsL07Jly9S8eXO9+eab1/t+AAAamOPHj+vpp5/WypUr69ztUImJiSoqKjK348eP13aVAABXcc2z8JWWlmrVqlU6c+aM0wJbK1euVJs2bdS1a1clJibqp59+Msuq4haIkpISZWVlOcU0adJE0dHRV7xNQuJWCQBojLKyslRYWKhevXqpadOmatq0qbZt26ZFixapadOm8vf3V0lJiU6dOuX0uoKCAgUEBEiSAgICLpmVr3z/ajFeXl6XnfXLarWat8WXbwCAuq3S60AdPHhQNptN586dU8uWLbVu3TpzTZJHHnlEISEhCgoK0oEDBzR9+nTl5OTonXfekVQ1t0D88MMPKi0trTDmiy++uGLdk5OTNWvWrMo2GQ1MI543BahRrix8WRP69++vgwcPOh174okn1LlzZ02fPl3BwcFq1qyZ0tPTNXz4cElSTk6O8vLyzC8IbTabnn/+eRUWFsrPz0+SlJaWJi8vL7MPtNls+uCDD5yuk5aW5vQlI1AZdeXfENCQVMW/q0onUJ06dVJ2draKior0z3/+U2PGjNG2bdsUFhamCRMmmHHdunVTYGCg+vfvr2PHjunmm2++7sper8TERCUkJJj7DoeD+80bkWbNmsnNzU0nT57UjTfeeMlq5QCqhmEYKikp0cmTJ9WkSRNzUcja0qpVK3Xt2tXpWIsWLdS6dWvz+NixY5WQkCBfX195eXnpqaeeks1mU58+fSRJAwYMUFhYmB577DHNnTtXdrtdM2bMUFxcnKxWq6Sf1/ZavHixpk2bpieffFJbt27VmjVrzPVgAFdZLBY1adJEJ06c0I033iiLxUKfBVynquybKp1AWSwWcwXgiIgI7d27VwsXLtRf//rXS2IjIyMlSV999ZVuvvlmBQQEXDJbXmVvgXB3d5e7u3uFMeXnuByr1Wp2dGh83N3d1bZtW/3nP//R119/XdvVARq85s2bq127dmrSpO6v2T5//nw1adJEw4cPV3FxsWJiYvTqq6+a5e7u7tqwYYMmTZokm82mFi1aaMyYMZo9e7YZExoaqo0bN2rKlClauHCh2rZtq9dff10xMTG10STUY02aNFFoaKjy8/N14sSJ2q4O0KBURd9U6QTql8rKylRcXFxhWXZ2tiQpMDBQUtXcAmGxWBQREaH09HQNGzbMrEN6errTSsRARVq2bKmOHTvq/PnztV0VoEFzd3dX06ZN6+y35hkZGU77Hh4eWrJkiZYsWXLZ14SEhFzSP/1SVFSU9u/fXxVVRCNnsVjUrl07XbhwQaWlpbVdHaBBqKq+qVIJVGJiogYNGqR27drpxx9/VGpqqjIyMrR582YdO3ZMqampGjx4sFq3bq0DBw5oypQp6tu3r8LDwyVV3S0QCQkJGjNmjHr37q3bb79dCxYs0JkzZ/TEE09c15uBxqF8FBMAgLrMzc1NzZo1U7NmzWq7KgAuUqkEqrCwUKNHj1Z+fr68vb0VHh6uzZs3695779Xx48f10UcfmclMcHCwhg8frhkzZpivr6pbIEaMGKGTJ08qKSlJdrtdPXr00KZNmy6ZWAIAAAAAqpKb0YinJHM4HPL29lZRUVGVTh07ZMilx9avr7LTA0C9V12fv/Vdtb4vGRV0TlE10DlVdN2aujYAVIKrn8F1/8leAAAAAKgjSKAAAAAAwEUkUAAAAADgIhIoAAAAAHARCRQAAAAAuOi6F9JF3cIMgAAAAED1IYECAKCxutwU47/ElOMAYOIWPgAAAABwEQkUAAAAALiIBAoAAAAAXMQzUAAANCSuPtcEALgmjEABAAAAgIsYgapFTDkOAAAA1C+MQAEAAACAixiBAgAANa+iZ7VYbwpAPcAIFAAAAAC4iAQKAAAAAFxEAgUAAAAALuIZqOtU0Ux6AAAAABomEigAAFA1WMQXQCNAAlWPMfoFAAAA1CwSqBpCsgMAAADUfyRQAADgylizCQBMJFCNVEUjYuvpCwEAAIArIoFqBLh9EAAAAKgaJFAAAKBu4FZBAPUAC+kCAAAAgItIoAAAAADARdzCV8cwuQMAAABQdzECBQAAAAAuIoECAAAAABeRQAEAGrylS5cqPDxcXl5e8vLyks1m04cffmiWR0VFyc3NzWmbOHGi0zny8vIUGxur5s2by8/PT1OnTtWFCxecYjIyMtSrVy9ZrVZ16NBBKSkpNdE8AEAN4hkoAECD17ZtW73wwgvq2LGjDMPQihUrNHToUO3fv1+33nqrJGn8+PGaPXu2+ZrmzZub/19aWqrY2FgFBARo586dys/P1+jRo9WsWTP9+c9/liTl5uYqNjZWEydO1MqVK5Wenq5x48YpMDBQMTExNdtgAEC1IYECADR4Q34xQ8/zzz+vpUuXateuXWYC1bx5cwUEBFT4+i1btujIkSP66KOP5O/vrx49emjOnDmaPn26Zs6cKYvFomXLlik0NFTz5s2TJHXp0kU7duzQ/PnzL5tAFRcXq7i42Nx3OBxV0VwAQDXiFj4AQKNSWlqqVatW6cyZM7LZbObxlStXqk2bNuratasSExP1008/mWWZmZnq1q2b/P39zWMxMTFyOBw6fPiwGRMdHe10rZiYGGVmZl62LsnJyfL29ja34ODgqmomAKCaMAIFAGgUDh48KJvNpnPnzqlly5Zat26dwsLCJEmPPPKIQkJCFBQUpAMHDmj69OnKycnRO++8I0my2+1OyZMkc99ut18xxuFw6OzZs/L09LykTomJiUpISDD3HQ4HSRQA1HEkUACARqFTp07Kzs5WUVGR/vnPf2rMmDHatm2bwsLCNGHCBDOuW7duCgwMVP/+/XXs2DHdfPPN1VYnq9Uqq9VabecHAFQ9buEDADQKFotFHTp0UEREhJKTk9W9e3ctXLiwwtjIyEhJ0ldffSVJCggIUEFBgVNM+X75c1OXi/Hy8qpw9AkAUD8xAgUAaJTKysqcJnC4WHZ2tiQpMDBQkmSz2fT888+rsLBQfn5+kqS0tDR5eXmZtwHabDZ98MEHTudJS0tzes6qQckYcvUYAGiASKAAAA1eYmKiBg0apHbt2unHH39UamqqMjIytHnzZh07dkypqakaPHiwWrdurQMHDmjKlCnq27evwsPDJUkDBgxQWFiYHnvsMc2dO1d2u10zZsxQXFyceQvexIkTtXjxYk2bNk1PPvmktm7dqjVr1mjjxo212XQAQBWr1C18V1uI8Ny5c4qLi1Pr1q3VsmVLDR8+/JLbGapqIcIlS5aoffv28vDwUGRkpPbs2VOZpgAAGpHCwkKNHj1anTp1Uv/+/bV3715t3rxZ9957rywWiz766CMNGDBAnTt31jPPPKPhw4dr/fr15uvd3d21YcMGubu7y2az6dFHH9Xo0aOd1o0KDQ3Vxo0blZaWpu7du2vevHl6/fXXWQMKABqYSo1AXW0hwilTpmjjxo1au3atvL29FR8frwceeECffvqppKpbiHD16tVKSEjQsmXLFBkZqQULFigmJkY5OTnmrRUAAJR74403LlsWHBysbdu2XfUcISEhl9yi90tRUVHav39/pesHAKg/3AzDMK7nBL6+vnrxxRf14IMP6sYbb1RqaqoefPBBSdIXX3yhLl26KDMzU3369NGHH36o++67TydOnDCnel22bJmmT5+ukydPymKxaPr06dq4caMOHTpkXmPkyJE6deqUNm3aJOnnh3tvu+02LV68WNLP97EHBwfrqaee0rPPPnvZula0YGFwcLCKiork5eV1Te0fUgO3gF/0JWi1Xvty1wGAquZwOOTt7X1dn78NUZW8Lw3t2aQoOicANcPVz+BrnoXvlwsRZmVl6fz5806LCHbu3Fnt2rUzFxGsioUIS0pKlJWV5RTTpEkTRUdHX3GxQokFCwEAAABcn0onUAcPHlTLli1ltVo1ceJEcyFCu90ui8UiHx8fp3h/f/+rLjJYXnalmPKFCL/99luVlpZWGFN+jstJTExUUVGRuR0/fryyzQcAAADQiFV6Fr7LLURYH7BgIQAAAIDrUekEqnwhQkmKiIjQ3r17tXDhQo0YMUIlJSU6deqU0yhUQUGB0yKDv5wtr7ILEbq7u8vd3b3CmPJzAAAAAEB1uOZnoMqVL0QYERGhZs2aKT093SzLyclRXl6euYigzWbTwYMHVVhYaMZUtBDhxecojyk/h8ViUUREhFNMWVmZ0tPTG+5ihQAAAADqhEqNQF1pIUJvb2+NHTtWCQkJ8vX1lZeXl5566inZbDb16dNHUtUtRJiQkKAxY8aod+/euv3227VgwQKdOXNGTzzxRBW+NXVHTcz0BwAAAODqKpVAlS9EmJ+fL29vb4WHh5sLEUrS/Pnz1aRJEw0fPlzFxcWKiYnRq6++ar6+fCHCSZMmyWazqUWLFhozZkyFCxFOmTJFCxcuVNu2bS9ZiHDEiBE6efKkkpKSZLfb1aNHD23atOmSiSUAAAAAoCpd9zpQ9VlVrLfRkEaHWAcKQE1hHaiKsQ5UBVgHCkANqfZ1oAAAAACgsSGBAgAAAAAXkUABAAAAgItIoAAAAADARSRQAAAAAOAiEigAAAAAcBEJFAAAAAC4iAQKAAAAAFxEAgUAAAAALiKBAgAAAAAXkUABAAAAgItIoAAAAADARSRQAAAAAOAiEigAAAAAcBEJFAAAAAC4iAQKAAAAAFxEAgUAAAAALiKBAgAAAAAXkUABAAAAgItIoAAAAADARSRQAAAAAOAiEigAAAAAcBEJFAAAAAC4iAQKAAAAAFxEAgUAaPCWLl2q8PBweXl5ycvLSzabTR9++KFZfu7cOcXFxal169Zq2bKlhg8froKCAqdz5OXlKTY2Vs2bN5efn5+mTp2qCxcuOMVkZGSoV69eslqt6tChg1JSUmqieQCAGkQCBQBo8Nq2basXXnhBWVlZ2rdvn+655x4NHTpUhw8fliRNmTJF69ev19q1a7Vt2zadOHFCDzzwgPn60tJSxcbGqqSkRDt37tSKFSuUkpKipKQkMyY3N1exsbHq16+fsrOzNXnyZI0bN06bN2+u8fYCAKqPm2EYRm1XorY4HA55e3urqKhIXl5e13SOIUOquFK1aP362q4BgMaiKj5/r5evr69efPFFPfjgg7rxxhuVmpqqBx98UJL0xRdfqEuXLsrMzFSfPn304Ycf6r777tOJEyfk7+8vSVq2bJmmT5+ukydPymKxaPr06dq4caMOHTpkXmPkyJE6deqUNm3a5FKdquR9yWhAHZMkRdE5AagZrn4GMwIFAGhUSktLtWrVKp05c0Y2m01ZWVk6f/68oqOjzZjOnTurXbt2yszMlCRlZmaqW7duZvIkSTExMXI4HOYoVmZmptM5ymPKz1GR4uJiORwOpw0AULeRQAEAGoWDBw+qZcuWslqtmjhxotatW6ewsDDZ7XZZLBb5+Pg4xfv7+8tut0uS7Ha7U/JUXl5edqUYh8Ohs2fPVlin5ORkeXt7m1twcHBVNBUAUI1IoAAAjUKnTp2UnZ2t3bt3a9KkSRozZoyOHDlSq3VKTExUUVGRuR0/frxW6wMAuLqmtV0BAABqgsViUYcOHSRJERER2rt3rxYuXKgRI0aopKREp06dchqFKigoUEBAgCQpICBAe/bscTpf+Sx9F8f8cua+goICeXl5ydPTs8I6Wa1WWa3WKmkfAKBmMAIFAGiUysrKVFxcrIiICDVr1kzp6elmWU5OjvLy8mSz2SRJNptNBw8eVGFhoRmTlpYmLy8vhYWFmTEXn6M8pvwcAICGgREoAECDl5iYqEGDBqldu3b68ccflZqaqoyMDG3evFne3t4aO3asEhIS5OvrKy8vLz311FOy2Wzq06ePJGnAgAEKCwvTY489prlz58put2vGjBmKi4szR5AmTpyoxYsXa9q0aXryySe1detWrVmzRhs3bqzNpgMAqhgJFACgwSssLNTo0aOVn58vb29vhYeHa/Pmzbr33nslSfPnz1eTJk00fPhwFRcXKyYmRq+++qr5end3d23YsEGTJk2SzWZTixYtNGbMGM2ePduMCQ0N1caNGzVlyhQtXLhQbdu21euvv66YmJgaby8AoPqwDhTrQJlYBwpATakL60DVRawDVQHWgQJQQ1gHCgAAAACqGAkUAAAAALiIBAoAAAAAXEQCBQAAAAAuqlQClZycrNtuu02tWrWSn5+fhg0bppycHKeYqKgoubm5OW0TJ050isnLy1NsbKyaN28uPz8/TZ06VRcuXHCKycjIUK9evWS1WtWhQwelpKRcUp8lS5aoffv28vDwUGRk5CWLHAIAAABAVapUArVt2zbFxcVp165dSktL0/nz5zVgwACdOXPGKW78+PHKz883t7lz55plpaWlio2NVUlJiXbu3KkVK1YoJSVFSUlJZkxubq5iY2PVr18/ZWdna/LkyRo3bpw2b95sxqxevVoJCQl67rnn9Nlnn6l79+6KiYlxWuQQAAAAAKrSdU1jfvLkSfn5+Wnbtm3q27evpJ9HoHr06KEFCxZU+JoPP/xQ9913n06cOCF/f39J0rJlyzR9+nSdPHlSFotF06dP18aNG3Xo0CHzdSNHjtSpU6e0adMmSVJkZKRuu+02LV68WNLPK8oHBwfrqaee0rPPPutS/ZnG3BnTmAOoKUxjXjGmMa8A05gDqCE1Mo15UVGRJMnX19fp+MqVK9WmTRt17dpViYmJ+umnn8yyzMxMdevWzUyeJCkmJkYOh0OHDx82Y6Kjo53OGRMTo8zMTElSSUmJsrKynGKaNGmi6OhoM6YixcXFcjgcThsAAAAAuKrptb6wrKxMkydP1p133qmuXbuaxx955BGFhIQoKChIBw4c0PTp05WTk6N33nlHkmS3252SJ0nmvt1uv2KMw+HQ2bNn9cMPP6i0tLTCmC+++OKydU5OTtasWbOutckAAAAAGrlrTqDi4uJ06NAh7dixw+n4hAkTzP/v1q2bAgMD1b9/fx07dkw333zztde0CiQmJiohIcHcdzgcCg4OrsUaAQAAAKhPrimBio+P14YNG7R9+3a1bdv2irGRkZGSpK+++ko333yzAgICLpktr6CgQJIUEBBg/rf82MUxXl5e8vT0lLu7u9zd3SuMKT9HRaxWq6xWq2uNBAAAAIBfqNQzUIZhKD4+XuvWrdPWrVsVGhp61ddkZ2dLkgIDAyVJNptNBw8edJotLy0tTV5eXgoLCzNj0tPTnc6TlpYmm80mSbJYLIqIiHCKKSsrU3p6uhkDAAAAAFWtUiNQcXFxSk1N1XvvvadWrVqZzyx5e3vL09NTx44dU2pqqgYPHqzWrVvrwIEDmjJlivr27avw8HBJ0oABAxQWFqbHHntMc+fOld1u14wZMxQXF2eODk2cOFGLFy/WtGnT9OSTT2rr1q1as2aNNm7caNYlISFBY8aMUe/evXX77bdrwYIFOnPmjJ544omqem8AAAAAwEmlEqilS5dK+nmq8ostX75cjz/+uCwWiz766CMzmQkODtbw4cM1Y8YMM9bd3V0bNmzQpEmTZLPZ1KJFC40ZM0azZ882Y0JDQ7Vx40ZNmTJFCxcuVNu2bfX6668rJibGjBkxYoROnjyppKQk2e129ejRQ5s2bbpkYgkAAAAAqCrXtQ5Ufcc6UM5YBwpATWEdqIqxDlQFWAcKQA2pkXWgAAAAAKAxIYECAAAAABeRQAEAAACAi0igAAAAAMBFJFAAAAAA4KJKTWMOAACAOqSiWReZuRCoVoxAAQAAAICLSKAAAAAAwEUkUAAAAADgIhIoAAAAAHARCRQAAAAAuIgECgAAAABcRAIFAAAAAC4igQIAAAAAF5FAAQAAAICLSKAAAAAAwEUkUAAAAADgIhIoAAAAAHBR09quAAAAAFDrMoZceixqfc3XA3UeI1BAJQwZcukGoO5LTk7WbbfdplatWsnPz0/Dhg1TTk6OU0xUVJTc3NyctokTJzrF5OXlKTY2Vs2bN5efn5+mTp2qCxcuOMVkZGSoV69eslqt6tChg1JSUqq7eQCAGkQCBQBo8LZt26a4uDjt2rVLaWlpOn/+vAYMGKAzZ844xY0fP175+fnmNnfuXLOstLRUsbGxKikp0c6dO7VixQqlpKQoKSnJjMnNzVVsbKz69eun7OxsTZ48WePGjdPmzZtrrK0AgOrFLXwAgAZv06ZNTvspKSny8/NTVlaW+vbtax5v3ry5AgICKjzHli1bdOTIEX300Ufy9/dXjx49NGfOHE2fPl0zZ86UxWLRsmXLFBoaqnnz5kmSunTpoh07dmj+/PmKiYmpvgYCAGoMI1AAahy3QqK2FRUVSZJ8fX2djq9cuVJt2rRR165dlZiYqJ9++sksy8zMVLdu3eTv728ei4mJkcPh0OHDh82Y6Ohop3PGxMQoMzOzwnoUFxfL4XA4bQCAuo0RKABAo1JWVqbJkyfrzjvvVNeuXc3jjzzyiEJCQhQUFKQDBw5o+vTpysnJ0TvvvCNJstvtTsmTJHPfbrdfMcbhcOjs2bPy9PR0KktOTtasWbOqvI0AgOpDAgUAaFTi4uJ06NAh7dixw+n4hAkTzP/v1q2bAgMD1b9/fx07dkw333xztdQlMTFRCQkJ5r7D4VBwcHC1XAsAUDW4hQ8A0GjEx8drw4YN+vjjj9W2bdsrxkZGRkqSvvrqK0lSQECACgoKnGLK98ufm7pcjJeX1yWjT5JktVrl5eXltAEA6jYSKABAg2cYhuLj47Vu3Tpt3bpVoaGhV31Ndna2JCkwMFCSZLPZdPDgQRUWFpoxaWlp8vLyUlhYmBmTnp7udJ60tDTZbLYqagkAoLaRQAEAGry4uDj9/e9/V2pqqlq1aiW73S673a6zZ89Kko4dO6Y5c+YoKytLX3/9td5//32NHj1affv2VXh4uCRpwIABCgsL02OPPabPP/9cmzdv1owZMxQXFyer1SpJmjhxov79739r2rRp+uKLL/Tqq69qzZo1mjJlSq21HQBQtUigAAAN3tKlS1VUVKSoqCgFBgaa2+rVqyVJFotFH330kQYMGKDOnTvrmWee0fDhw7V+/XrzHO7u7tqwYYPc3d1ls9n06KOPavTo0Zo9e7YZExoaqo0bNyotLU3du3fXvHnz9PrrrzOFOQA0IEwiAQBo8AzDuGJ5cHCwtm3bdtXzhISE6IMPPrhiTFRUlPbv31+p+gEA6g9GoAAAAADARSRQAAAAAOAiEigAAAAAcBEJFAAAAAC4iAQKAAAAAFxEAgUAAAAALiKBAgAAAAAXkUABAAAAgItIoAAAAADARSRQAAAAAOCiSiVQycnJuu2229SqVSv5+flp2LBhysnJcYo5d+6c4uLi1Lp1a7Vs2VLDhw9XQUGBU0xeXp5iY2PVvHlz+fn5aerUqbpw4YJTTEZGhnr16iWr1aoOHTooJSXlkvosWbJE7du3l4eHhyIjI7Vnz57KNAcAAAAAKqVSCdS2bdsUFxenXbt2KS0tTefPn9eAAQN05swZM2bKlClav3691q5dq23btunEiRN64IEHzPLS0lLFxsaqpKREO3fu1IoVK5SSkqKkpCQzJjc3V7GxserXr5+ys7M1efJkjRs3Tps3bzZjVq9erYSEBD333HP67LPP1L17d8XExKiwsPB63g8AAAAAuKymlQnetGmT035KSor8/PyUlZWlvn37qqioSG+88YZSU1N1zz33SJKWL1+uLl26aNeuXerTp4+2bNmiI0eO6KOPPpK/v7969OihOXPmaPr06Zo5c6YsFouWLVum0NBQzZs3T5LUpUsX7dixQ/Pnz1dMTIwk6eWXX9b48eP1xBNPSJKWLVumjRs36s0339Szzz573W8MAAAAAPzSdT0DVVRUJEny9fWVJGVlZen8+fOKjo42Yzp37qx27dopMzNTkpSZmalu3brJ39/fjImJiZHD4dDhw4fNmIvPUR5Tfo6SkhJlZWU5xTRp0kTR0dFmTEWKi4vlcDicNgAAAABw1TUnUGVlZZo8ebLuvPNOde3aVZJkt9tlsVjk4+PjFOvv7y+73W7GXJw8lZeXl10pxuFw6OzZs/r2229VWlpaYUz5OSqSnJwsb29vcwsODq58wwEAAAA0WtecQMXFxenQoUNatWpVVdanWiUmJqqoqMjcjh8/XttVAgAAAFCPVOoZqHLx8fHasGGDtm/frrZt25rHAwICVFJSolOnTjmNQhUUFCggIMCM+eVseeWz9F0c88uZ+woKCuTl5SVPT0+5u7vL3d29wpjyc1TEarXKarVWvsEAAAAAoEqOQBmGofj4eK1bt05bt25VaGioU3lERISaNWum9PR081hOTo7y8vJks9kkSTabTQcPHnSaLS8tLU1eXl4KCwszYy4+R3lM+TksFosiIiKcYsrKypSenm7GAAAAAEBVq9QIVFxcnFJTU/Xee++pVatW5vNG3t7e8vT0lLe3t8aOHauEhAT5+vrKy8tLTz31lGw2m/r06SNJGjBggMLCwvTYY49p7ty5stvtmjFjhuLi4szRoYkTJ2rx4sWaNm2annzySW3dulVr1qzRxo0bzbokJCRozJgx6t27t26//XYtWLBAZ86cMWflAwAAAICqVqkEaunSpZKkqKgop+PLly/X448/LkmaP3++mjRpouHDh6u4uFgxMTF69dVXzVh3d3dt2LBBkyZNks1mU4sWLTRmzBjNnj3bjAkNDdXGjRs1ZcoULVy4UG3bttXrr79uTmEuSSNGjNDJkyeVlJQku92uHj16aNOmTZdMLAEAAAAAVaVSCZRhGFeN8fDw0JIlS7RkyZLLxoSEhOiDDz644nmioqK0f//+K8bEx8crPj7+qnUCAAAAgKpwXetAAQAAAEBjQgIFAAAAAC4igQIAAAAAF5FAAQAAAICLSKAAAAAAwEWVmoUPAAAADVzGkEuPRa2v+XoAdRQJFFCLhlTQR62njwIAAKizuIUPAAAAAFxEAgUAAAAALiKBAgAAAAAXkUABAAAAgItIoAAAAADARSRQAAAAAOAiEigAQIOXnJys2267Ta1atZKfn5+GDRumnJwcp5hz584pLi5OrVu3VsuWLTV8+HAVFBQ4xeTl5Sk2NlbNmzeXn5+fpk6dqgsXLjjFZGRkqFevXrJarerQoYNSUlKqu3kAgBpEAgUAaPC2bdumuLg47dq1S2lpaTp//rwGDBigM2fOmDFTpkzR+vXrtXbtWm3btk0nTpzQAw88YJaXlpYqNjZWJSUl2rlzp1asWKGUlBQlJSWZMbm5uYqNjVW/fv2UnZ2tyZMna9y4cdq8eXONthcAUH1YSBcA0OBt2rTJaT8lJUV+fn7KyspS3759VVRUpDfeeEOpqam65557JEnLly9Xly5dtGvXLvXp00dbtmzRkSNH9NFHH8nf3189evTQnDlzNH36dM2cOVMWi0XLli1TaGio5s2bJ0nq0qWLduzYofnz5ysmJqbG2w0AqHqMQAEAGp2ioiJJkq+vryQpKytL58+fV3R0tBnTuXNntWvXTpmZmZKkzMxMdevWTf7+/mZMTEyMHA6HDh8+bMZcfI7ymPJz/FJxcbEcDofTBgCo20igAACNSllZmSZPnqw777xTXbt2lSTZ7XZZLBb5+Pg4xfr7+8tut5sxFydP5eXlZVeKcTgcOnv27CV1SU5Olre3t7kFBwdXSRsBANWHBAoA0KjExcXp0KFDWrVqVW1XRYmJiSoqKjK348eP13aVAABXwTNQAIBGIz4+Xhs2bND27dvVtm1b83hAQIBKSkp06tQpp1GogoICBQQEmDF79uxxOl/5LH0Xx/xy5r6CggJ5eXnJ09PzkvpYrVZZrdYqaRsAoGYwAgUAaPAMw1B8fLzWrVunrVu3KjQ01Kk8IiJCzZo1U3p6unksJydHeXl5stlskiSbzaaDBw+qsLDQjElLS5OXl5fCwsLMmIvPUR5Tfg4AQP3HCBQAoMGLi4tTamqq3nvvPbVq1cp8Zsnb21uenp7y9vbW2LFjlZCQIF9fX3l5eempp56SzWZTnz59JEkDBgxQWFiYHnvsMc2dO1d2u10zZsxQXFycOYo0ceJELV68WNOmTdOTTz6prVu3as2aNdq4cWOttR0AULUYgQIANHhLly5VUVGRoqKiFBgYaG6rV682Y+bPn6/77rtPw4cPV9++fRUQEKB33nnHLHd3d9eGDRvk7u4um82mRx99VKNHj9bs2bPNmNDQUG3cuFFpaWnq3r275s2bp9dff50pzAGgAWEECgDQ4BmGcdUYDw8PLVmyREuWLLlsTEhIiD744IMrnicqKkr79++vdB0BAPUDI1AAAAAA4CISKAAAAABwEQkUAAAAALiIZ6AAoJ4YMuTSY+vX13w9AABozBiBAgAAAAAXkUABAAAAgItIoAAAAADARSRQAAAAAOAiEigAAAAAcBGz8AEAAACovIwKpoeVpKiGPUUsI1AAAAAA4CISKAAAAABwEQkUAAAAALiIBAoAAAAAXEQCBQAAAAAuIoECAAAAABdVOoHavn27hgwZoqCgILm5uendd991Kn/88cfl5ubmtA0cONAp5vvvv9eoUaPk5eUlHx8fjR07VqdPn3aKOXDggO6++255eHgoODhYc+fOvaQua9euVefOneXh4aFu3brpgw8+qGxzAAAAAMBllU6gzpw5o+7du2vJkiWXjRk4cKDy8/PN7R//+IdT+ahRo3T48GGlpaVpw4YN2r59uyZMmGCWOxwODRgwQCEhIcrKytKLL76omTNn6rXXXjNjdu7cqYcfflhjx47V/v37NWzYMA0bNkyHDh2qbJMAAAAAwCWVXkh30KBBGjRo0BVjrFarAgICKiw7evSoNm3apL1796p3796SpFdeeUWDBw/WSy+9pKCgIK1cuVIlJSV68803ZbFYdOuttyo7O1svv/yymWgtXLhQAwcO1NSpUyVJc+bMUVpamhYvXqxly5ZVtlkAAAAAcFXV8gxURkaG/Pz81KlTJ02aNEnfffedWZaZmSkfHx8zeZKk6OhoNWnSRLt37zZj+vbtK4vFYsbExMQoJydHP/zwgxkTHR3tdN2YmBhlZmZetl7FxcVyOBxOGwAAAAC4qsoTqIEDB+qtt95Senq6/vKXv2jbtm0aNGiQSktLJUl2u11+fn5Or2natKl8fX1lt9vNGH9/f6eY8v2rxZSXVyQ5OVne3t7mFhwcfH2NBQAAANCoVPoWvqsZOXKk+f/dunVTeHi4br75ZmVkZKh///5VfblKSUxMVEJCgrnvcDhIogAAAAC4rNqnMb/pppvUpk0bffXVV5KkgIAAFRYWOsVcuHBB33//vfncVEBAgAoKCpxiyvevFnO5Z6+kn5/N8vLyctoAAAAAwFXVnkD95z//0XfffafAwEBJks1m06lTp5SVlWXGbN26VWVlZYqMjDRjtm/frvPnz5sxaWlp6tSpk2644QYzJj093elaaWlpstls1d0kAAAAAI1UpROo06dPKzs7W9nZ2ZKk3NxcZWdnKy8vT6dPn9bUqVO1a9cuff3110pPT9fQoUPVoUMHxcTESJK6dOmigQMHavz48dqzZ48+/fRTxcfHa+TIkQoKCpIkPfLII7JYLBo7dqwOHz6s1atXa+HChU633z399NPatGmT5s2bpy+++EIzZ87Uvn37FB8fXwVvCwAAAABcqtIJ1L59+9SzZ0/17NlTkpSQkKCePXsqKSlJ7u7uOnDggH7zm9/olltu0dixYxUREaFPPvlEVqvVPMfKlSvVuXNn9e/fX4MHD9Zdd93ltMaTt7e3tmzZotzcXEVEROiZZ55RUlKS01pRd9xxh1JTU/Xaa6+pe/fu+uc//6l3331XXbt2vZ73AwAAAAAuq9KTSERFRckwjMuWb968+arn8PX1VWpq6hVjwsPD9cknn1wx5qGHHtJDDz101esBAAAAQFWo9megAAAAAKChIIECAAAAABeRQAEAAACAi0igAAAAAMBFJFAAAAAA4CISKAAAAABwEQkUAAAAALiIBAoA0OBt375dQ4YMUVBQkNzc3PTuu+86lT/++ONyc3Nz2gYOHOgU8/3332vUqFHy8vKSj4+Pxo4dq9OnTzvFHDhwQHfffbc8PDwUHBysuXPnVnfTAAA1jAQKANDgnTlzRt27d9eSJUsuGzNw4EDl5+eb2z/+8Q+n8lGjRunw4cNKS0vThg0btH37dk2YMMEsdzgcGjBggEJCQpSVlaUXX3xRM2fO1GuvvVZt7QIA1LymtV0BAACq26BBgzRo0KArxlitVgUEBFRYdvToUW3atEl79+5V7969JUmvvPKKBg8erJdeeklBQUFauXKlSkpK9Oabb8pisejWW29Vdna2Xn75ZadECwBQvzECBQCApIyMDPn5+alTp06aNGmSvvvuO7MsMzNTPj4+ZvIkSdHR0WrSpIl2795txvTt21cWi8WMiYmJUU5Ojn744YcKr1lcXCyHw+G0AUCtyxhy6QYTCRQAoNEbOHCg3nrrLaWnp+svf/mLtm3bpkGDBqm0tFSSZLfb5efn5/Sapk2bytfXV3a73Yzx9/d3iinfL4/5peTkZHl7e5tbcHBwVTcNAFDFuIUPANDojRw50vz/bt26KTw8XDfffLMyMjLUv3//artuYmKiEhISzH2Hw0ESBeBnFY36RK2v+XrgEoxAAQDwCzfddJPatGmjr776SpIUEBCgwsJCp5gLFy7o+++/N5+bCggIUEFBgVNM+f7lnq2yWq3y8vJy2gAAdRsJFAAAv/Cf//xH3333nQIDAyVJNptNp06dUlZWlhmzdetWlZWVKTIy0ozZvn27zp8/b8akpaWpU6dOuuGGG2q2AQCAasMtfAAavSGXeTZ2fQ3cKVGb125MTp8+bY4mSVJubq6ys7Pl6+srX19fzZo1S8OHD1dAQICOHTumadOmqUOHDoqJiZEkdenSRQMHDtT48eO1bNkynT9/XvHx8Ro5cqSCgoIkSY888ohmzZqlsWPHavr06Tp06JAWLlyo+fPn10qbAQDVgxEoAECDt2/fPvXs2VM9e/aUJCUkJKhnz55KSkqSu7u7Dhw4oN/85je65ZZbNHbsWEVEROiTTz6R1Wo1z7Fy5Up17txZ/fv31+DBg3XXXXc5rfHk7e2tLVu2KDc3VxEREXrmmWeUlJTEFOYA0MAwAgUAaPCioqJkGMZlyzdv3nzVc/j6+io1NfWKMeHh4frkk08qXT8AQP3BCBQAAAAAuIgECgAAAABcRAIFAAAAAC4igQIAAAAAF5FAAQAAAICLSKAAAAAAwEUkUAAAAADgIhIoAAAAAHARCRQAAAAAuIgECgAAAABcRAIFAAAAAC5qWtsVAAAAQD2UMeTSY1Hra74eQA0jgQLqiSEV9FPr6acAAABqFLfwAQAAAICLSKAAAAAAwEUkUAAAAADgIp6BAgAAuB5MpgA0KiRQqHeYTAEAAAC1hVv4AAAAAMBFjEABAAAA9VVFt5BK3EZajRiBAgAAAAAXkUABAAAAgIsqnUBt375dQ4YMUVBQkNzc3PTuu+86lRuGoaSkJAUGBsrT01PR0dH68ssvnWK+//57jRo1Sl5eXvLx8dHYsWN1+vRpp5gDBw7o7rvvloeHh4KDgzV37txL6rJ27Vp17txZHh4e6tatmz744IPKNgcAKmXIkEs3AADQeFQ6gTpz5oy6d++uJUuWVFg+d+5cLVq0SMuWLdPu3bvVokULxcTE6Ny5c2bMqFGjdPjwYaWlpWnDhg3avn27JkyYYJY7HA4NGDBAISEhysrK0osvvqiZM2fqtddeM2N27typhx9+WGPHjtX+/fs1bNgwDRs2TIcOHapskwAAAADAJZWeRGLQoEEaNGhQhWWGYWjBggWaMWOGhg4dKkl666235O/vr3fffVcjR47U0aNHtWnTJu3du1e9e/eWJL3yyisaPHiwXnrpJQUFBWnlypUqKSnRm2++KYvFoltvvVXZ2dl6+eWXzURr4cKFGjhwoKZOnSpJmjNnjtLS0rR48WItW7bsmt4MAAAAALiSKn0GKjc3V3a7XdHR0eYxb29vRUZGKjMzU5KUmZkpHx8fM3mSpOjoaDVp0kS7d+82Y/r27SuLxWLGxMTEKCcnRz/88IMZc/F1ymPKr1OR4uJiORwOpw0AAAAAXFWlCZTdbpck+fv7Ox339/c3y+x2u/z8/JzKmzZtKl9fX6eYis5x8TUuF1NeXpHk5GR5e3ubW3BwcGWbCAAAAKARa1Sz8CUmJqqoqMjcjh8/XttVAgAAAFCPVGkCFRAQIEkqKChwOl5QUGCWBQQEqLCw0Kn8woUL+v77751iKjrHxde4XEx5eUWsVqu8vLycNgAAAABwVZUmUKGhoQoICFB6erp5zOFwaPfu3bLZbJIkm82mU6dOKSsry4zZunWrysrKFBkZacZs375d58+fN2PS0tLUqVMn3XDDDWbMxdcpjym/DgAAAABUtUonUKdPn1Z2drays7Ml/TxxRHZ2tvLy8uTm5qbJkyfrT3/6k95//30dPHhQo0ePVlBQkIYNGyZJ6tKliwYOHKjx48drz549+vTTTxUfH6+RI0cqKChIkvTII4/IYrFo7NixOnz4sFavXq2FCxcqISHBrMfTTz+tTZs2ad68efriiy80c+ZM7du3T/Hx8df/rgAAAABABSo9jfm+ffvUr18/c788qRkzZoxSUlI0bdo0nTlzRhMmTNCpU6d01113adOmTfLw8DBfs3LlSsXHx6t///5q0qSJhg8frkWLFpnl3t7e2rJli+Li4hQREaE2bdooKSnJaa2oO+64Q6mpqZoxY4b+93//Vx07dtS7776rrl27XtMbAQAAgEYig1XQce0qnUBFRUXJMIzLlru5uWn27NmaPXv2ZWN8fX2Vmpp6xeuEh4frk08+uWLMQw89pIceeujKFQYAAACAKlLpBAoAKmMIX/IBAIAGpFFNYw7g2gwZcukG1Cfbt2/XkCFDFBQUJDc3N7377rtO5YZhKCkpSYGBgfL09FR0dLS+/PJLp5jvv/9eo0aNkpeXl3x8fDR27FidPn3aKebAgQO6++675eHhoeDgYM2dO7e6m4ZyGUMu3QCgGjAChWtS0R/Q69fXfD0AwBVnzpxR9+7d9eSTT+qBBx64pHzu3LlatGiRVqxYodDQUP3xj39UTEyMjhw5Yj7DO2rUKOXn5ystLU3nz5/XE088oQkTJpi3pDscDg0YMEDR0dFatmyZDh48qCeffFI+Pj5Oz/ACqAIVJchR/CGCmkECBQBo8AYNGqRBgwZVWGYYhhYsWKAZM2Zo6NChkqS33npL/v7+evfddzVy5EgdPXpUmzZt0t69e9W7d29J0iuvvKLBgwfrpZdeUlBQkFauXKmSkhK9+eabslgsuvXWW5Wdna2XX36ZBAoAGhASKKCO4fY4oGbl5ubKbrcrOjraPObt7a3IyEhlZmZq5MiRyszMlI+Pj5k8SVJ0dLSaNGmi3bt36/7771dmZqb69u0ri8VixsTExOgvf/mLfvjhB3Mdw4sVFxeruLjY3Hc4HNXUSuA6cUskYOIZKABAo2a32yVJ/v7+Tsf9/f3NMrvdLj8/P6fypk2bytfX1ymmonNcfI1fSk5Olre3t7kFBwdff4MAANWKBAoAgFqSmJiooqIiczt+/HhtVwkAcBXcwgcAaNQCAgIkSQUFBQoMDDSPFxQUqEePHmZMYWGh0+suXLig77//3nx9QECACgoKnGLK98tjfslqtcpqtVZJO3CdmJQAgIsYgQIANGqhoaEKCAhQenq6eczhcGj37t2y2WySJJvNplOnTikrK8uM2bp1q8rKyhQZGWnGbN++XefPnzdj0tLS1KlTpwqffwIA1E8kUACABu/06dPKzs5Wdna2pJ8njsjOzlZeXp7c3Nw0efJk/elPf9L777+vgwcPavTo0QoKCtKwYcMkSV26dNHAgQM1fvx47dmzR59++qni4+M1cuRIBQUFSZIeeeQRWSwWjR07VocPH9bq1au1cOFCJSQk1FKrAQDVgVv4UONYQwpATdu3b5/69etn7pcnNWPGjFFKSoqmTZumM2fOaMKECTp16pTuuusubdq0yVwDSpJWrlyp+Ph49e/fX02aNNHw4cO1aNEis9zb21tbtmxRXFycIiIi1KZNGyUlJTGFOa4NtxQCdRYJFBo9Ejqg4YuKipJhGJctd3Nz0+zZszV79uzLxvj6+pqL5l5OeHi4Pvnkk2uuJwCg7iOBAlDvkPQCAIDaQgIFAAAAXI/LLTTMbZcNEpNIAAAAAICLSKAAAAAAwEUkUAAAAADgIp6BAq4TExoAAOoUnscBqhUjUAAAAADgIkaggApUNKoEAAAAkEABAADUB5e7NQ9AjeIWPgAAAABwEQkUAAAAALiIBAoAAAAAXEQCBQAAAAAuIoECAAAAABeRQAEAAACAi0igAAAAAMBFJFAAAAAA4CISKAAAAABwEQkUAAAAALiIBAoAAAAAXEQCBQAAAAAuIoECAAAAABc1re0KoO4YMuTSY+vX13w9AAAAgLqKESgAAAAAcBEJFAAAAAC4iFv4AABA3ZVRwf3lUdxfDqD2MAIFAAAAAC4igQIAAAAAF1V5AjVz5ky5ubk5bZ07dzbLz507p7i4OLVu3VotW7bU8OHDVVBQ4HSOvLw8xcbGqnnz5vLz89PUqVN14cIFp5iMjAz16tVLVqtVHTp0UEpKSlU3BQAAAACcVMsI1K233qr8/Hxz27Fjh1k2ZcoUrV+/XmvXrtW2bdt04sQJPfDAA2Z5aWmpYmNjVVJSop07d2rFihVKSUlRUlKSGZObm6vY2Fj169dP2dnZmjx5ssaNG6fNmzdXR3MAAAAAQFI1TSLRtGlTBQQEXHK8qKhIb7zxhlJTU3XPPfdIkpYvX64uXbpo165d6tOnj7Zs2aIjR47oo48+kr+/v3r06KE5c+Zo+vTpmjlzpiwWi5YtW6bQ0FDNmzdPktSlSxft2LFD8+fPV0xMzGXrVVxcrOLiYnPf4XBUccsBAAAANGTVMgL15ZdfKigoSDfddJNGjRqlvLw8SVJWVpbOnz+v6OhoM7Zz585q166dMjMzJUmZmZnq1q2b/P39zZiYmBg5HA4dPnzYjLn4HOUx5ee4nOTkZHl7e5tbcHBwlbQXAAAAQONQ5SNQkZGRSklJUadOnZSfn69Zs2bp7rvv1qFDh2S322WxWOTj4+P0Gn9/f9ntdkmS3W53Sp7Ky8vLrhTjcDh09uxZeXp6Vli3xMREJSQkmPsOh4MkCgAAoCGoaMp7iWnvUeWqPIEaNGiQ+f/h4eGKjIxUSEiI1qxZc9nEpqZYrVZZrdZarQMAAACA+qvapzH38fHRLbfcoq+++koBAQEqKSnRqVOnnGIKCgrMZ6YCAgIumZWvfP9qMV5eXrWepAGNxZAhl25AfVVTM8gCFcoYcukGoM6q9gTq9OnTOnbsmAIDAxUREaFmzZopPT3dLM/JyVFeXp5sNpskyWaz6eDBgyosLDRj0tLS5OXlpbCwMDPm4nOUx5SfAwCAyqruGWQBuIBkEvVAld/C94c//EFDhgxRSEiITpw4oeeee07u7u56+OGH5e3trbFjxyohIUG+vr7y8vLSU089JZvNpj59+kiSBgwYoLCwMD322GOaO3eu7Ha7ZsyYobi4OPP2u4kTJ2rx4sWaNm2annzySW3dulVr1qzRxo0bq7o5aGAYJQFwOdU9g2xFmB22lvBHOYDrUOUjUP/5z3/08MMPq1OnTvrtb3+r1q1ba9euXbrxxhslSfPnz9d9992n4cOHq2/fvgoICNA777xjvt7d3V0bNmyQu7u7bDabHn30UY0ePVqzZ882Y0JDQ7Vx40alpaWpe/fumjdvnl5//fUrTmGO2sFtXgDqi+qeQbYizA4LAPVPlY9ArVq16orlHh4eWrJkiZYsWXLZmJCQEH3wwQdXPE9UVJT2799/TXUEakNNJY8VXWd9BRMQuRoHNAY1MYNsRZgdFg0OM+GhEaiWhXQB1AxG9ICqUVszyDI7bDXjVr2r4z0CKo0EClWGP+YBNBQXzyB77733mjPIXjwK9csZZPfs2eN0jl/OIAs0ahUlaoxKoZ6q9ln4AACob6pjBlkAQMPACBQAoNGriRlkAQANAwkUAKDRK59B9rvvvtONN96ou+6665IZZJs0aaLhw4eruLhYMTExevXVV83Xl88gO2nSJNlsNrVo0UJjxoxxmkEWANAwkEABABq9mppBFgBQ/5FAAQAAVDWm8wYaLBIoXBEz6wEA6hym3gZQi0ig0CCwKGzDRRIPAADqEhIoAAAAwFWMgDZ6rAMFAAAAAC4igQIAAAAAF3ELHwAAgKu4fQto9EigAAAAgPqgMSTwFbWxjk3/TwKFOovZ1wAAAKpZdSRlrp6zjiVGriKBAoAawpcCAADUfyRQAKoMCULNc/U9r2hdtMu9ljXUAAB13uVGuWpgVIsECmgEXP0juz4nQLW5mHJ1XLuqfxbXez4WqwaqSGN4hqWu4T2vGryPJhIooBrU50QE/w8/RwANSl37A9jV+tS1eleGqxMi1NRzSHXtmaN6+jtAAoU6gT9UUVO/A/yuAXBZHfujDbWgof0ONLT21BISKDRY/KGM2sTvHwAADRMJFADACckfAACXRwIFAAAA1BRuo6v3mtR2BQAAAACgviCBAgAAAAAXcQsfgAaLZ3kAAEBVYwQKAAAAAFxEAgUAAAAALiKBAgAAAAAXkUABAAAAgItIoAAAAADARSRQAAAAAOAiEigAAAAAcBEJFAAAAAC4iAQKAAAAAFxEAgUAAAAALiKBAgAAAAAXkUABAAAAgItIoAAAAADARSRQAAAAAOCiep9ALVmyRO3bt5eHh4ciIyO1Z8+e2q4SAKCRo28CgIarXidQq1evVkJCgp577jl99tln6t69u2JiYlRYWFjbVQMANFL0TQDQsLkZhmHUdiWuVWRkpG677TYtXrxYklRWVqbg4GA99dRTevbZZy+JLy4uVnFxsblfVFSkdu3a6fjx4/Ly8rqmOvz2t9dWdwCo79asufbXOhwOBQcH69SpU/L29q66StUBlembqqNf0id0TAAasbuvvXNytW9qes1XqGUlJSXKyspSYmKieaxJkyaKjo5WZmZmha9JTk7WrFmzLjkeHBxcbfUEgIaqKvKeH3/8sUElUJXtm+iXAKCqXX+fcrW+qd4mUN9++61KS0vl7+/vdNzf319ffPFFha9JTExUQkKCuV9WVqbvv/9erVu3lpubW6XrUJ6lXtc3hXVIQ2uP1PDa1NDaIzW8NjW09kjV0ybDMPTjjz8qKCioSs5XV1S2b6JfurqG1qaG1h6p4bWpobVHanhtqq72uNo31dsE6lpYrVZZrVanYz4+Ptd9Xi8vrwbxy1iuobVHanhtamjtkRpemxpae6Sqb1NDGnm6VvRLrmtobWpo7ZEaXpsaWnukhtem6miPK31TvZ1Eok2bNnJ3d1dBQYHT8YKCAgUEBNRSrQAAjRl9EwA0fPU2gbJYLIqIiFB6erp5rKysTOnp6bLZbLVYMwBAY0XfBAANX72+hS8hIUFjxoxR7969dfvtt2vBggU6c+aMnnjiiRq5vtVq1XPPPXfJ7Rf1VUNrj9Tw2tTQ2iM1vDY1tPZIDbNN1ak2+6aG+LNqaG1qaO2RGl6bGlp7pIbXptpuT72exlySFi9erBdffFF2u109evTQokWLFBkZWdvVAgA0YvRNANBw1fsECgAAAABqSr19BgoAAAAAahoJFAAAAAC4iAQKAAAAAFxEAgUAAAAALiKBukZLlixR+/bt5eHhocjISO3Zs6e2q+Sy7du3a8iQIQoKCpKbm5veffddp3LDMJSUlKTAwEB5enoqOjpaX375Ze1U1gXJycm67bbb1KpVK/n5+WnYsGHKyclxijl37pzi4uLUunVrtWzZUsOHD79kocu6YunSpQoPDzdX17bZbPrwww/N8vrUlst54YUX5ObmpsmTJ5vH6lO7Zs6cKTc3N6etc+fOZnl9asvF/vvf/+rRRx9V69at5enpqW7dumnfvn1meX37bGiM6JvqDvqmutuWitT3fkmib6rJzwYSqGuwevVqJSQk6LnnntNnn32m7t27KyYmRoWFhbVdNZecOXNG3bt315IlSyosnzt3rhYtWqRly5Zp9+7datGihWJiYnTu3Lkarqlrtm3bpri4OO3atUtpaWk6f/68BgwYoDNnzpgxU6ZM0fr167V27Vpt27ZNJ06c0AMPPFCLtb68tm3b6oUXXlBWVpb27dune+65R0OHDtXhw4cl1a+2VGTv3r3661//qvDwcKfj9a1dt956q/Lz881tx44dZll9a4sk/fDDD7rzzjvVrFkzffjhhzpy5IjmzZunG264wYypb58NjQ19U91C31R32/JLDaVfkuibauyzwUCl3X777UZcXJy5X1paagQFBRnJycm1WKtrI8lYt26duV9WVmYEBAQYL774onns1KlThtVqNf7xj3/UQg0rr7Cw0JBkbNu2zTCMn+vfrFkzY+3atWbM0aNHDUlGZmZmbVWzUm644Qbj9ddfr/dt+fHHH42OHTsaaWlpxq9//Wvj6aefNgyj/v2MnnvuOaN79+4VltW3tpSbPn26cdddd122vCF8NjR09E11G31T3dRQ+iXDoG8qVxOfDYxAVVJJSYmysrIUHR1tHmvSpImio6OVmZlZizWrGrm5ubLb7U7t8/b2VmRkZL1pX1FRkSTJ19dXkpSVlaXz5887talz585q165dnW9TaWmpVq1apTNnzshms9XrtkhSXFycYmNjneov1c+f0ZdffqmgoCDddNNNGjVqlPLy8iTVz7ZI0vvvv6/evXvroYcekp+fn3r27Km//e1vZnlD+GxoyOib6j76prqpIfVLEn2TVDOfDSRQlfTtt9+qtLRU/v7+Tsf9/f1lt9trqVZVp7wN9bV9ZWVlmjx5su6880517dpV0s9tslgs8vHxcYqty206ePCgWrZsKavVqokTJ2rdunUKCwurl20pt2rVKn322WdKTk6+pKy+tSsyMlIpKSnatGmTli5dqtzcXN1999368ccf611byv373//W0qVL1bFjR23evFmTJk3S73//e61YsUJS/f9saOjom+o2+qa6qSH1SxJ908Wqu11Nq+3MQC2Ii4vToUOHnO75rY86deqk7OxsFRUV6Z///KfGjBmjbdu21Xa1rtnx48f19NNPKy0tTR4eHrVdnes2aNAg8//Dw8MVGRmpkJAQrVmzRp6enrVYs2tXVlam3r17689//rMkqWfPnjp06JCWLVumMWPG1HLtgPqNvqnuaWj9kkTfVJMYgaqkNm3ayN3d/ZJZSwoKChQQEFBLtao65W2oj+2Lj4/Xhg0b9PHHH6tt27bm8YCAAJWUlOjUqVNO8XW5TRaLRR06dFBERISSk5PVvXt3LVy4sF62Rfr51oHCwkL16tVLTZs2VdOmTbVt2zYtWrRITZs2lb+/f71sVzkfHx/dcsst+uqrr+rtzygwMFBhYWFOx7p06WLe/lGfPxsaA/qmuou+qW62paH3SxJ9U3W2iwSqkiwWiyIiIpSenm4eKysrU3p6umw2Wy3WrGqEhoYqICDAqX0Oh0O7d++us+0zDEPx8fFat26dtm7dqtDQUKfyiIgINWvWzKlNOTk5ysvLq7Nt+qWysjIVFxfX27b0799fBw8eVHZ2trn17t1bo0aNMv+/Prar3OnTp3Xs2DEFBgbW25/RnXfeeckUy//6178UEhIiqX5+NjQm9E11D31T3W5LQ++XJPqmam1XtU1P0YCtWrXKsFqtRkpKinHkyBFjwoQJho+Pj2G322u7ai758ccfjf379xv79+83JBkvv/yysX//fuObb74xDMMwXnjhBcPHx8d47733jAMHDhhDhw41QkNDjbNnz9ZyzSs2adIkw9vb28jIyDDy8/PN7aeffjJjJk6caLRr187YunWrsW/fPsNmsxk2m60Wa315zz77rLFt2zYjNzfXOHDggPHss88abm5uxpYtWwzDqF9tuZKLZzsyjPrVrmeeecbIyMgwcnNzjU8//dSIjo422rRpYxQWFhqGUb/aUm7Pnj1G06ZNjeeff9748ssvjZUrVxrNmzc3/v73v5sx9e2zobGhb6pb6Jvqblsupz73S4ZB31STnw0kUNfolVdeMdq1a2dYLBbj9ttvN3bt2lXbVXLZxx9/bEi6ZBszZoxhGD9PCfnHP/7R8Pf3N6xWq9G/f38jJyendit9BRW1RZKxfPlyM+bs2bPG//zP/xg33HCD0bx5c+P+++838vPza6/SV/Dkk08aISEhhsViMW688Uajf//+ZgdlGPWrLVfyy46qPrVrxIgRRmBgoGGxWIxf/epXxogRI4yvvvrKLK9PbbnY+vXrja5duxpWq9Xo3Lmz8dprrzmV17fPhsaIvqnuoG+qu225nPrcLxkGfVNNfja4GYZhVN/4FgAAAAA0HDwDBQAAAAAuIoECAAAAABeRQAEAAACAi0igAAAAAMBFJFAAAAAA4CISKAAAAABwEQkUAAAAALiIBAoAAAAAXEQCBQAAAAAuIoECAAAAABeRQAEAAACAi/5/YRIl95B+RQIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "centralized_train_dataset: FEMNIST = FEMNIST(\n",
        "    mapping=centralized_partition / \"0\", data_dir=data_dir, name=\"train\"\n",
        ")\n",
        "centralized_test_dataset: FEMNIST = FEMNIST(\n",
        "    mapping=centralized_partition / \"0\", data_dir=data_dir, name=\"test\"\n",
        ")\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "train_histo = ax[0].hist(\n",
        "    [int(x[1]) for x in centralized_train_dataset.data],\n",
        "    bins=62,\n",
        "    color=\"blue\",\n",
        "    alpha=0.7,\n",
        "    label=\"centralized train dataset\",\n",
        ")\n",
        "test_histo = ax[1].hist(\n",
        "    [int(x[1]) for x in centralized_test_dataset.data],\n",
        "    bins=62,\n",
        "    color=\"orange\",\n",
        "    alpha=0.7,\n",
        "    label=\"centralized test dataset\",\n",
        ")\n",
        "ax[0].legend()\n",
        "ax[1].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AWfsLZo9jmi"
      },
      "source": [
        "Since the distribution is all but uniform, we need to make a further choice. We want to build a federation of 62 clients each of them having one class only. We want all the classes to be represented in the federation. Likewise, we also want FedAvg to treat equally all the clients in the federation. Thus, we will need to partition clients taking into account the population of the least represented class in both the `train` and the `test` set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_yGo1zI9UyA",
        "outputId": "d1ca99f5-5c11-4497-9df2-9dc23b94d4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-10 14:27:02,762 | <ipython-input-38-319cf1b2fc68>:1 | The least represented class in the train set has 1786.0 samples\n",
            "INFO:flwr:The least represented class in the train set has 1786.0 samples\n",
            "INFO flwr 2024-02-10 14:27:02,767 | <ipython-input-38-319cf1b2fc68>:6 | The least represented class in the test set has 233.0 samples\n",
            "INFO:flwr:The least represented class in the test set has 233.0 samples\n"
          ]
        }
      ],
      "source": [
        "log(\n",
        "    INFO,\n",
        "    \"The least represented class in the train set has %s samples\",\n",
        "    min(train_histo[0]),\n",
        ")\n",
        "log(\n",
        "    INFO,\n",
        "    \"The least represented class in the test set has %s samples\",\n",
        "    min(test_histo[0]),\n",
        ")\n",
        "max_train_samples = int(min(train_histo[0]))\n",
        "max_test_samples = int(min(test_histo[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuvZvcU3_eq0"
      },
      "source": [
        "Let's now create the function that creates the partition. We will stick to the folder structure the dataset has.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvJS4NX5_r-F"
      },
      "outputs": [],
      "source": [
        "class_unbalanced_partition: Path = (\n",
        "    dataset_dir / \"client_data_mappings\" / \"class_unbalanced\"\n",
        ")\n",
        "class_unbalanced_partition.mkdir(parents=True, exist_ok=True)\n",
        "train_df = pd.read_csv(centralized_mapping / \"train.csv\")\n",
        "test_df = pd.read_csv(centralized_mapping / \"test.csv\")\n",
        "max_train_samples = 200\n",
        "max_test_samples = 50\n",
        "for i in range(62):\n",
        "    folder_path: Path = class_unbalanced_partition / str(i)\n",
        "    folder_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_path: Path = folder_path / \"train.csv\"\n",
        "    test_path: Path = folder_path / \"test.csv\"\n",
        "\n",
        "    client_df = deepcopy(\n",
        "        train_df[train_df.label == i].sample(frac=1)[:max_train_samples]\n",
        "    ).reset_index()\n",
        "    client_df[\"client_id\"] = i\n",
        "    client_df.drop(columns=[\"level_0\"], inplace=True)\n",
        "    client_df.to_csv(train_path, index=False)\n",
        "    client_df = deepcopy(\n",
        "        test_df[test_df.label == i].sample(frac=1)[:max_test_samples]\n",
        "    ).reset_index()\n",
        "    client_df[\"client_id\"] = i\n",
        "    client_df.drop(columns=[\"level_0\"], inplace=True)\n",
        "    client_df.to_csv(test_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcuMI5TzW08E"
      },
      "source": [
        "Here, we seed the initial model parameters to come from a partially trained model on the centralized dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0Bj3btM9llx",
        "outputId": "3859bb1c-b536-4605-9342-8d0e4cd07658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-10 14:27:04,471 | client.py:57 | Creating client with cid: 0\n",
            "INFO:flwr:Creating client with cid: 0\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(Seeds.DEFAULT)\n",
        "network_generator_cnn = get_network_generator_cnn()\n",
        "seed_net_cnn = network_generator_cnn()\n",
        "centralized_flower_client_generator: Callable[\n",
        "    [int], FlowerClient\n",
        "] = get_flower_client_generator(\n",
        "    model_generator=network_generator_cnn,\n",
        "    partition_dir=centralized_partition,\n",
        "    data_dir=data_dir,\n",
        ")\n",
        "centralized_flower_client = centralized_flower_client_generator(0)\n",
        "centralized_train_config: dict[str, Any] = {\n",
        "    \"epochs\": 1,\n",
        "    \"batch_size\": 32,\n",
        "    \"client_learning_rate\": 0.01,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": 1000,\n",
        "}\n",
        "test_config: dict[str, Any] = {\n",
        "    \"batch_size\": 32,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": None,\n",
        "}\n",
        "# Train parameters on the centralised dataset\n",
        "trained_params, num_examples, train_metrics = fit_client_seeded(\n",
        "    centralized_flower_client,\n",
        "    params=get_model_parameters(seed_net_cnn),\n",
        "    conf=centralized_train_config,\n",
        ")\n",
        "initial_parameters: Parameters = ndarrays_to_parameters(trained_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ytbOMN2W08F"
      },
      "source": [
        "We also create the centralised evaluation function that will be executed by the server at the end of every round if requested.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRiXe-eU9m4u",
        "outputId": "fc0920d2-37e8-4596-bf7e-10d628c3e94c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-10 14:27:30,994 | client_utils.py:388 | Reduced federated test_set size from 28510 to a size of 1500 mean index: 14726.628666666667\n",
            "INFO:flwr:Reduced federated test_set size from 28510 to a size of 1500 mean index: 14726.628666666667\n"
          ]
        }
      ],
      "source": [
        "federated_evaluation_function = get_federated_evaluation_function(\n",
        "    data_dir=data_dir,\n",
        "    centralized_mapping=centralized_mapping,\n",
        "    device=get_device(),\n",
        "    batch_size=test_config[\"batch_size\"],\n",
        "    num_workers=test_config[\"num_workers\"],\n",
        "    model_generator=network_generator_cnn,\n",
        "    criterion=nn.CrossEntropyLoss()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGghXFCiW08F"
      },
      "source": [
        "Finally, the client generator function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0Ohncc3DLJG"
      },
      "outputs": [],
      "source": [
        "unbalanced_flower_client_generator: Callable[\n",
        "    [int], FlowerClient\n",
        "] = get_flower_client_generator(\n",
        "    model_generator=network_generator_cnn,\n",
        "    data_dir=data_dir,\n",
        "    partition_dir=class_unbalanced_partition,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJxlg3wEW08F"
      },
      "source": [
        "Let's see how these clients look like.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa1YUA70W08F",
        "outputId": "ff8dd0fc-5829-40a3-cb0d-2284fe7b8b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-10 14:27:31,015 | client.py:57 | Creating client with cid: 0\n",
            "INFO:flwr:Creating client with cid: 0\n",
            "INFO flwr 2024-02-10 14:27:31,107 | client.py:57 | Creating client with cid: 1\n",
            "INFO:flwr:Creating client with cid: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c8e11263040>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "N_CLASSES = 62\n",
        "plt.hist(\n",
        "    [\n",
        "        int(x[1])\n",
        "        for x in unbalanced_flower_client_generator(0)._load_dataset(\"train\").data\n",
        "    ],\n",
        "    bins=N_CLASSES,\n",
        "    color=\"blue\",\n",
        "    alpha=0.7,\n",
        "    label=\"client 0 train set\",\n",
        ")\n",
        "plt.hist(\n",
        "    [\n",
        "        int(x[1])\n",
        "        for x in unbalanced_flower_client_generator(1)._load_dataset(\"train\").data\n",
        "    ],\n",
        "    bins=N_CLASSES,\n",
        "    color=\"orange\",\n",
        "    alpha=0.7,\n",
        "    label=\"client 1 train set\",\n",
        ")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Oh84SnSW08G"
      },
      "source": [
        "We will now create a wrapper for the strategy that will be used to extract the clients' model parameters obtained during the training for the next question.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTYpbRDbW08G"
      },
      "outputs": [],
      "source": [
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.common import FitRes, parameters_to_ndarrays\n",
        "\n",
        "\n",
        "class WrappedFedAvg(FedAvg):\n",
        "    clients_models: dict[int, list[tuple[int, NDArrays]]] = {}\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: list[tuple[ClientProxy, FitRes]],\n",
        "        failures: list[tuple[ClientProxy, FitRes] | BaseException],\n",
        "    ) -> tuple[Parameters | None, dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        # Call FedAvg original aggregate_fit, so that it handles the failures\n",
        "        ret = super().aggregate_fit(server_round, results, failures)\n",
        "        # Append clients' model parameters to the list\n",
        "        self.clients_models[server_round] = [\n",
        "            (i, parameters_to_ndarrays(fit_res.parameters))\n",
        "            for i, (_, fit_res) in enumerate(results)\n",
        "        ]\n",
        "        # Return the original return value\n",
        "        return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuSAFGmXDgYT"
      },
      "outputs": [],
      "source": [
        "train_config: dict[str, Any] = {\n",
        "    \"epochs\": 8,\n",
        "    \"batch_size\": 32,\n",
        "    \"client_learning_rate\": 0.01,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": None,\n",
        "}\n",
        "\n",
        "\n",
        "def _on_fit_config_fn(server_round: int) -> dict[str, Scalar]:\n",
        "    return train_config | {\"server_round\": server_round}\n",
        "\n",
        "\n",
        "num_total_clients = 62\n",
        "num_clients_per_round: int = 5\n",
        "num_evaluate_clients: int = 5\n",
        "\n",
        "strategy = WrappedFedAvg(\n",
        "    fraction_fit=sys.float_info.min,\n",
        "    fraction_evaluate=sys.float_info.min,\n",
        "    min_fit_clients=num_clients_per_round,\n",
        "    min_evaluate_clients=num_evaluate_clients,\n",
        "    min_available_clients=max(num_clients_per_round, num_evaluate_clients),\n",
        "    on_fit_config_fn=_on_fit_config_fn,\n",
        "    on_evaluate_config_fn=None,\n",
        "    evaluate_fn=federated_evaluation_function,\n",
        "    initial_parameters=initial_parameters,\n",
        "    accept_failures=False,\n",
        "    fit_metrics_aggregation_fn=aggregate_weighted_average,\n",
        "    evaluate_metrics_aggregation_fn=aggregate_weighted_average,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5sFPqF0k596b",
        "outputId": "560e8020-1f0e-4103-fd6d-bb0ffb7e60d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-10 14:27:31,649 | app.py:149 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO flwr 2024-02-10 14:27:31,652 | server_returns_parameters.py:81 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-02-10 14:27:31,656 | server_returns_parameters.py:273 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2024-02-10 14:27:31,666 | server_returns_parameters.py:84 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "100%|██████████| 47/47 [00:01<00:00, 40.54it/s]\n",
            "INFO flwr 2024-02-10 14:27:32,848 | server_returns_parameters.py:87 | initial parameters (loss, other metrics): 58.245476484298706, {'accuracy': 0.5813333333333334}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 58.245476484298706, {'accuracy': 0.5813333333333334}\n",
            "INFO flwr 2024-02-10 14:27:32,851 | server_returns_parameters.py:97 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-02-10 14:27:32,855 | server_returns_parameters.py:223 | fit_round 1: strategy sampled 5 clients (out of 62)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 5 clients (out of 62)\n",
            "INFO flwr 2024-02-10 14:27:32,862 | client.py:57 | Creating client with cid: 39\n",
            "INFO:flwr:Creating client with cid: 39\n",
            "INFO flwr 2024-02-10 14:27:32,862 | client.py:57 | Creating client with cid: 59\n",
            "INFO:flwr:Creating client with cid: 59\n",
            "INFO flwr 2024-02-10 14:27:32,869 | client.py:57 | Creating client with cid: 34\n",
            "INFO:flwr:Creating client with cid: 34\n",
            "INFO flwr 2024-02-10 14:27:32,880 | client.py:57 | Creating client with cid: 45\n",
            "INFO flwr 2024-02-10 14:27:32,881 | client.py:57 | Creating client with cid: 23\n",
            "INFO:flwr:Creating client with cid: 45\n",
            "INFO:flwr:Creating client with cid: 23\n",
            "ERROR flwr 2024-02-10 14:27:41,431 | app.py:189 | DataLoader worker (pid 6073) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
            "ERROR:flwr:DataLoader worker (pid 6073) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
            "ERROR flwr 2024-02-10 14:27:41,477 | app.py:190 | Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\", line 338, in fit_clients\n",
            "    finished_fs, _ = concurrent.futures.wait(\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 307, in wait\n",
            "    waiter.event.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
            "    waiter.acquire()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 5690) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/app.py\", line 184, in start_simulation_no_ray\n",
            "    parameters_list, hist = run_fl_return_parameters(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/app.py\", line 249, in run_fl_return_parameters\n",
            "    parameters_list, hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\", line 102, in fit\n",
            "    res_fit = self.fit_round(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\", line 232, in fit_round\n",
            "    results, failures = fit_clients(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\", line 333, in fit_clients\n",
            "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 649, in __exit__\n",
            "    self.shutdown(wait=True)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 235, in shutdown\n",
            "    t.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 6073) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
            "\n",
            "ERROR:flwr:Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\", line 338, in fit_clients\n",
            "    finished_fs, _ = concurrent.futures.wait(\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 307, in wait\n",
            "    waiter.event.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 607, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 320, in wait\n",
            "    waiter.acquire()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 5690) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/app.py\", line 184, in start_simulation_no_ray\n",
            "    parameters_list, hist = run_fl_return_parameters(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/app.py\", line 249, in run_fl_return_parameters\n",
            "    parameters_list, hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\", line 102, in fit\n",
            "    res_fit = self.fit_round(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\", line 232, in fit_round\n",
            "    results, failures = fit_clients(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\", line 333, in fit_clients\n",
            "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 649, in __exit__\n",
            "    self.shutdown(wait=True)\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/thread.py\", line 235, in shutdown\n",
            "    t.join()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1096, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1116, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 6073) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
            "\n",
            "ERROR flwr 2024-02-10 14:27:41,488 | app.py:191 | Your simulation crashed :(. This could be because of several reasons.The most common are: \n",
            "\t > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.\n",
            "\t > All the actors in your pool crashed. This could be because: \n",
            "\t\t - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {} is not enough for your workload). Use fewer concurrent actors. \n",
            "\t\t - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {}.\n",
            "ERROR:flwr:Your simulation crashed :(. This could be because of several reasons.The most common are: \n",
            "\t > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.\n",
            "\t > All the actors in your pool crashed. This could be because: \n",
            "\t\t - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {} is not enough for your workload). Use fewer concurrent actors. \n",
            "\t\t - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {}.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Simulation crashed.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\u001b[0m in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout)\u001b[0m\n\u001b[1;32m    337\u001b[0m         }\n\u001b[0;32m--> 338\u001b[0;31m         finished_fs, _ = concurrent.futures.wait(\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubmitted_fs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 5690) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/simulation/app.py\u001b[0m in \u001b[0;36mstart_simulation_no_ray\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         parameters_list, hist = run_fl_return_parameters(\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0mserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialized_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/app.py\u001b[0m in \u001b[0;36mrun_fl_return_parameters\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;34m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0mparameters_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"app_fit: losses_distributed %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_distributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m# Train model and replace previous global model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             res_fit = self.fit_round(\n\u001b[0m\u001b[1;32m    103\u001b[0m                 \u001b[0mserver_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\u001b[0m in \u001b[0;36mfit_round\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Collect `fit` results from all clients participating in this round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         results, failures = fit_clients(\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mclient_instructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_instructions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server_returns_parameters.py\u001b[0m in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;34m\"\"\"Refine parameters concurrently on all selected clients.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m         submitted_fs = {\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/signal_handling.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 6073) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-3ad272161034>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m params, hist = start_seeded_simulation(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mclient_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mcid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munbalanced_flower_client_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_clients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_total_clients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mServerConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-f00ead899963>\u001b[0m in \u001b[0;36mstart_seeded_simulation\u001b[0;34m(client_fn, num_clients, config, strategy, name, seed, iteration)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m^\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     parameter_list, hist = fl.simulation.start_simulation_no_ray(\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mclient_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mnum_clients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/simulation/app.py\u001b[0m in \u001b[0;36mstart_simulation_no_ray\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager)\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mclient_resources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         )\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Simulation crashed.\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Simulation crashed."
          ]
        }
      ],
      "source": [
        "params, hist = start_seeded_simulation(\n",
        "    client_fn=lambda cid: unbalanced_flower_client_generator(cid).to_client(),\n",
        "    num_clients=num_total_clients,\n",
        "    config=ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    name=\"unbalanced\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfHiEN9MW08H"
      },
      "source": [
        "We will now investigate how such a partition behaves in an FL setting. In particular, we will try to understand what happens to the global model and the clients' updates as the training progresses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzG9xF-lgb51"
      },
      "source": [
        "**Question 4 (Part II ✅):**\n",
        "\n",
        "(You need to provide the answer with **code** and **plots** for this question. A short written argumentation is recommended.)\n",
        "\n",
        "1. For each round, retrieve the clients' models and the global model using the appropriate attribute of the `WrappedFedAvg` strategy.\n",
        "2. Inspect the models collected for each round as follows:\n",
        "   - Extract the \"softmax-ed\" activations of the last layer of each clients' model when the model is fed with random inputs. (HINT: `from common.client_utils import get_activations_from_random_input`, give a motivation for the choice of the parameters of this function if you decide to use it)\n",
        "   - Compute the pairwise cosine-similarity (you can use functions similar to those used in the previous Lab) between the values obtained in the previous step.\n",
        "   - Plot the results of this computation in a confusion matrix. The confusion matrix will have the shape `n_clients_per_round`x`n_clients_per_round`.\n",
        "   - Repeat the same procedure for computing and compare the pairwise KL divergence between the \"softmax-ed\" activations of the last layer of each clients' model when the model is fed with random inputs. (HINT: `from scipy.stats import entropy`).\n",
        "3. Compare the confusion matrices obtained. What do you observe, and how does it compare with your expectations? Briefly discuss the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKm-X5MBW08H"
      },
      "source": [
        "**Question 5 (Part III/MPhil ✅):**\n",
        "\n",
        "(This is meant to be a conceptual question. You should provide a written answer to this. **No more than 3 sentences**. **No code** is needed)\n",
        "\n",
        "1. How does the concept of a client relate to a task in Multi-task Learning (MTL)?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5\n",
        "\n",
        "1. If we imagine a task in MTL to be \"fitting a model for data on a client\", then each client would correspond to a task in MTL, where Federated Learning corresponds to learning to solve multiple of such learning tasks at the same time by exploiting similarities and differences between data across clients."
      ],
      "metadata": {
        "id": "fG_tTmz-au5U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I64eyic-tnWF"
      },
      "source": [
        "### LDA partitions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLFg0zOBh77Q"
      },
      "source": [
        "The most popular method for creating heterogeneous partitions from a centralized dataset in terms of class unbalancing is [Latent Dirichlet Allocation (LDA)](https://web.archive.org/web/20120501152722/http://jmlr.csail.mit.edu/papers/v3/blei03a.html). LDA is a generative probabilistic model for collections of discrete data. The paper linked above provides all the theoretical details about the method.\n",
        "\n",
        "The important detail for you to understand about LDA is that the `concentration` parameter controls the degree of heterogeneity in the distribution while `num_partitions` controls how many clients are generated following the specified distribution.\n",
        "\n",
        "A `concentration=0` implies a completely heterogeneous distribution where each client may only contain examples from one class. Thus, if for a `concentration=0` we were to set the `num_partitions` argument to the number of classes we will get the same partitioning as the one we manually created above.\n",
        "\n",
        "> **Important:** The LDA partitioning only approaches a fully i.i.d distribution when `concentration` tends towards $\\infty$. The most appropriate value of the `concentration` to generate a completely i.i.d. partition is dataset dependent. Feel free to try out different values of `concentration` and `num_partitions` to see how the partitioning changes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNho5BDtlpbh"
      },
      "outputs": [],
      "source": [
        "from common.lda_utils import create_lda_partitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueTmkfi-W08I"
      },
      "source": [
        "Let's create the partitions using LDA with `concentration=2.5` and `num_partitions=1000`. This will result in a non-i.i.d. partitioning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztmKkBPLhBVP"
      },
      "outputs": [],
      "source": [
        "N_TOTAL_CLIENTS = 1_000\n",
        "concentration = 2.5\n",
        "# Create partitions\n",
        "x = np.array([x[0] for x in centralized_train_dataset.data])\n",
        "y = np.array([x[1] for x in centralized_train_dataset.data])\n",
        "train_clients_partitions, dist = create_lda_partitions(\n",
        "    dataset=(x, y),\n",
        "    dirichlet_dist=None,\n",
        "    num_partitions=N_TOTAL_CLIENTS,\n",
        "    concentration=concentration,\n",
        "    accept_imbalanced=True,\n",
        "    seed=Seeds.DEFAULT,\n",
        ")\n",
        "x = np.array([x[0] for x in centralized_test_dataset.data])\n",
        "y = np.array([x[1] for x in centralized_test_dataset.data])\n",
        "test_clients_partitions, dist = create_lda_partitions(\n",
        "    dataset=(x, y),\n",
        "    dirichlet_dist=dist,\n",
        "    num_partitions=N_TOTAL_CLIENTS,\n",
        "    concentration=concentration,\n",
        "    accept_imbalanced=True,\n",
        "    seed=Seeds.DEFAULT,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQtlY6DJW08I"
      },
      "source": [
        "Let's store the partitions in the folder structure we have been using so far.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EFfE0fVqnCB"
      },
      "outputs": [],
      "source": [
        "lda_partition: Path = dataset_dir / \"client_data_mappings\" / \"lda\"\n",
        "if lda_partition.exists():\n",
        "    ! rm -rf {str(lda_partition)}\n",
        "lda_partition.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for i, (train_set, test_set) in enumerate(\n",
        "    zip(train_clients_partitions, test_clients_partitions, strict=True)\n",
        "):\n",
        "    folder_path: Path = lda_partition / str(i)\n",
        "    folder_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_path: Path = folder_path / \"train.csv\"\n",
        "    test_path: Path = folder_path / \"test.csv\"\n",
        "\n",
        "    pd.DataFrame(\n",
        "        {\n",
        "            \"client_id\": [0] * len(train_set[0]),\n",
        "            \"sample_path\": train_set[0],\n",
        "            \"sample_id\": range(len(train_set[0])),\n",
        "            \"label\": train_set[1],\n",
        "        }\n",
        "    ).to_csv(train_path, index=False, mode=\"w\")\n",
        "    pd.DataFrame(\n",
        "        {\n",
        "            \"client_id\": [0] * len(test_set[0]),\n",
        "            \"sample_path\": test_set[0],\n",
        "            \"sample_id\": range(len(test_set[0])),\n",
        "            \"label\": test_set[1],\n",
        "        }\n",
        "    ).to_csv(test_path, index=False, mode=\"w\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFN4SR8wW08J"
      },
      "source": [
        "We instantiate a client generator function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pm6IBCqGqgHD"
      },
      "outputs": [],
      "source": [
        "lda_flower_client_generator: Callable[\n",
        "    [int], FlowerClient\n",
        "] = get_flower_client_generator(\n",
        "    model_generator=network_generator_cnn,\n",
        "    data_dir=data_dir,\n",
        "    partition_dir=lda_partition,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIRf74QPW08J"
      },
      "source": [
        "We can also plot two clients' labels distributions to see how different they are.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGf3J7SytbIc",
        "outputId": "5b0843ed-5197-40b9-b970-0ea43da8819f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-10 14:31:01,569 | client.py:57 | Creating client with cid: 0\n",
            "INFO:flwr:Creating client with cid: 0\n",
            "INFO flwr 2024-02-10 14:31:01,641 | client.py:57 | Creating client with cid: 1\n",
            "INFO:flwr:Creating client with cid: 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c8e135ab6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "N_CLASSES = 62\n",
        "plt.hist(\n",
        "    [int(x[1]) for x in lda_flower_client_generator(0)._load_dataset(\"train\").data],\n",
        "    bins=N_CLASSES,\n",
        "    color=\"blue\",\n",
        "    alpha=0.7,\n",
        "    label=\"client 0 train set\",\n",
        ")\n",
        "plt.hist(\n",
        "    [int(x[1]) for x in lda_flower_client_generator(1)._load_dataset(\"train\").data],\n",
        "    bins=N_CLASSES,\n",
        "    color=\"orange\",\n",
        "    alpha=0.7,\n",
        "    label=\"client 1 train set\",\n",
        ")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI2rsUVbW08J"
      },
      "source": [
        "We try now to run an FL simulation is such challenging setting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWbg6Ty6s7c0"
      },
      "outputs": [],
      "source": [
        "train_config: dict[str, Any] = {\n",
        "    \"epochs\": 1,\n",
        "    \"batch_size\": 32,\n",
        "    \"client_learning_rate\": 0.01,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": None,\n",
        "}\n",
        "\n",
        "\n",
        "def _on_fit_config_fn(server_round: int) -> dict[str, Scalar]:\n",
        "    return train_config | {\"server_round\": server_round}\n",
        "\n",
        "\n",
        "num_total_clients = N_TOTAL_CLIENTS\n",
        "num_clients_per_round: int = 5\n",
        "num_evaluate_clients: int = 0\n",
        "\n",
        "strategy = FedAvg(\n",
        "    fraction_fit=sys.float_info.min,\n",
        "    fraction_evaluate=sys.float_info.min,\n",
        "    min_fit_clients=num_clients_per_round,\n",
        "    min_evaluate_clients=num_evaluate_clients,\n",
        "    min_available_clients=max(num_clients_per_round, num_evaluate_clients),\n",
        "    on_fit_config_fn=_on_fit_config_fn,\n",
        "    on_evaluate_config_fn=None,\n",
        "    evaluate_fn=federated_evaluation_function,\n",
        "    initial_parameters=initial_parameters,\n",
        "    accept_failures=False,\n",
        "    fit_metrics_aggregation_fn=aggregate_weighted_average,\n",
        "    evaluate_metrics_aggregation_fn=aggregate_weighted_average,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PscXeuI6Dpo",
        "outputId": "5c7a2141-d743-4276-da2e-a83a937efae6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-10 14:31:02,072 | app.py:149 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO flwr 2024-02-10 14:31:02,084 | server_returns_parameters.py:81 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-02-10 14:31:02,089 | server_returns_parameters.py:273 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2024-02-10 14:31:02,097 | server_returns_parameters.py:84 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "100%|██████████| 47/47 [00:00<00:00, 72.85it/s]\n",
            "INFO flwr 2024-02-10 14:31:02,762 | server_returns_parameters.py:87 | initial parameters (loss, other metrics): 58.245476484298706, {'accuracy': 0.5813333333333334}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 58.245476484298706, {'accuracy': 0.5813333333333334}\n",
            "INFO flwr 2024-02-10 14:31:02,767 | server_returns_parameters.py:97 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-02-10 14:31:02,769 | server_returns_parameters.py:223 | fit_round 1: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:31:02,776 | client.py:57 | Creating client with cid: 632\n",
            "INFO:flwr:Creating client with cid: 632\n",
            "INFO flwr 2024-02-10 14:31:02,776 | client.py:57 | Creating client with cid: 947\n",
            "INFO:flwr:Creating client with cid: 947\n",
            "INFO flwr 2024-02-10 14:31:02,777 | client.py:57 | Creating client with cid: 546\n",
            "INFO:flwr:Creating client with cid: 546\n",
            "INFO flwr 2024-02-10 14:31:02,784 | client.py:57 | Creating client with cid: 726\n",
            "INFO:flwr:Creating client with cid: 726\n",
            "INFO flwr 2024-02-10 14:31:02,814 | client.py:57 | Creating client with cid: 374\n",
            "INFO:flwr:Creating client with cid: 374\n",
            "DEBUG flwr 2024-02-10 14:31:05,732 | server_returns_parameters.py:237 | fit_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:01<00:00, 43.38it/s]\n",
            "INFO flwr 2024-02-10 14:31:06,857 | server_returns_parameters.py:120 | fit progress: (1, 67.41769367456436, {'accuracy': 0.662}, 4.08818971200003)\n",
            "INFO:flwr:fit progress: (1, 67.41769367456436, {'accuracy': 0.662}, 4.08818971200003)\n",
            "INFO flwr 2024-02-10 14:31:06,859 | server_returns_parameters.py:171 | evaluate_round 1: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 1: no clients selected, cancel\n",
            "DEBUG flwr 2024-02-10 14:31:06,862 | server_returns_parameters.py:223 | fit_round 2: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:31:06,867 | client.py:57 | Creating client with cid: 584\n",
            "INFO:flwr:Creating client with cid: 584\n",
            "INFO flwr 2024-02-10 14:31:06,875 | client.py:57 | Creating client with cid: 599\n",
            "INFO:flwr:Creating client with cid: 599\n",
            "INFO flwr 2024-02-10 14:31:06,886 | client.py:57 | Creating client with cid: 749\n",
            "INFO:flwr:Creating client with cid: 749\n",
            "INFO flwr 2024-02-10 14:31:06,906 | client.py:57 | Creating client with cid: 169\n",
            "INFO:flwr:Creating client with cid: 169\n",
            "INFO flwr 2024-02-10 14:31:06,924 | client.py:57 | Creating client with cid: 793\n",
            "INFO:flwr:Creating client with cid: 793\n",
            "DEBUG flwr 2024-02-10 14:31:10,084 | server_returns_parameters.py:237 | fit_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:00<00:00, 66.33it/s]\n",
            "INFO flwr 2024-02-10 14:31:10,818 | server_returns_parameters.py:120 | fit progress: (2, 62.74609237909317, {'accuracy': 0.6833333333333333}, 8.049464950000129)\n",
            "INFO:flwr:fit progress: (2, 62.74609237909317, {'accuracy': 0.6833333333333333}, 8.049464950000129)\n",
            "INFO flwr 2024-02-10 14:31:10,822 | server_returns_parameters.py:171 | evaluate_round 2: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 2: no clients selected, cancel\n",
            "DEBUG flwr 2024-02-10 14:31:10,827 | server_returns_parameters.py:223 | fit_round 3: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:31:10,832 | client.py:57 | Creating client with cid: 844\n",
            "INFO:flwr:Creating client with cid: 844\n",
            "INFO flwr 2024-02-10 14:31:10,840 | client.py:57 | Creating client with cid: 340\n",
            "INFO:flwr:Creating client with cid: 340\n",
            "INFO flwr 2024-02-10 14:31:10,840 | client.py:57 | Creating client with cid: 392\n",
            "INFO:flwr:Creating client with cid: 392\n",
            "INFO flwr 2024-02-10 14:31:10,841 | client.py:57 | Creating client with cid: 650\n",
            "INFO:flwr:Creating client with cid: 650\n",
            "INFO flwr 2024-02-10 14:31:10,867 | client.py:57 | Creating client with cid: 808\n",
            "INFO:flwr:Creating client with cid: 808\n",
            "DEBUG flwr 2024-02-10 14:31:12,972 | server_returns_parameters.py:237 | fit_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:00<00:00, 71.96it/s]\n",
            "INFO flwr 2024-02-10 14:31:13,653 | server_returns_parameters.py:120 | fit progress: (3, 73.6429991722107, {'accuracy': 0.68}, 10.884522896000135)\n",
            "INFO:flwr:fit progress: (3, 73.6429991722107, {'accuracy': 0.68}, 10.884522896000135)\n",
            "INFO flwr 2024-02-10 14:31:13,656 | server_returns_parameters.py:171 | evaluate_round 3: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 3: no clients selected, cancel\n",
            "DEBUG flwr 2024-02-10 14:31:13,659 | server_returns_parameters.py:223 | fit_round 4: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:31:13,667 | client.py:57 | Creating client with cid: 368\n",
            "INFO:flwr:Creating client with cid: 368\n",
            "INFO flwr 2024-02-10 14:31:13,675 | client.py:57 | Creating client with cid: 943\n",
            "INFO:flwr:Creating client with cid: 943\n",
            "INFO flwr 2024-02-10 14:31:13,679 | client.py:57 | Creating client with cid: 315\n",
            "INFO:flwr:Creating client with cid: 315\n",
            "INFO flwr 2024-02-10 14:31:13,685 | client.py:57 | Creating client with cid: 400\n",
            "INFO:flwr:Creating client with cid: 400\n",
            "INFO flwr 2024-02-10 14:31:13,702 | client.py:57 | Creating client with cid: 713\n",
            "INFO:flwr:Creating client with cid: 713\n",
            "DEBUG flwr 2024-02-10 14:31:15,693 | server_returns_parameters.py:237 | fit_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:00<00:00, 70.67it/s]\n",
            "INFO flwr 2024-02-10 14:31:16,387 | server_returns_parameters.py:120 | fit progress: (4, 74.57913506031036, {'accuracy': 0.6966666666666667}, 13.619005068999968)\n",
            "INFO:flwr:fit progress: (4, 74.57913506031036, {'accuracy': 0.6966666666666667}, 13.619005068999968)\n",
            "INFO flwr 2024-02-10 14:31:16,390 | server_returns_parameters.py:171 | evaluate_round 4: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 4: no clients selected, cancel\n",
            "DEBUG flwr 2024-02-10 14:31:16,393 | server_returns_parameters.py:223 | fit_round 5: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:31:16,399 | client.py:57 | Creating client with cid: 209\n",
            "INFO:flwr:Creating client with cid: 209\n",
            "INFO flwr 2024-02-10 14:31:16,414 | client.py:57 | Creating client with cid: 779\n",
            "INFO:flwr:Creating client with cid: 779\n",
            "INFO flwr 2024-02-10 14:31:16,426 | client.py:57 | Creating client with cid: 672\n",
            "INFO:flwr:Creating client with cid: 672\n",
            "INFO flwr 2024-02-10 14:31:16,440 | client.py:57 | Creating client with cid: 884\n",
            "INFO:flwr:Creating client with cid: 884\n",
            "INFO flwr 2024-02-10 14:31:16,448 | client.py:57 | Creating client with cid: 934\n",
            "INFO:flwr:Creating client with cid: 934\n",
            "DEBUG flwr 2024-02-10 14:31:18,532 | server_returns_parameters.py:237 | fit_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:00<00:00, 70.86it/s]\n",
            "INFO flwr 2024-02-10 14:31:19,221 | server_returns_parameters.py:120 | fit progress: (5, 77.24941498041153, {'accuracy': 0.69}, 16.45215275700002)\n",
            "INFO:flwr:fit progress: (5, 77.24941498041153, {'accuracy': 0.69}, 16.45215275700002)\n",
            "INFO flwr 2024-02-10 14:31:19,226 | server_returns_parameters.py:171 | evaluate_round 5: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 5: no clients selected, cancel\n",
            "INFO flwr 2024-02-10 14:31:19,230 | server_returns_parameters.py:150 | FL finished in 16.46175988699997\n",
            "INFO:flwr:FL finished in 16.46175988699997\n",
            "INFO flwr 2024-02-10 14:31:19,232 | app.py:250 | app_fit: losses_distributed []\n",
            "INFO:flwr:app_fit: losses_distributed []\n",
            "INFO flwr 2024-02-10 14:31:19,236 | app.py:251 | app_fit: metrics_distributed_fit {'train_loss': [(1, {'avg': 0.024912073076702655, 'all': [(20, 0.029112376598641278), (20, 0.024296989291906358), (20, 0.021277979668229818), (20, 0.013403004198335112), (20, 0.03647001562640071)]}), (2, {'avg': 0.031598609038628635, 'all': [(20, 0.07301894035190344), (20, 0.017685759509913624), (20, 0.0156875669490546), (20, 0.023578989040106534), (20, 0.028021789342164993)]}), (3, {'avg': 0.024837994929403067, 'all': [(20, 0.04414435103535652), (20, 0.014282949967309833), (20, 0.014507869305089117), (20, 0.01718271542340517), (20, 0.03407208891585469)]}), (4, {'avg': 0.028647088253637775, 'all': [(20, 0.03275457136332989), (20, 0.010841719451127574), (20, 0.049212072510272264), (20, 0.017381841922178863), (20, 0.03304523602128029)]}), (5, {'avg': 0.03052163648768328, 'all': [(20, 0.01821103598922491), (20, 0.011807468783808872), (20, 0.011693413811735809), (20, 0.01998460649047047), (20, 0.09091165736317634)]})]}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {'train_loss': [(1, {'avg': 0.024912073076702655, 'all': [(20, 0.029112376598641278), (20, 0.024296989291906358), (20, 0.021277979668229818), (20, 0.013403004198335112), (20, 0.03647001562640071)]}), (2, {'avg': 0.031598609038628635, 'all': [(20, 0.07301894035190344), (20, 0.017685759509913624), (20, 0.0156875669490546), (20, 0.023578989040106534), (20, 0.028021789342164993)]}), (3, {'avg': 0.024837994929403067, 'all': [(20, 0.04414435103535652), (20, 0.014282949967309833), (20, 0.014507869305089117), (20, 0.01718271542340517), (20, 0.03407208891585469)]}), (4, {'avg': 0.028647088253637775, 'all': [(20, 0.03275457136332989), (20, 0.010841719451127574), (20, 0.049212072510272264), (20, 0.017381841922178863), (20, 0.03304523602128029)]}), (5, {'avg': 0.03052163648768328, 'all': [(20, 0.01821103598922491), (20, 0.011807468783808872), (20, 0.011693413811735809), (20, 0.01998460649047047), (20, 0.09091165736317634)]})]}\n",
            "INFO flwr 2024-02-10 14:31:19,240 | app.py:252 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2024-02-10 14:31:19,243 | app.py:253 | app_fit: losses_centralized [(0, 58.245476484298706), (1, 67.41769367456436), (2, 62.74609237909317), (3, 73.6429991722107), (4, 74.57913506031036), (5, 77.24941498041153)]\n",
            "INFO:flwr:app_fit: losses_centralized [(0, 58.245476484298706), (1, 67.41769367456436), (2, 62.74609237909317), (3, 73.6429991722107), (4, 74.57913506031036), (5, 77.24941498041153)]\n",
            "INFO flwr 2024-02-10 14:31:19,247 | app.py:254 | app_fit: metrics_centralized {'accuracy': [(0, 0.5813333333333334), (1, 0.662), (2, 0.6833333333333333), (3, 0.68), (4, 0.6966666666666667), (5, 0.69)]}\n",
            "INFO:flwr:app_fit: metrics_centralized {'accuracy': [(0, 0.5813333333333334), (1, 0.662), (2, 0.6833333333333333), (3, 0.68), (4, 0.6966666666666667), (5, 0.69)]}\n"
          ]
        }
      ],
      "source": [
        "params, hist = start_seeded_simulation(\n",
        "    client_fn=lambda cid: lda_flower_client_generator(cid).to_client(),\n",
        "    num_clients=num_total_clients,\n",
        "    config=ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    name=\"fedavg_lda_example\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GK6PX9kW08K"
      },
      "source": [
        "**Question 6 (Part II ✅):**\n",
        "\n",
        "(You need to provide the answer with **code** and **plots** for this question. A short written argumentation is recommended.)\n",
        "\n",
        "1. Produce a set of LDA partitions with `concentration` in `[0.001, 0.1, 1e3]`.\n",
        "2. Train an FL setting for every partition you have produced using the same hyperparameter we used in the cell above, but with `num_clients_per_round=62` and `ServerConfig(num_rounds=1)`.\n",
        "3. Why do you think one-shot averaging works well for full i.i.d data and not for very heterogeneous clients?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "872EAMGYW08K"
      },
      "source": [
        "Use the configuration provided by the following cell.\n",
        "\n",
        "> **IMPORTANT**: Be careful when using the strategy object. You must ensure that the different experiments will use the same initial parameters. Inspect `flwr.server.strategy.FedAvg` to understand how these are used.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6AaV9zgW08K"
      },
      "outputs": [],
      "source": [
        "# NOTE: We are using randomly initialized parameters here.\n",
        "torch.manual_seed(Seeds.DEFAULT)\n",
        "network_generator_cnn = get_network_generator_cnn()\n",
        "seed_net_cnn = network_generator_cnn()\n",
        "q6_initial_parameters: Parameters = ndarrays_to_parameters(\n",
        "    get_model_parameters(seed_net_cnn)\n",
        ")\n",
        "# Set up experiment configuration\n",
        "N_TOTAL_CLIENTS = 100\n",
        "N_TOTAL_ROUNDS = 1\n",
        "train_config: dict[str, Any] = {\n",
        "    \"epochs\": 1,\n",
        "    \"batch_size\": 32,\n",
        "    \"client_learning_rate\": 0.001,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": None,\n",
        "}\n",
        "\n",
        "\n",
        "def _on_fit_config_fn(server_round: int) -> dict[str, Scalar]:\n",
        "    return train_config | {\"server_round\": server_round}\n",
        "\n",
        "\n",
        "num_total_clients = N_TOTAL_CLIENTS\n",
        "num_clients_per_round: int = 62\n",
        "num_evaluate_clients: int = 0\n",
        "fraction_fit: float = float(num_clients_per_round) / num_total_clients\n",
        "fraction_evaluate: float = float(num_evaluate_clients) / num_total_clients\n",
        "# Set up strategy\n",
        "strategy = FedAvg(\n",
        "    fraction_fit=sys.float_info.min,\n",
        "    fraction_evaluate=sys.float_info.min,\n",
        "    min_fit_clients=num_clients_per_round,\n",
        "    min_evaluate_clients=num_evaluate_clients,\n",
        "    min_available_clients=max(num_clients_per_round, num_evaluate_clients),\n",
        "    on_fit_config_fn=_on_fit_config_fn,\n",
        "    on_evaluate_config_fn=None,\n",
        "    evaluate_fn=federated_evaluation_function,\n",
        "    initial_parameters=q6_initial_parameters,\n",
        "    accept_failures=False,\n",
        "    fit_metrics_aggregation_fn=aggregate_weighted_average,\n",
        "    evaluate_metrics_aggregation_fn=aggregate_weighted_average,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0_aN4dkcvv8"
      },
      "source": [
        "# 4. FL Strategies tackling heterogeneity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ayxhgBa-8Oi"
      },
      "source": [
        "The challenge of dealing with non-iidness in FL has been discussed extensively since the publication of the first paper about FL. Many approaches have been proposed, but still, the literature doesn't agree on a general approach or a rule of thumb. A natural method is to modify/extend FedAvg or develop another algorithm specifically oriented to mitigating heterogeneity. In some applications, augmenting data to make it more similar between clients is possible. Some works assume a small dataset that is shared between clients to serve as a reference.\n",
        "\n",
        "Every time a new approach has been proposed, many related questions have arisen. It is no longer clear that treating all examples of all the clients equally make sense. Some works proposed limiting the contributions of data from any client in the federation. The notion of fairness has been introduced and defined in many ways in order to set up principles that could result in new approaches, for example emphasizing underperforming clients during aggregation. It is not even clear whether a single global model is the correct objective for FL---works related to this question gave birth to Personalised Federated Learning (PFL), a sub-branch of research.\n",
        "\n",
        "We started to think that we should be able to turn the non-iid problem from a bug into a feature treated similarly to a task in MTL. The number of works that start with this perspective is however limited.\n",
        "\n",
        "Even if FedAvg can partially mitigate heterogeneity, it is not working well in all situations, as we saw previously. From the many new algorithms that were introduced, it is worth mentioning: [FedProx](https://www.researchgate.net/profile/Anit-Sahu/publication/329734586_On_the_Convergence_of_Federated_Optimization_in_Heterogeneous_Networks/links/5c1bdd5e299bf12be38ee52d/On-the-Convergence-of-Federated-Optimization-in-Heterogeneous-Networks.pdf), [q-FedAvg](https://arxiv.org/abs/1905.10497), [SCAFFOLD](http://proceedings.mlr.press/v119/karimireddy20a.html). For a matter of time, we will now explore just one of these algorithms introduced for tackling the non-iid problem specifically. We chose FedProx since it is the simplest to demonstrate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3xe9fHHc5Sc"
      },
      "source": [
        "## FedProx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNyYEsRnId3C"
      },
      "source": [
        "The Federated Proximal (FedProx) method was developed in the context of tuning and benchmarking FedAvg in a heterogeneous setting. The authors of FedAvg proposed carefully tuning the learning rate and the number of local epochs to increase the accuracy in such settings but turned out clear that something more was necessary. Based on the client's heterogeneity, local updates change the global model not only in different directions in the loss space but also at different rates. This phenomenon is called client divergence or drifting.\n",
        "\n",
        "Using FedAvg we would like to have a different number of local epochs for each client based on its characteristics. Thus, heuristically setting the number of local updates is not always optimal, because clients are all different from each other. Limiting the number of local updates through a more flexible tool is beneficial. Thus, FedProx proposes to incorporate a term in the local objective function that penalizes big changes from the current model at the server. In each node $k$, instead of minimizing the local loss function $F_k$, the local solver tries to approximately minimize:\n",
        "\n",
        "$\\min_wh_w(w;w^t)=F_k(w)+\\frac{\\mu}{2}||w-w^t||^2$,\n",
        "\n",
        "where $||w-w^t||^2$ is the new proximal term.\n",
        "\n",
        "FedProx acts as FedAvg apart from the change in the local objective. This new objective enforces limited local model updates more explicitly than FedAvg. Using FedProx, it is no longer necessary to tune the number of local epochs for each client to minimize divergence.\n",
        "\n",
        "We will now implement and test FedProx on the natural partition of FEMNIST. Implementing FedProx just involves modifying the local training function of our `FlowerRayClient`. We will then write the new function and build a new `client_generator` function that overwrites the relevant methods of our client.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoGXFQALRRkR"
      },
      "outputs": [],
      "source": [
        "def train_fedprox_FEMNIST(\n",
        "    net: Module,\n",
        "    train_loader: DataLoader,\n",
        "    epochs: int,\n",
        "    device: str,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    criterion: Module,\n",
        "    proximal_mu: float,\n",
        ") -> float:\n",
        "    \"\"\"Trains the network on the training set using FedProx.\n",
        "\n",
        "    Args:\n",
        "        net (Module): generic module object describing the network to train.\n",
        "        train_loader (DataLoader): dataloader to iterate during the training.\n",
        "        epochs (int): number of epochs of training.\n",
        "        device (str): device name onto which perform the computation.\n",
        "        optimizer (torch.optim.Optimizer): optimizer object.\n",
        "        criterion (Module): generic module describing the loss function.\n",
        "        proximal_mu (float): parameter for the weight of the proximal term.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        float: the final epoch mean train loss.\n",
        "    \"\"\"\n",
        "    global_params: Module = deepcopy(net)\n",
        "    global_params.requires_grad_(False)\n",
        "    global_params = [val for _, val in global_params.state_dict().items()]\n",
        "    net.train()\n",
        "    running_loss, total = 0.0, 0\n",
        "    for _ in tqdm(range(epochs)):\n",
        "        running_loss = 0.0\n",
        "        total = 0\n",
        "        for data, labels in train_loader:\n",
        "            data, labels = data.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            # NOTE: here comes the implementation of FedProx algorithm\n",
        "            proximal_term = 0.0\n",
        "            for local_weights, global_weights in zip(\n",
        "                net.parameters(), global_params, strict=True\n",
        "            ):\n",
        "                proximal_term += (local_weights - global_weights).norm(2)\n",
        "            loss = criterion(net(data), labels) + (proximal_mu / 2) * proximal_term\n",
        "            running_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    return running_loss / total\n",
        "\n",
        "\n",
        "def _train_fedprox(\n",
        "    self, net: Module, train_loader: DataLoader, config: dict[str, Scalar]\n",
        ") -> float:\n",
        "    return train_fedprox_FEMNIST(\n",
        "        net=net,\n",
        "        train_loader=train_loader,\n",
        "        epochs=int(config[\"epochs\"]),\n",
        "        device=self.device,\n",
        "        optimizer=torch.optim.AdamW(\n",
        "            net.parameters(),\n",
        "            lr=float(config[\"client_learning_rate\"]),\n",
        "            weight_decay=float(config[\"weight_decay\"]),\n",
        "        ),\n",
        "        criterion=torch.nn.CrossEntropyLoss(),\n",
        "        proximal_mu=config[\"proximal_mu\"],\n",
        "    )\n",
        "\n",
        "\n",
        "def get_fedprox_flower_client_generator(\n",
        "    model_generator: Callable[[], Module],\n",
        "    data_dir: Path,\n",
        "    partition_dir: Path,\n",
        ") -> Callable[[str], FlowerClient]:\n",
        "    \"\"\"Implement a wrapper function for the client instance generator.\n",
        "\n",
        "    This provides the client generator with a model generator function.\n",
        "    Also, the partition directory must be passed.\n",
        "    The clients generated will train using FedProx algorithm.\n",
        "\n",
        "    Args:\n",
        "        data_dir (Path): path to the dataset folder.\n",
        "        model_generator (Callable[[], Module]): model generator function.\n",
        "        partition_dir (Path): directory containing the partition.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        Callable[[str], WrappedClient]: client instance.\n",
        "    \"\"\"\n",
        "\n",
        "    def client_fn(cid: str) -> FlowerClient:\n",
        "        \"\"\"Create a single client instance given the client id `cid`.\n",
        "\n",
        "        Args:\n",
        "            cid (str): client id, Flower requires this to of type str.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            WrappedClient: client instance.\n",
        "        \"\"\"\n",
        "        log(INFO, f\"Getting client with id {cid}\")\n",
        "        client = FlowerClient(\n",
        "            cid=cid,\n",
        "            data_dir=data_dir,\n",
        "            partition_dir=partition_dir,\n",
        "            model_generator=model_generator,\n",
        "        )\n",
        "        # Pay attention to the following line\n",
        "        client._train = _train_fedprox.__get__(client, FlowerClient)\n",
        "        return client\n",
        "\n",
        "    return client_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOEq5uvEW08M"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(Seeds.DEFAULT)\n",
        "N_TOTAL_CLIENTS = 1000\n",
        "CONCENTRATION = 0.1\n",
        "# Create partitions\n",
        "x = np.array([x[0] for x in centralized_train_dataset.data])\n",
        "y = np.array([x[1] for x in centralized_train_dataset.data])\n",
        "train_clients_partitions, dist = create_lda_partitions(\n",
        "    dataset=(x, y),\n",
        "    dirichlet_dist=None,\n",
        "    num_partitions=N_TOTAL_CLIENTS,\n",
        "    concentration=CONCENTRATION,\n",
        "    accept_imbalanced=True,\n",
        "    seed=Seeds.DEFAULT,\n",
        ")\n",
        "x = np.array([x[0] for x in centralized_test_dataset.data])\n",
        "y = np.array([x[1] for x in centralized_test_dataset.data])\n",
        "test_clients_partitions, dist = create_lda_partitions(\n",
        "    dataset=(x, y),\n",
        "    dirichlet_dist=dist,\n",
        "    num_partitions=N_TOTAL_CLIENTS,\n",
        "    concentration=CONCENTRATION,\n",
        "    accept_imbalanced=True,\n",
        ")\n",
        "# Store partitions\n",
        "lda_partition: Path = dataset_dir / \"client_data_mappings\" / f\"lda_{CONCENTRATION}\"\n",
        "if lda_partition.exists():\n",
        "    ! rm -rf {str(lda_partition)}\n",
        "lda_partition.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for i, (train_set, test_set) in enumerate(\n",
        "    zip(train_clients_partitions, test_clients_partitions, strict=True)\n",
        "):\n",
        "    folder_path: Path = lda_partition / str(i)\n",
        "    folder_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_path: Path = folder_path / \"train.csv\"\n",
        "    test_path: Path = folder_path / \"test.csv\"\n",
        "\n",
        "    pd.DataFrame(\n",
        "        {\n",
        "            \"client_id\": [0] * len(train_set[0]),\n",
        "            \"sample_path\": train_set[0],\n",
        "            \"sample_id\": range(len(train_set[0])),\n",
        "            \"label\": train_set[1],\n",
        "        }\n",
        "    ).to_csv(train_path, index=False)\n",
        "    pd.DataFrame(\n",
        "        {\n",
        "            \"client_id\": [0] * len(test_set[0]),\n",
        "            \"sample_path\": test_set[0],\n",
        "            \"sample_id\": range(len(test_set[0])),\n",
        "            \"label\": test_set[1],\n",
        "        }\n",
        "    ).to_csv(test_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjiLOOddl6cw"
      },
      "source": [
        "We are now able to train an FL setting using FedProx.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbd8Ks4Hl-Uz"
      },
      "outputs": [],
      "source": [
        "# NOTE: we are using here the `get_fedprox_flower_client_generator`\n",
        "federated_fedprox_flower_client_generator: Callable[\n",
        "    [int], FlowerClient\n",
        "] = get_fedprox_flower_client_generator(\n",
        "    model_generator=network_generator_cnn,\n",
        "    data_dir=data_dir,\n",
        "    partition_dir=lda_partition,\n",
        ")\n",
        "N_TOTAL_ROUNDS = 5\n",
        "# Set up experiment configuration\n",
        "train_config: dict[str, Any] = {\n",
        "    \"epochs\": 1,\n",
        "    \"batch_size\": 32,\n",
        "    \"client_learning_rate\": 0.1,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": None,\n",
        "    \"proximal_mu\": 0.01,\n",
        "}\n",
        "\n",
        "\n",
        "def _on_fit_config_fn(server_round: int) -> dict[str, Scalar]:\n",
        "    return train_config | {\"server_round\": server_round}\n",
        "\n",
        "\n",
        "num_total_clients = N_TOTAL_CLIENTS\n",
        "num_clients_per_round: int = 5\n",
        "num_evaluate_clients: int = 0\n",
        "fraction_fit: float = float(num_clients_per_round) / num_total_clients\n",
        "fraction_evaluate: float = float(num_evaluate_clients) / num_total_clients\n",
        "# Set up strategy\n",
        "strategy = FedAvg(\n",
        "    fraction_fit=sys.float_info.min,\n",
        "    fraction_evaluate=sys.float_info.min,\n",
        "    min_fit_clients=num_clients_per_round,\n",
        "    min_evaluate_clients=num_evaluate_clients,\n",
        "    min_available_clients=max(num_clients_per_round, num_evaluate_clients),\n",
        "    on_fit_config_fn=_on_fit_config_fn,\n",
        "    on_evaluate_config_fn=None,\n",
        "    evaluate_fn=federated_evaluation_function,\n",
        "    initial_parameters=initial_parameters,\n",
        "    accept_failures=False,\n",
        "    fit_metrics_aggregation_fn=aggregate_weighted_average,\n",
        "    evaluate_metrics_aggregation_fn=aggregate_weighted_average,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cg576GQBRWS",
        "outputId": "359b31d0-a748-4912-e0e1-f8dde074a1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-10 14:42:10,025 | app.py:149 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO flwr 2024-02-10 14:42:10,036 | server_returns_parameters.py:81 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-02-10 14:42:10,041 | server_returns_parameters.py:273 | Using initial parameters provided by strategy\n",
            "INFO:flwr:Using initial parameters provided by strategy\n",
            "INFO flwr 2024-02-10 14:42:10,045 | server_returns_parameters.py:84 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "100%|██████████| 47/47 [00:00<00:00, 71.62it/s]\n",
            "INFO flwr 2024-02-10 14:42:10,721 | server_returns_parameters.py:87 | initial parameters (loss, other metrics): 58.245476484298706, {'accuracy': 0.5813333333333334}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 58.245476484298706, {'accuracy': 0.5813333333333334}\n",
            "INFO flwr 2024-02-10 14:42:10,725 | server_returns_parameters.py:97 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-02-10 14:42:10,727 | server_returns_parameters.py:223 | fit_round 1: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:42:10,734 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 632\n",
            "INFO:flwr:Getting client with id 632\n",
            "INFO flwr 2024-02-10 14:42:10,735 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 947\n",
            "INFO flwr 2024-02-10 14:42:10,737 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 546\n",
            "INFO:flwr:Getting client with id 947\n",
            "INFO:flwr:Getting client with id 546\n",
            "INFO flwr 2024-02-10 14:42:10,738 | client.py:57 | Creating client with cid: 632\n",
            "INFO flwr 2024-02-10 14:42:10,739 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 726\n",
            "INFO flwr 2024-02-10 14:42:10,743 | client.py:57 | Creating client with cid: 947\n",
            "INFO flwr 2024-02-10 14:42:10,747 | client.py:57 | Creating client with cid: 546\n",
            "INFO:flwr:Creating client with cid: 632\n",
            "INFO:flwr:Getting client with id 726\n",
            "INFO flwr 2024-02-10 14:42:10,751 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 374\n",
            "INFO flwr 2024-02-10 14:42:10,757 | client.py:57 | Creating client with cid: 726\n",
            "INFO:flwr:Creating client with cid: 947\n",
            "INFO:flwr:Creating client with cid: 546\n",
            "INFO:flwr:Getting client with id 374\n",
            "INFO flwr 2024-02-10 14:42:10,793 | client.py:57 | Creating client with cid: 374\n",
            "INFO:flwr:Creating client with cid: 726\n",
            "INFO:flwr:Creating client with cid: 374\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n",
            "DEBUG flwr 2024-02-10 14:42:13,918 | server_returns_parameters.py:237 | fit_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:00<00:00, 73.50it/s]\n",
            "INFO flwr 2024-02-10 14:42:14,585 | server_returns_parameters.py:120 | fit progress: (1, 190.52885580062866, {'accuracy': 0.006}, 3.8586848690001716)\n",
            "INFO:flwr:fit progress: (1, 190.52885580062866, {'accuracy': 0.006}, 3.8586848690001716)\n",
            "INFO flwr 2024-02-10 14:42:14,588 | server_returns_parameters.py:171 | evaluate_round 1: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 1: no clients selected, cancel\n",
            "DEBUG flwr 2024-02-10 14:42:14,590 | server_returns_parameters.py:223 | fit_round 2: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:42:14,596 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 584\n",
            "INFO:flwr:Getting client with id 584\n",
            "INFO flwr 2024-02-10 14:42:14,596 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 599\n",
            "INFO:flwr:Getting client with id 599\n",
            "INFO flwr 2024-02-10 14:42:14,607 | client.py:57 | Creating client with cid: 599\n",
            "INFO:flwr:Creating client with cid: 599\n",
            "INFO flwr 2024-02-10 14:42:14,604 | client.py:57 | Creating client with cid: 584\n",
            "INFO:flwr:Creating client with cid: 584\n",
            "INFO flwr 2024-02-10 14:42:14,605 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 169\n",
            "INFO:flwr:Getting client with id 169\n",
            "INFO flwr 2024-02-10 14:42:14,605 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 749\n",
            "INFO:flwr:Getting client with id 749\n",
            "INFO flwr 2024-02-10 14:42:14,609 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 793\n",
            "INFO flwr 2024-02-10 14:42:14,636 | client.py:57 | Creating client with cid: 169\n",
            "INFO:flwr:Getting client with id 793\n",
            "INFO flwr 2024-02-10 14:42:14,648 | client.py:57 | Creating client with cid: 749\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]INFO:flwr:Creating client with cid: 169\n",
            "INFO flwr 2024-02-10 14:42:14,651 | client.py:57 | Creating client with cid: 793\n",
            "INFO:flwr:Creating client with cid: 749\n",
            "\n",
            "INFO:flwr:Creating client with cid: 793\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
            "DEBUG flwr 2024-02-10 14:42:16,970 | server_returns_parameters.py:237 | fit_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:00<00:00, 74.60it/s]\n",
            "INFO flwr 2024-02-10 14:42:17,630 | server_returns_parameters.py:120 | fit progress: (2, 206.56386399269104, {'accuracy': 0.05733333333333333}, 6.903314070000306)\n",
            "INFO:flwr:fit progress: (2, 206.56386399269104, {'accuracy': 0.05733333333333333}, 6.903314070000306)\n",
            "INFO flwr 2024-02-10 14:42:17,635 | server_returns_parameters.py:171 | evaluate_round 2: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 2: no clients selected, cancel\n",
            "DEBUG flwr 2024-02-10 14:42:17,639 | server_returns_parameters.py:223 | fit_round 3: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:42:17,644 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 844\n",
            "INFO:flwr:Getting client with id 844\n",
            "INFO flwr 2024-02-10 14:42:17,646 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 392\n",
            "INFO:flwr:Getting client with id 392\n",
            "INFO flwr 2024-02-10 14:42:17,645 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 340\n",
            "INFO:flwr:Getting client with id 340\n",
            "INFO flwr 2024-02-10 14:42:17,647 | client.py:57 | Creating client with cid: 844\n",
            "INFO flwr 2024-02-10 14:42:17,648 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 650\n",
            "INFO:flwr:Creating client with cid: 844\n",
            "INFO flwr 2024-02-10 14:42:17,651 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 808\n",
            "INFO:flwr:Getting client with id 650\n",
            "INFO flwr 2024-02-10 14:42:17,652 | client.py:57 | Creating client with cid: 392\n",
            "INFO:flwr:Getting client with id 808\n",
            "INFO:flwr:Creating client with cid: 392\n",
            "INFO flwr 2024-02-10 14:42:17,653 | client.py:57 | Creating client with cid: 340\n",
            "INFO:flwr:Creating client with cid: 340\n",
            "INFO flwr 2024-02-10 14:42:17,666 | client.py:57 | Creating client with cid: 650\n",
            "INFO:flwr:Creating client with cid: 650\n",
            "INFO flwr 2024-02-10 14:42:17,668 | client.py:57 | Creating client with cid: 808\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]INFO:flwr:Creating client with cid: 808\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
            "\n",
            "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
            "DEBUG flwr 2024-02-10 14:42:20,281 | server_returns_parameters.py:237 | fit_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:01<00:00, 26.68it/s]\n",
            "INFO flwr 2024-02-10 14:42:22,118 | server_returns_parameters.py:120 | fit progress: (3, 181.06872844696045, {'accuracy': 0.07333333333333333}, 11.391062022999904)\n",
            "INFO:flwr:fit progress: (3, 181.06872844696045, {'accuracy': 0.07333333333333333}, 11.391062022999904)\n",
            "INFO flwr 2024-02-10 14:42:22,122 | server_returns_parameters.py:171 | evaluate_round 3: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 3: no clients selected, cancel\n",
            "DEBUG flwr 2024-02-10 14:42:22,128 | server_returns_parameters.py:223 | fit_round 4: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:42:22,130 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 368\n",
            "INFO:flwr:Getting client with id 368\n",
            "INFO flwr 2024-02-10 14:42:22,145 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 943\n",
            "INFO:flwr:Getting client with id 943\n",
            "INFO flwr 2024-02-10 14:42:22,149 | client.py:57 | Creating client with cid: 368\n",
            "INFO:flwr:Creating client with cid: 368\n",
            "INFO flwr 2024-02-10 14:42:22,149 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 315\n",
            "INFO:flwr:Getting client with id 315\n",
            "INFO flwr 2024-02-10 14:42:22,174 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 713\n",
            "INFO:flwr:Getting client with id 713\n",
            "INFO flwr 2024-02-10 14:42:22,187 | client.py:57 | Creating client with cid: 713\n",
            "INFO:flwr:Creating client with cid: 713\n",
            "INFO flwr 2024-02-10 14:42:22,175 | client.py:57 | Creating client with cid: 315\n",
            "INFO:flwr:Creating client with cid: 315\n",
            "INFO flwr 2024-02-10 14:42:22,154 | client.py:57 | Creating client with cid: 943\n",
            "INFO:flwr:Creating client with cid: 943\n",
            "INFO flwr 2024-02-10 14:42:22,155 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 400\n",
            "INFO:flwr:Getting client with id 400\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]INFO flwr 2024-02-10 14:42:22,251 | client.py:57 | Creating client with cid: 400\n",
            "INFO:flwr:Creating client with cid: 400\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n",
            "\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
            "DEBUG flwr 2024-02-10 14:42:26,638 | server_returns_parameters.py:237 | fit_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:00<00:00, 71.79it/s]\n",
            "INFO flwr 2024-02-10 14:42:27,335 | server_returns_parameters.py:120 | fit progress: (4, 192.76110243797302, {'accuracy': 0.07533333333333334}, 16.60806684499994)\n",
            "INFO:flwr:fit progress: (4, 192.76110243797302, {'accuracy': 0.07533333333333334}, 16.60806684499994)\n",
            "INFO flwr 2024-02-10 14:42:27,339 | server_returns_parameters.py:171 | evaluate_round 4: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 4: no clients selected, cancel\n",
            "DEBUG flwr 2024-02-10 14:42:27,342 | server_returns_parameters.py:223 | fit_round 5: strategy sampled 5 clients (out of 1000)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 5 clients (out of 1000)\n",
            "INFO flwr 2024-02-10 14:42:27,351 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 209\n",
            "INFO:flwr:Getting client with id 209\n",
            "INFO flwr 2024-02-10 14:42:27,352 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 779\n",
            "INFO flwr 2024-02-10 14:42:27,353 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 672\n",
            "INFO:flwr:Getting client with id 779\n",
            "INFO:flwr:Getting client with id 672\n",
            "INFO flwr 2024-02-10 14:42:27,360 | client.py:57 | Creating client with cid: 209\n",
            "INFO:flwr:Creating client with cid: 209\n",
            "INFO flwr 2024-02-10 14:42:27,362 | client.py:57 | Creating client with cid: 779\n",
            "INFO:flwr:Creating client with cid: 779\n",
            "INFO flwr 2024-02-10 14:42:27,362 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 884\n",
            "INFO flwr 2024-02-10 14:42:27,363 | client.py:57 | Creating client with cid: 672\n",
            "INFO:flwr:Getting client with id 884\n",
            "INFO flwr 2024-02-10 14:42:27,368 | <ipython-input-55-382d20eccbda>:99 | Getting client with id 934\n",
            "INFO:flwr:Creating client with cid: 672\n",
            "INFO flwr 2024-02-10 14:42:27,387 | client.py:57 | Creating client with cid: 884\n",
            "INFO:flwr:Getting client with id 934\n",
            "INFO flwr 2024-02-10 14:42:27,398 | client.py:57 | Creating client with cid: 934\n",
            "INFO:flwr:Creating client with cid: 884\n",
            "INFO:flwr:Creating client with cid: 934\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
            "DEBUG flwr 2024-02-10 14:42:30,148 | server_returns_parameters.py:237 | fit_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 5 results and 0 failures\n",
            "100%|██████████| 47/47 [00:00<00:00, 48.76it/s]\n",
            "INFO flwr 2024-02-10 14:42:31,337 | server_returns_parameters.py:120 | fit progress: (5, 180.44808506965637, {'accuracy': 0.07333333333333333}, 20.610429306000242)\n",
            "INFO:flwr:fit progress: (5, 180.44808506965637, {'accuracy': 0.07333333333333333}, 20.610429306000242)\n",
            "INFO flwr 2024-02-10 14:42:31,345 | server_returns_parameters.py:171 | evaluate_round 5: no clients selected, cancel\n",
            "INFO:flwr:evaluate_round 5: no clients selected, cancel\n",
            "INFO flwr 2024-02-10 14:42:31,352 | server_returns_parameters.py:150 | FL finished in 20.624936871000045\n",
            "INFO:flwr:FL finished in 20.624936871000045\n",
            "INFO flwr 2024-02-10 14:42:31,357 | app.py:250 | app_fit: losses_distributed []\n",
            "INFO:flwr:app_fit: losses_distributed []\n",
            "INFO flwr 2024-02-10 14:42:31,363 | app.py:251 | app_fit: metrics_distributed_fit {'train_loss': [(1, {'avg': 0.08071763393469154, 'all': [(20, 0.1079472559504211), (20, 0.05742798540741205), (20, 0.14925501737743616), (20, 0.06254632845520973), (20, 0.0264115824829787)]}), (2, {'avg': 0.05537538843229413, 'all': [(20, 0.05838445406407118), (20, 0.07544974889606237), (20, 0.03932849634438753), (20, 0.06374443192034959), (20, 0.03996981093659997)]}), (3, {'avg': 0.050546578383073214, 'all': [(20, 0.037792375683784483), (20, 0.07853928599506617), (20, 0.009368053218349815), (20, 0.07110068276524543), (20, 0.05593249425292015)]}), (4, {'avg': 0.05643579972442239, 'all': [(20, 0.03146925689652562), (20, 0.02731993345078081), (20, 0.08386124186217785), (20, 0.07753031961619854), (20, 0.06199824679642916)]}), (5, {'avg': 0.05934031143784523, 'all': [(20, 0.061150654405355456), (20, 0.08372788727283478), (20, 0.0634509289637208), (20, 0.03565534511581063), (20, 0.05271674143150449)]})]}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {'train_loss': [(1, {'avg': 0.08071763393469154, 'all': [(20, 0.1079472559504211), (20, 0.05742798540741205), (20, 0.14925501737743616), (20, 0.06254632845520973), (20, 0.0264115824829787)]}), (2, {'avg': 0.05537538843229413, 'all': [(20, 0.05838445406407118), (20, 0.07544974889606237), (20, 0.03932849634438753), (20, 0.06374443192034959), (20, 0.03996981093659997)]}), (3, {'avg': 0.050546578383073214, 'all': [(20, 0.037792375683784483), (20, 0.07853928599506617), (20, 0.009368053218349815), (20, 0.07110068276524543), (20, 0.05593249425292015)]}), (4, {'avg': 0.05643579972442239, 'all': [(20, 0.03146925689652562), (20, 0.02731993345078081), (20, 0.08386124186217785), (20, 0.07753031961619854), (20, 0.06199824679642916)]}), (5, {'avg': 0.05934031143784523, 'all': [(20, 0.061150654405355456), (20, 0.08372788727283478), (20, 0.0634509289637208), (20, 0.03565534511581063), (20, 0.05271674143150449)]})]}\n",
            "INFO flwr 2024-02-10 14:42:31,368 | app.py:252 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2024-02-10 14:42:31,374 | app.py:253 | app_fit: losses_centralized [(0, 58.245476484298706), (1, 190.52885580062866), (2, 206.56386399269104), (3, 181.06872844696045), (4, 192.76110243797302), (5, 180.44808506965637)]\n",
            "INFO:flwr:app_fit: losses_centralized [(0, 58.245476484298706), (1, 190.52885580062866), (2, 206.56386399269104), (3, 181.06872844696045), (4, 192.76110243797302), (5, 180.44808506965637)]\n",
            "INFO flwr 2024-02-10 14:42:31,378 | app.py:254 | app_fit: metrics_centralized {'accuracy': [(0, 0.5813333333333334), (1, 0.006), (2, 0.05733333333333333), (3, 0.07333333333333333), (4, 0.07533333333333334), (5, 0.07333333333333333)]}\n",
            "INFO:flwr:app_fit: metrics_centralized {'accuracy': [(0, 0.5813333333333334), (1, 0.006), (2, 0.05733333333333333), (3, 0.07333333333333333), (4, 0.07533333333333334), (5, 0.07333333333333333)]}\n"
          ]
        }
      ],
      "source": [
        "params_list, hist = start_seeded_simulation(\n",
        "    client_fn=lambda cid: federated_fedprox_flower_client_generator(cid).to_client(),\n",
        "    num_clients=N_TOTAL_CLIENTS,\n",
        "    config=ServerConfig(num_rounds=N_TOTAL_ROUNDS),\n",
        "    strategy=strategy,\n",
        "    name=\"fedprox\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qfu-DErGW08N"
      },
      "source": [
        "**Question 7 (Part II ✅):**\n",
        "\n",
        "(You need to provide the answer with **code** and **plots** for this question. A short written argumentation is recommended.)\n",
        "\n",
        "1. Train the FL setting composed of LDA partitions with `concentration=1.0` using FedProx with values of `proximal_mu` in $\\{10.0, 0.1, 1e-5\\}$. Keep `num_clients_per_round=5` and `ServerConfig(num_rounds=10)`. Use the experimental configurations bellow.\n",
        "2. Plot convergence curves for both `proximal_mu`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCn1RFBgW08N",
        "outputId": "e01aad83-c5a4-4280-e53d-90c141ae72b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-02-10 14:42:31,887 | client.py:57 | Creating client with cid: 0\n",
            "INFO:flwr:Creating client with cid: 0\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(Seeds.DEFAULT)\n",
        "network_generator_cnn = get_network_generator_cnn()\n",
        "seed_net_cnn = network_generator_cnn()\n",
        "centralized_flower_client_generator: Callable[\n",
        "    [int], FlowerClient\n",
        "] = get_flower_client_generator(\n",
        "    model_generator=network_generator_cnn,\n",
        "    partition_dir=centralized_partition,\n",
        "    data_dir=data_dir,\n",
        ")\n",
        "centralized_flower_client = centralized_flower_client_generator(0)\n",
        "centralized_train_config: dict[str, Any] = {\n",
        "    \"epochs\": 1,\n",
        "    \"batch_size\": 32,\n",
        "    \"client_learning_rate\": 0.01,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": 1000,\n",
        "}\n",
        "# Train parameters on the centralised dataset\n",
        "trained_params, num_examples, train_metrics = fit_client_seeded(\n",
        "    centralized_flower_client,\n",
        "    params=get_model_parameters(seed_net_cnn),\n",
        "    conf=centralized_train_config,\n",
        ")\n",
        "q7_initial_parameters_pretrained = ndarrays_to_parameters(trained_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7YangTtW08N"
      },
      "outputs": [],
      "source": [
        "N_TOTAL_CLIENTS = 1000\n",
        "N_TOTAL_ROUNDS = 10\n",
        "N_CLIENTS_PER_ROUND = 5\n",
        "CONCENTRATION = 1.0\n",
        "# Set up experiment configuration\n",
        "train_config: dict[str, Any] = {\n",
        "    \"epochs\": 5,\n",
        "    \"batch_size\": 32,\n",
        "    \"client_learning_rate\": 0.01,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"num_workers\": 2,\n",
        "    \"max_batches\": None,\n",
        "    # NOTE: This must be adjusted according to the requests\n",
        "    \"proximal_mu\": ...,\n",
        "}\n",
        "\n",
        "\n",
        "def _on_fit_config_fn(server_round: int) -> dict[str, Scalar]:\n",
        "    return train_config | {\"server_round\": server_round}\n",
        "\n",
        "\n",
        "num_total_clients = N_TOTAL_CLIENTS\n",
        "num_clients_per_round: int = N_CLIENTS_PER_ROUND\n",
        "num_evaluate_clients: int = 0\n",
        "fraction_fit: float = float(num_clients_per_round) / num_total_clients\n",
        "fraction_evaluate: float = float(num_evaluate_clients) / num_total_clients\n",
        "# Set up strategy\n",
        "strategy = FedAvg(\n",
        "    fraction_fit=sys.float_info.min,\n",
        "    fraction_evaluate=sys.float_info.min,\n",
        "    min_fit_clients=num_clients_per_round,\n",
        "    min_evaluate_clients=num_evaluate_clients,\n",
        "    min_available_clients=max(num_clients_per_round, num_evaluate_clients),\n",
        "    on_fit_config_fn=_on_fit_config_fn,\n",
        "    on_evaluate_config_fn=None,\n",
        "    evaluate_fn=federated_evaluation_function,\n",
        "    initial_parameters=q7_initial_parameters_pretrained,\n",
        "    accept_failures=False,\n",
        "    fit_metrics_aggregation_fn=aggregate_weighted_average,\n",
        "    evaluate_metrics_aggregation_fn=aggregate_weighted_average,\n",
        ")\n",
        "\n",
        "# Create partitions\n",
        "x = np.array([x[0] for x in centralized_train_dataset.data])\n",
        "y = np.array([x[1] for x in centralized_train_dataset.data])\n",
        "train_clients_partitions, dist = create_lda_partitions(\n",
        "    dataset=(x, y),\n",
        "    dirichlet_dist=None,\n",
        "    num_partitions=N_TOTAL_CLIENTS,\n",
        "    concentration=CONCENTRATION,\n",
        "    accept_imbalanced=True,\n",
        ")\n",
        "x = np.array([x[0] for x in centralized_test_dataset.data])\n",
        "y = np.array([x[1] for x in centralized_test_dataset.data])\n",
        "test_clients_partitions, dist = create_lda_partitions(\n",
        "    dataset=(x, y),\n",
        "    dirichlet_dist=dist,\n",
        "    num_partitions=N_TOTAL_CLIENTS,\n",
        "    concentration=CONCENTRATION,\n",
        "    accept_imbalanced=True,\n",
        ")\n",
        "# Store partitions\n",
        "lda_partition: Path = dataset_dir / \"client_data_mappings\" / f\"lda_{CONCENTRATION}\"\n",
        "if lda_partition.exists():\n",
        "    ! rm -rf {lda_partition}\n",
        "lda_partition.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for i, (train_set, test_set) in enumerate(\n",
        "    zip(train_clients_partitions, test_clients_partitions, strict=True)\n",
        "):\n",
        "    folder_path: Path = lda_partition / str(i)\n",
        "    folder_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_path: Path = folder_path / \"train.csv\"\n",
        "    test_path: Path = folder_path / \"test.csv\"\n",
        "\n",
        "    pd.DataFrame(\n",
        "        {\n",
        "            \"client_id\": [0] * len(train_set[0]),\n",
        "            \"sample_path\": train_set[0],\n",
        "            \"sample_id\": range(len(train_set[0])),\n",
        "            \"label\": train_set[1],\n",
        "        }\n",
        "    ).to_csv(train_path, index=False)\n",
        "    pd.DataFrame(\n",
        "        {\n",
        "            \"client_id\": [0] * len(test_set[0]),\n",
        "            \"sample_path\": test_set[0],\n",
        "            \"sample_id\": range(len(test_set[0])),\n",
        "            \"label\": test_set[1],\n",
        "        }\n",
        "    ).to_csv(test_path, index=False)\n",
        "# Create the client generator\n",
        "fedprox_flower_client_generator: Callable[\n",
        "    [int], FlowerClient\n",
        "] = get_fedprox_flower_client_generator(\n",
        "    model_generator=network_generator_cnn,\n",
        "    data_dir=data_dir,\n",
        "    partition_dir=lda_partition,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K1N62Obm679"
      },
      "source": [
        "**Question 8 (Part II ✅ | Part III/MPhil ✅):**\n",
        "\n",
        "(These are meant to be conceptual questions. You should provide written answers for these. **No more than 3 sentences each**. No code is needed)\n",
        "\n",
        "In FL, fairness is generally defined as the variance of the accuracy of the global model on local clients' test sets. If two models have the same average accuracy, the one with the lower variance between clients is the fairer.\n",
        "\n",
        "- In light of this, is it reasonable to say that analysing the fairness of the model across clients, i.e. the distributed accuracy, could be used as a tool to measure the data heterogeneity? Motivate your answer.\n",
        "- Both FedAvg and FedProx are training a single global model, so we will always measure some unfairness. Do you think we could improve fairness by finetuning the global model on the local clients just before evaluating it on their local test set?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8\n",
        "\n",
        "1. Fairness of the same model across different sets of clients could be used as a metric to compare the degree of data heterogeneity, however simply using the fairness of one model across clients may not always be an accurate measure of data heterogeneity as a lot of other factors could affect it, such as the generalizability of the model, the specific model architecture etc.\n",
        "\n",
        "2. I think in most cases this would improve accuracy, as finetuning the model on the local client dataset would make it perfom better on local client data, and assuming the local training data has similar distribution to local test set this would improve accuracy. This should also improve fairness as if a client's data distribution is very different from global data distribution and it has low accuracy, then this would increase its accuracy more compared to clients with data distributions similar to the global distribution, and thus even out the accuracies."
      ],
      "metadata": {
        "id": "pvEshF-LeB_d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICOGgdnJRd1b"
      },
      "source": [
        "(c) 2024 Alexandru-Andrei Iacob, Lorenzo Sani\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "f60f5a2c15992c74df12f0554524b987217e124a6a47cf1bc494002bece5a18b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}